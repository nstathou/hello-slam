{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282d6c95",
   "metadata": {},
   "source": [
    "## <span style=\"color:#a4d4a3\">**Least Squares**</span>\n",
    "\n",
    "The <span style=\"color:#ffa500\">**Least Squares**</span> method is one of the cornerstones of modern estimation and optimization in robotics.  \n",
    "It provides a simple yet powerful way to find the state that best fits a set of noisy measurements.\n",
    "\n",
    "Least Squares tries to <span style=\"color:#ffa500\">**minimize the difference**</span> between what we <span style=\"color:#ffa500\">**measure**</span> and what we <span style=\"color:#ffa500\">**expect to measure**</span>.\n",
    "\n",
    "- Originally used decades ago, but computationally too expensive for large systems.  \n",
    "\n",
    "- With the rise of efficient solvers (gtsam, g2o and isam2) and sparse linear algebra in the 2010s, it made a strong comeback in SLAM and computer vision.  \n",
    "\n",
    "- Today, it is the foundation of most <span style=\"color:#ffa500\">**graph-based SLAM**</span>, <span style=\"color:#ffa500\">**bundle adjustment**</span>, and <span style=\"color:#ffa500\">**trajectory optimization**</span> techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396c252",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d552b2e",
   "metadata": {},
   "source": [
    "\n",
    "## üåê <span style=\"color:#a4d4a3\"> **Least Squares in General** </span>\n",
    "\n",
    "The Least Squares is designed to compute a solution for an <span style=\"color:#ffa500\">**overdetermined**</span> system (*‚Äúmore equations than unknowns‚Äù*).  \n",
    "\n",
    "<span style=\"color:#00703c\">**Goal:**</span>\n",
    "\n",
    "- Minimize the <span style=\"color:#ffa500\">**sum of squared errors**</span> in the equations.  \n",
    "\n",
    "Standard approach for a large set of problems.\n",
    "\n",
    "<span style=\"color:#00703c\"> **Example:** </span>\n",
    "\n",
    "- In <span style=\"color:#ffa500\">**regression models**</span>, Least Squares is used to find the line or curve that best fits a set of observed data.  \n",
    "\n",
    "### üß© <span style=\"color:#a4d4a3\"> **Problem Definition** </span>\n",
    "\n",
    "Given a system described by a set of $n$ observation functions $\\{f_i(\\mathbf{x})\\}_{i=1:n}$\n",
    "\n",
    "<span style=\"color:#00703c\">**Let:**</span>\n",
    "\n",
    "- $\\mathbf{x} \\;\\;$ be the <span style=\"color:#ffa500\">**state vector**</span>,\n",
    "\n",
    "- $\\mathbf{z}_i \\;\\;$ be a <span style=\"color:#ffa500\">**measurement**</span> of the state $\\mathbf{x}$,\n",
    "\n",
    "- $\\hat{\\mathbf{z}}_i = f_i(\\mathbf{x}) \\;\\;$ be a function which maps $\\mathbf{x}$ to a <span style=\"color:#ffa500\">**predicted measurement**</span> $\\hat{\\mathbf{z}}_i$.\n",
    "\n",
    "<span style=\"color:#00703c\">**Given:**</span>\n",
    "\n",
    "- $n$ <span style=\"color:#ffa500\">**noisy measurements**</span> $\\mathbf{z}_{1:n}$ about the state $\\mathbf{x}$.\n",
    "\n",
    "<span style=\"color:#00703c\">**Goal:**</span>\n",
    "\n",
    "- Estimate the state $\\mathbf{x}$ which <span style=\"color:#ffa500\">**best explains the measurements**</span> $\\mathbf{z}_{1:n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acf6b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f61e2de",
   "metadata": {},
   "source": [
    "### üö® <span style=\"color:#a4d4a3\"> **Error Function** </span>\n",
    "\n",
    "The <span style=\"color:#ffa500\">**error**</span> $\\mathbf{e}_i$ is typically the <span style=\"color:#ffa500\">**difference**</span> between the <span style=\"color:#ffa500\">**predicted**</span> and <span style=\"color:#ffa500\">**actual**</span> measurement:\n",
    "\n",
    "$$\n",
    "\\mathbf{e}_i(\\mathbf{x}) = \\mathbf{z}_i - f_i(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "- We assume the error has <span style=\"color:#ffa500\">**zero mean**</span> and is <span style=\"color:#ffa500\">**normally distributed**</span>.\n",
    "\n",
    "- Gaussian error with <span style=\"color:#ffa500\">**information matrix**</span> $\\mathbf{\\Omega}_i$.\n",
    "\n",
    "- The <span style=\"color:#ffa500\">**squared error**</span> of a measurement depends only on the state and is a scalar:\n",
    "\n",
    "$$\n",
    "e_i(\\mathbf{x}) = \\mathbf{e}_i(\\mathbf{x})^{T}\\,\\mathbf{\\Omega}_i\\,\\mathbf{e}_i(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20f64a",
   "metadata": {},
   "source": [
    "\n",
    "### üìâ <span style=\"color:#a4d4a3\">**Find the Minimum**</span>\n",
    "\n",
    "Find the state $\\mathbf{x}^\\star$ which  <span style=\"color:#ffa500\">**minimizes the error**</span> given all measurements:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{x}^* &= \\arg\\min_\\mathbf{x} F(\\mathbf{x}) \\\\\n",
    "             &= \\arg\\min_\\mathbf{x} \\sum_i e_i(\\mathbf{x}) \\\\\n",
    "             &= \\arg\\min_\\mathbf{x} \\sum_i \\mathbf{e}_i(\\mathbf{x})^T \\, \\mathbf{\\Omega}_i \\, \\mathbf{e}_i(\\mathbf{x}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mathbf{\\Omega}_i$ represents our <span style=\"color:#ffa500\">**uncertainty**</span> in the measurements.\n",
    "\n",
    "- A general solution is to <span style=\"color:#ffa500\">**derive the global error function**</span> and find its nulls.\n",
    "\n",
    "- In general this is complex with <span style=\"color:#ffa500\">**no closed-form**</span> solution.\n",
    "\n",
    "   **‚Ü≥** Use <span style=\"color:#ffa500\">**Numerical Approaches**</span>.\n",
    "\n",
    "#### ü§î <span style=\"color:#a4d4a3\">Assumptions</span>\n",
    "\n",
    "- A <span style=\"color:#ffa500\">**good initial guess**</span> is available.  \n",
    "\n",
    "- The error functions are <span style=\"color:#ffa500\">***‚Äúsmooth‚Äù***</span> in the neighborhood of the *(hopefully)* global minima.\n",
    "\n",
    "   **‚Ü≥** Then we can solve by <span style=\"color:#ffa500\">**iterative local linearization**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f4feb",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">Solve via Iterative Local Linearizations</span>\n",
    "\n",
    "1. <span style=\"color:#ffa500\">**Linearize**</span> the error terms around the current solution (<span style=\"color:#ffa500\">**initial guess**</span>).\n",
    "\n",
    "2. Compute the <span style=\"color:#ffa500\">**first derivative**</span> of the squared error function.\n",
    "\n",
    "3. Set it to <span style=\"color:#ffa500\">**zero**</span> and solve a <span style=\"color:#ffa500\">**linear system**</span>.\n",
    "\n",
    "4. Obtain the <span style=\"color:#ffa500\">**new state**</span> (hopefully closer to the minimum).\n",
    "\n",
    "5. <span style=\"color:#ffa500\">**Iterate.**</span>\n",
    "\n",
    "#### <span style=\"color:#a4d4a3\">Linearize the Error Function</span>\n",
    "\n",
    "Approximate the error functions <span style=\"color:#ffa500\">**around an initial guess**</span> $\\mathbf{x}$ via a Taylor expansion:\n",
    "\n",
    "$$\n",
    "\\mathbf{e}_i(\\mathbf{x} + \\Delta \\mathbf{x}) \\approx \\mathbf{e}_i + \\mathbf{J}_i(\\mathbf{x})\\,\\Delta \\mathbf{x},\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mathbf{J}_i$ is the Jacobian of $\\mathbf{e}_i$ w.r.t. $\\mathbf{x}$.\n",
    "\n",
    "#### <span style=\"color:#a4d4a3\">Squared Error</span>\n",
    "\n",
    "- With the previous linearization, we fix $\\mathbf{x}$ and carry out the <span style=\"color:#ffa500\">**minimization in the increments**</span> $\\Delta \\mathbf{x}$. \n",
    "\n",
    "- We <span style=\"color:#ffa500\">**replace**</span> the Taylor expansion in the squared error terms as follows:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\mathbf{e}_i(\\mathbf{x}) = \\mathbf{z}_i - f_i(\\mathbf{x}),\\qquad\n",
    "e_i(\\mathbf{x}) = \\mathbf{e}_i(\\mathbf{x})^{T}\\,\\mathbf{\\Omega}_i\\, \\mathbf{e}_i(\\mathbf{x}),\\qquad\n",
    "F(\\mathbf{x})=\\sum_i e_i(\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "Linearize:\n",
    "$$\n",
    "\\mathbf{e}_i(\\mathbf{x}+\\Delta \\mathbf{x}) \\approx \\mathbf{e}_i(\\mathbf{x}) + \\mathbf{J}_i\\,\\Delta \\mathbf{x}.\n",
    "$$\n",
    "\n",
    "Substitute into $e_i$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "e_i(x) &\\approx \\big(\\mathbf{e}_i + \\mathbf{J}_i\\,\\Delta \\mathbf{x}\\big)^{T}\\,\\mathbf{\\Omega}_i\\,\\big(\\mathbf{e}_i + \\mathbf{J}_i\\,\\Delta \\mathbf{x}\\big) \\\\\n",
    "&= \\mathbf{e}_i^T\\;\\mathbf{\\Omega}\\;\\mathbf{e}_i + \\Delta \\mathbf{x}\\;\\mathbf{J}_i\\;\\mathbf{\\Omega}_i\\;\\mathbf{e}_i + \\mathbf{e}_i^T\\;\\mathbf{\\Omega}_i\\;\\mathbf{J}_i\\;\\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T \\;\\mathbf{J}_i\\;\\mathbf{\\Omega}_i\\;\\mathbf{J}_i\\;\\Delta\\mathbf{x}\\\\\n",
    "&= \\underbrace{\\mathbf{e}_i^T\\;\\mathbf{\\Omega}\\;\\mathbf{e}_i}_{={c}_i} + \\Delta\\mathbf{x}^T \\underbrace{\\;\\mathbf{J}_i\\;\\mathbf{\\Omega}_i\\;\\mathbf{J}_i}_{=\\mathbf{H}_i}\\;\\Delta\\mathbf{x} + 2\\underbrace{\\;\\mathbf{e}_i^T\\;\\mathbf{\\Omega}_i\\;\\mathbf{J}_i}_{=\\mathbf{b}_i^T}\\;\\Delta\\mathbf{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence\n",
    "\n",
    "$$\n",
    "e_i(x) \\approx c_i + 2\\,\\mathbf{b}_i^T\\;\\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T \\;\\mathbf{H}_i\\;\\Delta\\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea3c3e",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">Global Error</span>\n",
    "\n",
    "- The global error is the <span style=\"color:#ffa500\">**sum of the squared error**</span> terms corresponding to the individual measurements.\n",
    "\n",
    "- For a new expression which approximates the global error in the <span style=\"color:#ffa500\">**neighborhoud of the current solution**</span> $\\mathbf{x}$:\n",
    "\n",
    "From $\\:\\: F(\\mathbf{x})=\\sum_i e_i(\\mathbf{x})$, $\\;$ we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "F(\\mathbf{x} + \\Delta\\mathbf{x}) &\\approx \\sum_i \\Big( c_i \\;+\\; 2\\,\\mathbf{b}_i^T\\;\\Delta\\mathbf{x} \\;+\\; \\Delta\\mathbf{x}^T \\;\\mathbf{H}_i\\;\\Delta\\mathbf{x}\\Big) \\\\\n",
    "& = \\underbrace{\\sum_i c_i}_{c} + 2\\;(\\underbrace{\\sum_i \\mathbf{b}_i}_{\\mathbf{b}})^T\\Delta\\mathbf{x} + \\Delta \\mathbf{x}^T\\Big(\\underbrace{\\sum_i \\mathbf{H}_i}_{\\mathbf{H}}\\Big)\\Delta\\mathbf{x} \\\\\n",
    "& = c + 2\\mathbf{b}^T\\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T\\mathbf{H}\\Delta\\mathbf{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{b}^T &= \\sum_i \\mathbf{e}_i^T\\mathbf{\\Omega}_i\\mathbf{J}_i \\\\\n",
    "\\mathbf{H} &= \\sum_i \\mathbf{J}_i^T\\mathbf{\\Omega}\\mathbf{J}_i\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507396b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f9f47",
   "metadata": {},
   "source": [
    "\n",
    "### ‚úçÔ∏è <span style=\"color:#a4d4a3\">**Quadratic Form Minimization**</span>\n",
    "\n",
    "Based on the above, we can write the global error term as a <span style=\"color:#ffa500\">**quadratic form**</span> in $\\Delta\\mathbf{x}$:\n",
    "\n",
    "$$\n",
    "F(\\mathbf{x} + \\Delta\\mathbf{x}) \\approx c + 2\\mathbf{b}^T\\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T\\mathbf{H}\\Delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "The <span style=\"color:#ffa500\">**approximated derivation**</span> of $F(\\mathbf{x} + \\Delta\\mathbf{x})$ w.r.t. $\\Delta\\mathbf{x}$ is then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F(\\mathbf{x} + \\Delta\\mathbf{x})}{\\partial \\Delta\\mathbf{x}} \\approx 2\\mathbf{b} + 2\\mathbf{H}\\,\\Delta\\mathbf{x}.\n",
    "$$\n",
    "\n",
    "Setting it <span style=\"color:#ffa500\">**to zero**</span> (minimum condition):\n",
    "\n",
    "$$\n",
    "0 = 2\\mathbf{b} + 2\\mathbf{H}\\Delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "Which leads to the <span style=\"color:#ffa500\">**linear system**</span>:\n",
    "\n",
    "$$\n",
    "\\mathbf{H} \\Delta\\mathbf{x} = -\\mathbf{b}  \n",
    "$$\n",
    "\n",
    "The solution for the increment $\\Delta\\mathbf{x}^*$ is:\n",
    "\n",
    "$$\n",
    "\\Delta\\mathbf{x}^* = -\\mathbf{H}^{-1}\\mathbf{b}\n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a3cd2",
   "metadata": {},
   "source": [
    "\n",
    "### üéì <span style=\"color:#a4d4a3\"> Gauss-Newton Solution\n",
    "\n",
    "**Iterate the following steps:**\n",
    "\n",
    "1. <span style=\"color:#ffa500\">**Linearize**</span> around $\\mathbf{x}$ and compute for each measurement:\n",
    "   $$\n",
    "   \\mathbf{e}_i(\\mathbf{x} + \\Delta\\mathbf{x}) \\approx \\mathbf{e}_i(\\mathbf{x}) + \\mathbf{J}_i \\Delta\\mathbf{x}.\n",
    "   $$\n",
    "\n",
    "2. <span style=\"color:#ffa500\">**Compute the terms**</span> for the linear system:\n",
    "   $$\n",
    "   \\mathbf{b} = \\sum_i \\mathbf{e}_i^T \\mathbf{\\Omega}_i\\, \\mathbf{J}_i, \n",
    "   \\qquad\n",
    "   \\mathbf{H} = \\sum_i \\mathbf{J}_i^T \\mathbf{\\Omega}_i\\,\\mathbf{J}_i.\n",
    "   $$\n",
    "\n",
    "3. <span style=\"color:#ffa500\">**Solve**</span> the linear system:\n",
    "   $$\n",
    "   \\mathbf{H} \\Delta \\mathbf{x}^* = -\\mathbf{b} \\quad\\Rightarrow\\quad \\Delta \\mathbf{x}^* = -\\mathbf{H}^{-1}\\mathbf{b}.\n",
    "   $$\n",
    "\n",
    "4. <span style=\"color:#ffa500\">**Update state:**</span> \n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\leftarrow \\mathbf{x} + \\Delta \\mathbf{x}^*\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b6c8a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e7f78",
   "metadata": {},
   "source": [
    "\n",
    "#### ‚úîÔ∏è <span style=\"color:#a4d4a3\">Gauss-Newton Summary</span>\n",
    "\n",
    "Method to <span style=\"color:#ffa500\">**minimize a sum of squared errors**</span>.\n",
    "\n",
    "- Start with an <span style=\"color:#ffa500\">**initial guess**</span>.  \n",
    "\n",
    "- <span style=\"color:#ffa500\">**Linearize**</span> the individual error functions.  \n",
    "\n",
    "- This leads to a <span style=\"color:#ffa500\">**quadratic form**</span>.  \n",
    "\n",
    "- Obtain a <span style=\"color:#ffa500\">**linear system**</span> by setting its derivative to <span style=\"color:#ffa500\">**zero**</span>.  \n",
    "\n",
    "- Solving the linear system leads to a <span style=\"color:#ffa500\">**state update**</span>.  \n",
    "\n",
    "- <span style=\"color:#ffa500\">**Iterate.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d4a78",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63deae",
   "metadata": {},
   "source": [
    "\n",
    "## üñáÔ∏è <span style=\"color:#a4d4a3\">**Relation to Probabilistic State Estimation**</span>\n",
    "\n",
    "So far, we minimized an error function.  \n",
    "\n",
    "*How does this relate to state estimation in the <span style=\"color:#ffa500\">**probabilistic**</span> sense?*\n",
    "\n",
    "### üßÆ <span style=\"color:#a4d4a3\">**General State Estimation**</span>\n",
    "\n",
    "Using Bayes‚Äô rule, independence, and the Markov assumption, we can write:\n",
    "\n",
    "$$\n",
    "p(x_{0:t}\\mid z_{1:t}, u_{1:t}) \\propto p(x_0)\\,\\prod_{t}\\,p(x_t\\mid x_{t-1},u_t)\\,p(z_t\\mid x_t).\n",
    "$$\n",
    "\n",
    "Written as the <span style=\"color:#ffa500\">**Log-Likelihood**</span>:\n",
    "\n",
    "$$\n",
    "\\log p(x_{0:t}\\mid z_{1:t}, u_{1:t}) = \\text{const.} + \\log p(x_0) + \\sum_t \\big[\\log p(x_t\\mid x_{t-1},u_t) + \\log p(z_t\\mid x_t)\\big].\n",
    "$$\n",
    "\n",
    "Assuming <span style=\"color:#ffa500\">**Gaussian distributions**</span>, for a Gaussian $\\mathcal N(x;\\mu,\\Sigma)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log \\mathcal N(x;\\mu,\\Sigma) &= \\text{const.} - \\tfrac{1}{2}\\,\\underbrace{(x-\\mu)^T}_{\\mathbf{e}^T(x)}\\,\\underbrace{\\Sigma^{-1}}_{\\mathbf{\\Omega}}\\,\\underbrace{(x-\\mu)}_{\\mathbf{e}(x)}\\\\\n",
    "&= \\text{const.} - \\tfrac{1}{2}\\,\\underbrace{\\mathbf{e}(x)^T\\,\\mathbf{\\Omega}\\,\\mathbf{e}(x)}_{\\text{quadratic error } e(x)},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, up to a constant, the log-likelihood is equivalent to the <span style=\"color:#ffa500\">**error functions**</span> used before.\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\log p(x_{0:t}\\mid z_{1:t}, u_{1:t}) =\\text{const.} - \\tfrac{1}{2}\\,e_p(x) - \\tfrac{1}{2}\\sum_t \\big(e_{u_t}(x) + e_{z_t}(x)\\big),\n",
    "$$\n",
    "\n",
    "where $e_p$ is the <span style=\"color:#ffa500\">**prior term**</span>, $e_{u_t}$ the <span style=\"color:#ffa500\">**motion**</span> (odometry) <span style=\"color:#ffa500\">**error**</span>, and $e_{z_t}$ the <span style=\"color:#ffa500\">**measurement error**</span>.\n",
    "\n",
    "<span style=\"color:#ffa500\">**Maximizing**</span> the log-likelihood leads to:\n",
    "\n",
    "$$\n",
    "\\arg\\max_x \\log p(x_{0:t}\\mid z_{1:t}, u_{1:t}) \\equiv \\arg\\min_x \\Big( e_p(x) + \\sum_t \\big[ e_{u_t}(x) + e_{z_t}(x) \\big] \\Big).\n",
    "$$\n",
    "\n",
    "\n",
    "<span style=\"color:#00703c\">**Takeaway:**</span>\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Least squares**</span> (with Gaussian assumptions) is <span style=\"color:#ffa500\">**equivalent to Maximum A Posteriori**</span> (MAP) estimation. \n",
    "\n",
    "- <span style=\"color:#ffa500\">**Minimizing the sum of weighted squared residuals**</span> corresponds to <span style=\"color:#ffa500\">**maximizing the posterior probability**.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761050c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d5037c",
   "metadata": {},
   "source": [
    "#### ‚úîÔ∏è <span style=\"color:#a4d4a3\">Summary</span>\n",
    "\n",
    "- Technique to <span style=\"color:#ffa500\">**minimize squared error**</span> functions.\n",
    "\n",
    "- Gauss-Newton is an <span style=\"color:#ffa500\">**iterative approach**</span> for non-linear problems.\n",
    "\n",
    "- Uses linearization (approximation).\n",
    "\n",
    "- Equivalent to <span style=\"color:#ffa500\">**maximizing the log likelihood**</span> of independent Gaussians.\n",
    "\n",
    "- Popular method in a lot of disciplines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
