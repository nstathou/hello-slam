{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d997c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e38d957e",
   "metadata": {},
   "source": [
    "# <span style=\"color:#a4d4a3\">**Particle Filter Localization**</span>\n",
    "\n",
    "### üéØ <span style=\"color:#a4d4a3\">**Short intro to PF & Monte Carlo Localization**</span>\n",
    "\n",
    "- Kalman Filter and variants only model <span style=\"color:#ffa500\">**Gaussian**</span> distributions.\n",
    "\n",
    "<span style=\"color:#00703c\">**Goal:**</span>\n",
    "\n",
    "- Be able to handle <span style=\"color:#ffa500\">**arbitrary**</span> distributions.\n",
    "\n",
    "The main idea of the <span style=\"color:#00703c\">**Particle Filter**</span> is:\n",
    "- Use <span style=\"color:#ffa500\">**multiple samples**</span> (particles) to represent the belief over a pose.\n",
    "- The more samples in a region, the <span style=\"color:#ffa500\">**higher the probability**</span>.\n",
    "- Assign <span style=\"color:#ffa500\">**weights**</span> to samples; larger weight ‚áí higher probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc95f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b07ba9",
   "metadata": {},
   "source": [
    "\n",
    "### üî∏ <span style=\"color:#a4d4a3\">**Particle Set**</span>\n",
    "\n",
    "The <span style=\"color:#ffa500\">**particles**</span> are a set of weighted samples:\n",
    "\n",
    "$$\n",
    "\\mathcal{X} = \\left\\{\\left\\langle x_t^{[j]},\\,w_t^{[j]}\\right\\rangle\\right\\}_{j=1,\\ldots,J}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $x_t^{[j]}$ is a <span style=\"color:#ffa500\">**state hypothesis**</span> and\n",
    "- $w_t^{[j]}$ is the <span style=\"color:#ffa500\">**importance weight**</span>.\n",
    "\n",
    "\n",
    "The samples represent the <span style=\"color:#ffa500\">**posterior**</span>:\n",
    "\n",
    "$$\n",
    "p(x)\\ \\approx\\ \\sum_{j=1}^{J} w^{[j]}\\,\\delta_{x^{[j]}}(x)\n",
    "$$\n",
    "\n",
    "where $\\delta_x$ is the <span style=\"color:#ffa500\">**Dirac**</span> distribution.\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em>If we want more accurate representation we need more samples. Also the bigger/complex the function we are trying to describe, the more samples we need. This directly affects the computational demands.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ec78e",
   "metadata": {},
   "source": [
    "The main <span style=\"color:#ffa500\">**idea**</span> is to use many samples (particles) to approximate a target distribution. The denser the particles in a region, the <span style=\"color:#ffa500\">**higher**</span> the estimated probability of that region. Below we plot two examples:\n",
    "- On the <span style=\"color:#ffa500\">**left**</span> a unimodal Gaussian.\n",
    "- On the <span style=\"color:#ffa500\">**right**</span> a multi-modal mixture.\n",
    "\n",
    "The <span style=\"color:#ffa500\">**rug marks**</span> on the x-axis show particle locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f29f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Particles for Approximation: unimodal vs. multimodal ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "# ---- target pdfs ----\n",
    "def normal_pdf(x, mu=0.0, sigma=1.0):\n",
    "    c = 1.0 / (np.sqrt(2*np.pi) * sigma)\n",
    "    return c * np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "def mix2_pdf(x, w=0.45, mu1=-2.0, s1=0.7, mu2=1.5, s2=0.4):\n",
    "    return w*normal_pdf(x, mu1, s1) + (1-w)*normal_pdf(x, mu2, s2)\n",
    "\n",
    "def sample_mix2(n, w=0.45, mu1=-2.0, s1=0.7, mu2=1.5, s2=0.4, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    sel = rng.uniform(size=n) < w\n",
    "    x = np.empty(n)\n",
    "    x[sel]  = rng.normal(mu1, s1, sel.sum())\n",
    "    x[~sel] = rng.normal(mu2, s2, (~sel).sum())\n",
    "    return x\n",
    "\n",
    "# ---- draw samples ----\n",
    "J = 3000  # number of particles\n",
    "samples_uni = rng.normal(0.0, 1.0, J)\n",
    "samples_mix = sample_mix2(J, rng=rng)\n",
    "\n",
    "# ---- plotting ----\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "\n",
    "# Ranges for pdf curves\n",
    "x1 = np.linspace(-4, 4, 600)\n",
    "x2 = np.linspace(-5, 4, 600)\n",
    "\n",
    "# Left: unimodal Gaussian\n",
    "ax = axes[0]\n",
    "ax.plot(x1, normal_pdf(x1, 0.0, 1.0), lw=2.5, color='crimson', label='f(x)')\n",
    "ax.hist(samples_uni, bins=60, density=True, histtype='stepfilled', alpha=0.25, color='crimson')\n",
    "ax.plot(samples_uni, np.full_like(samples_uni, ax.get_ylim()[0]), '|', ms=20, color='black', alpha=0.5)  # rug\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('probability / weight')\n",
    "ax.set_title('Unimodal: Gaussian')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Right: bimodal mixture\n",
    "ax = axes[1]\n",
    "ax.plot(x2, mix2_pdf(x2), lw=2.5, color='steelblue', label='f(x)')\n",
    "ax.hist(samples_mix, bins=60, density=True, histtype='stepfilled', alpha=0.25, color='steelblue')\n",
    "ax.plot(samples_mix, np.full_like(samples_mix, ax.get_ylim()[0]), '|', ms=20, color='black', alpha=0.5)  # rug\n",
    "ax.set_xlabel('x')\n",
    "ax.set_title('Multi-modal: Gaussian Mixture')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.margins(x=0.02)\n",
    "    ax.grid(alpha=0.15)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f2d9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ccffd",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#a4d4a3\">How to obtain such samples?</span>\n",
    "\n",
    "<span style=\"color:#ffa500\">**Closed-form sampling**</span> is only possible for a few distributions.\n",
    "- Example: Gaussian - $\\frac{1}{2} \\sum_{i=1}^{12} \\text{rand}(-\\sigma, \\sigma) $\n",
    "\n",
    "\n",
    "How to <span style=\"color:#ffa500\">**sample**</span> from <span style=\"color:#ffa500\">**other**</span> distributions?\n",
    "\n",
    "$\\quad\\quad$ **‚Ü≥** use <span style=\"color:#ffa500\">**importance sampling**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310acb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d963c7",
   "metadata": {},
   "source": [
    "\n",
    "### üìä <span style=\"color:#a4d4a3\">**Importance Sampling Principle**</span>\n",
    "\n",
    "We can use a different <span style=\"color:#ffa500\">**proposal**</span> distribution $g(x)$ to generate samples from the <span style=\"color:#ffa500\">**target**</span> distribution $f(x)$.\n",
    "\n",
    "- Account for the difference with a weight $w(x)$:\n",
    "\n",
    "$$\n",
    "w(x)\\ \\propto\\ \\frac{f(x)}{g(x)}\n",
    "$$\n",
    "\n",
    "**Pre-condition:**\n",
    "\n",
    "- if $f(x)>0 \\to g(x)>0$.\n",
    "\n",
    "In the example below, we compare <span style=\"color:#ffa500\">**two proposals**</span>  for approximating a <span style=\"color:#ffa500\">**bimodal**</span>  target density $f(x)$ using <span style=\"color:#ffa500\">**importance sampling**</span> . We draw samples $x^{[j]} \\sim g(x)$ and assign weights $w^{[j]} \\propto \\frac{f(x^{[j]})}{g(x^{[j]})}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importance Sampling demo: recovering a target pdf from proposal samples ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(2)\n",
    "\n",
    "# ---- utilities ----\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return (1.0 / (np.sqrt(2*np.pi)*sigma)) * np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "\n",
    "# Target: bimodal mixture (normalized)\n",
    "def target_pdf(x):\n",
    "    return 0.35*normal_pdf(x, -2.0, 0.6) + 0.65*normal_pdf(x, 1.8, 0.8)\n",
    "\n",
    "# Proposals (both positive everywhere)\n",
    "def g_good_pdf(x):  # broad, covers both modes well\n",
    "    return normal_pdf(x, 0.0, 2.2)\n",
    "\n",
    "def g_bad_pdf(x):   # too narrow, poor tail/mode coverage\n",
    "    return normal_pdf(x, 0.0, 0.8)\n",
    "\n",
    "def sample_g_good(n, rng):\n",
    "    return rng.normal(0.0, 2.2, n)\n",
    "\n",
    "def sample_g_bad(n, rng):\n",
    "    return rng.normal(0.0, 0.8, n)\n",
    "\n",
    "# ---- sampling ----\n",
    "J = 5000\n",
    "x_good = sample_g_good(J, rng)\n",
    "x_bad  = sample_g_bad(J, rng)\n",
    "\n",
    "# Unnormalized importance weights (proportional to f/g)\n",
    "w_good = target_pdf(x_good) / g_good_pdf(x_good)\n",
    "w_bad  = target_pdf(x_bad)  / g_bad_pdf(x_bad)\n",
    "\n",
    "# Normalize for estimators (sum to 1)\n",
    "w_good /= np.sum(w_good)\n",
    "w_bad  /= np.sum(w_bad)\n",
    "\n",
    "# Check a simple expectation: mean of x under f(x)\n",
    "true_mean = 0.35*(-2.0) + 0.65*(1.8)  # mixture mean\n",
    "is_mean_good = np.sum(w_good * x_good)\n",
    "is_mean_bad  = np.sum(w_bad  * x_bad)\n",
    "print(f\"True mean ‚âà {true_mean:.3f} | IS mean (good) ‚âà {is_mean_good:.3f} | IS mean (bad) ‚âà {is_mean_bad:.3f}\")\n",
    "\n",
    "# ---- plotting ----\n",
    "xs = np.linspace(-5, 5, 800)\n",
    "fxs = target_pdf(xs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "\n",
    "# Left: GOOD proposal\n",
    "ax = axes[0]\n",
    "ax.plot(xs, fxs, lw=2.5, color='crimson', label='target f(x)')\n",
    "ax.plot(xs, g_good_pdf(xs), lw=1.5, color='gray', alpha=0.9, label='proposal g(x)')\n",
    "# Unweighted histogram shows proposal density (for comparison)\n",
    "ax.hist(x_good, bins=60, density=True,  alpha=0.5, color='gray', label='samples from g(x)')\n",
    "# Weighted histogram approximates f(x)\n",
    "ax.hist(x_good, bins=60, density=True, weights=w_good, alpha=0.25, color='crimson', label='IS weighted')\n",
    "ax.set_title('Good proposal (broad)'); ax.set_xlabel('x'); ax.set_ylabel('density')\n",
    "ax.legend(loc='upper left'); ax.grid(alpha=0.15)\n",
    "\n",
    "# Right: BAD proposal\n",
    "ax = axes[1]\n",
    "ax.plot(xs, fxs, lw=2.5, color='steelblue', label='target f(x)')\n",
    "ax.plot(xs, g_bad_pdf(xs), lw=1.5, color='gray', alpha=0.9, label='proposal g(x)')\n",
    "ax.hist(x_bad, bins=60, density=True, alpha=0.5, color='gray', label='samples from g(x)')\n",
    "ax.hist(x_bad, bins=60, density=True, weights=w_bad, alpha=0.25, color='steelblue', label='IS weighted')\n",
    "ax.set_title('Bad proposal (narrow)'); ax.set_xlabel('x')\n",
    "ax.legend(loc='upper left'); ax.grid(alpha=0.15)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0efbf2",
   "metadata": {},
   "source": [
    "<span style=\"color:#ffa500\">**Takeaway:**</span> \n",
    "\n",
    "- A well-matched proposal yields a weighted histogram that closely follows $f$; a poor proposal leads to <span style=\"color:#ffa500\">**few dominating weights**</span> and a noisy approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fbb72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925473ee",
   "metadata": {},
   "source": [
    "\n",
    "### üìç <span style=\"color:#a4d4a3\">**Particle Filter (PF)**</span>\n",
    "\n",
    "The <span style=\"color:#ffa500\">**Particle filter**</span> is a realization of the <span style=\"color:#ffa500\">**recursive Bayes filter**</span>. More specifically, is a <span style=\"color:#ffa500\">**non-parametric**</span> approach that does not maintain a closed-form distribution.\n",
    "\n",
    "As we have already discussed so far, the key idea is to model any <span style=\"color:#ffa500\">**arbitrary distribution**</span> using <span style=\"color:#ffa500\">**samples**</span>. Thus the <span style=\"color:#ffa500\">**two steps**</span> of the Bayes filter are:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Prediction step:**</span> draw samples from the proposal distribution (use the <span style=\"color:#ffa500\">**motion model**</span> to sample).\n",
    "- <span style=\"color:#00703c\">**Correction step:**</span> use the <span style=\"color:#ffa500\">**observations**</span> to compute the correction or (weights).\n",
    "\n",
    "The more samples we use, the better our estimate is going to be!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e4491",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3170c1",
   "metadata": {},
   "source": [
    "#### üë®üèª‚Äçüíª <span style=\"color:#a4d4a3\">**Particle Filter Algorithm**</span>\n",
    "\n",
    "The <span style=\"color:#ffa500\">**Particle Filter**</span> can be summarized in the following algorithm:\n",
    "\n",
    "> <tt> <span style=\"color:#4D96FF\">def</span> **<span style=\"color:#6BCB77\">Particle_Filter</span>($\\color{#ffa500}\\mathcal{X}_{t-1}, \\color{#ffa500}u_t, \\color{#ffa500}z_t$):**    \n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">1.</span> $\\bar{\\mathcal{X}}_t = \\mathcal{X}_t = \\emptyset \\quad$ <span style=\"color:#948979\"># Init</span>\n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">2.</span> <span style=\"color:#e74c3c\">for</span> $j=1$ <span style=\"color:#ffa500\">to</span> $J$ <span style=\"color:#e74c3c\">do</span>: $\\quad$ <span style=\"color:#948979\"># Iterate over all previous samples</span>    \n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">3.</span> $x_t^{[j]} \\sim \\pi(x_t) \\quad$ <span style=\"color:#948979\"># Sample from the proposal distribution</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">4.</span> $w_t^{[j]} = \\frac{p(x_t^{[j]})}{\\pi(x_t^{[j]})} \\quad$ <span style=\"color:#948979\"># Compute correction weight</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">5.</span> $\\bar{\\mathcal{X}}_t = \\bar{\\mathcal{X}}_t + \\langle x_t^{[j]}, w_t^{[j]}\\rangle \\quad$ <span style=\"color:#948979\"># Add to predicted sample set</span> \n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">6.</span> <span style=\"color:#e74c3c\">endfor</span>\n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">7.</span> <span style=\"color:#e74c3c\">for</span> $j=1$ <span style=\"color:#ffa500\">to</span> $J$ <span style=\"color:#e74c3c\">do</span>: $\\quad$<span style=\"color:#948979\"># Resample</span>  \n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">8.</span> <span style=\"color:#ffa500\">draw</span> $i \\in 1, \\ldots, J$ <span style=\"color:#ffa500\">with probability</span> $\\propto w_t^{[i]}$\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">9.</span> <span style=\"color:#ffa500\">add</span> $x_t^{[i]}$ <span style=\"color:#ffa500\">to</span> $\\mathcal{X}_t$\n",
    ">>>\n",
    ">><span style=\"color:#FF2DD1\">10.</span> <span style=\"color:#e74c3c\">endfor</span>    \n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">11.</span> <span style=\"color:#e74c3c\">return</span> $\\mathcal{X}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18edff3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c383479",
   "metadata": {},
   "source": [
    "\n",
    "### üöô <span style=\"color:#a4d4a3\">**Monte Carlo Localization (MCL)**</span>\n",
    "\n",
    "When we focus on <span style=\"color:#ffa500\">**only localization**</span> and assume a **known map** (e.g., an occupancy grid), we can use <span style=\"color:#ffa500\">**Monte Carlo Localization (MCL)**</span>.  \n",
    "\n",
    "MCL is a <span style=\"color:#ffa500\">**specialized instance**</span> of the <span style=\"color:#ffa500\">**Particle Filter**</span> tailored to pose estimation with a fixed map.\n",
    "\n",
    "- Each particle is a <span style=\"color:#ffa500\">**pose hypothesis**</span>.\n",
    "- <span style=\"color:#00703c\">**Proposal**</span> is the <span style=\"color:#ffa500\"> **motion model** </span>:\n",
    "\n",
    "  $$\n",
    "  x_t^{[j]} \\sim p(x_t \\mid x_{t-1}, u_t)\n",
    "  $$\n",
    "\n",
    "- <span style=\"color:#00703c\">**Correction**</span> via the <span style=\"color:#ffa500\">**observation model**</span> (with known map $m$):\n",
    "\n",
    "  $$\n",
    "  w_t^{[j]} = \\frac{\\textit{target}}{\\textit{proposal}} \\propto p(z_t \\mid x_t, m)\n",
    "  $$\n",
    "\n",
    "If we revisit the <tt><span style=\"color:#6BCB77\">Particle_Filter</span></tt> algorithm, then the MCL is the same but we replace lines <tt><span style=\"color:#FF2DD1\">3.</span></tt> and <tt><span style=\"color:#FF2DD1\">4.</span></tt> with:\n",
    "\n",
    ">>>  <tt><span style=\"color:#FF2DD1\">3.</span></tt> $x_t^{[j]} \\sim p(x_t \\mid x_{t-1}^{[j]}, u_t) \\quad$ <span style=\"color:#948979\"># Sample from the proposal distribution</span>\n",
    ">>>\n",
    ">>>  <tt><span style=\"color:#FF2DD1\">4.</span></tt> $w_t^{[j]} = p(z_t \\mid x_t^{[j]}) \\quad$ <span style=\"color:#948979\"># Compute correction weight</span>\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em> The Particle Filter becomes the Monte Carlo Localization (MCL) approach when we are trying to solve the localizaiton problem and the proposal is chosen as the motion model. Then there is a more detailed derivation, showing that the importance weight becomes proportional to the obseravtion model.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2dcf2f",
   "metadata": {},
   "source": [
    "#### üß´ <span style=\"color:#a4d4a3\">**Resampling**</span>\n",
    "\n",
    "Before we move into a `python` example of the Monte Carlo Localization, let's take a look into the <span style=\"color:#ffa500\">**resampling**</span> step first.\n",
    "\n",
    "The resampling step <span style=\"color:#ffa500\">**updates the particle set**</span> by reallocating our <span style=\"color:#ffa500\">**limited particle budget**</span>. It lets low-weight (unlikely) samples to *die out* and replicates high-weight ones, so the particle set <span style=\"color:#ffa500\">**better captures the belief**</span> at each step.\n",
    "\n",
    "- <span style=\"color:#00703c\">**Prune**</span> low-weight (unlikely) particles ‚Äî let weak hypotheses **die out**.\n",
    "- <span style=\"color:#00703c\">**Replicate**</span> high-weight (likely) particles ‚Äî create **stronger** hypotheses.\n",
    "- Concentrate computational effort on <span style=\"color:#00703c\">**high-probability regions**</span> of the state space.\n",
    "- <span style=\"color:#00703c\">**Survival of the fittest**</span>; a trick to avoid many samples covering unlikely states.\n",
    "\n",
    "##### <span style=\"color:#a4d4a3\">Resampling Methods</span>\n",
    "\n",
    "<span style=\"color:#00703c\">**Roulette wheel resampling:**</span>\n",
    "\n",
    "- Build the cumulative sum (CDF) of <span style=\"color:#ffa500\">**normalized**</span> weights.  \n",
    "\n",
    "- Draw $J$ independent uniforms $u_j \\sim \\mathcal{U}(0,1)$.  \n",
    "\n",
    "- For each $u_j$, find the first CDF bin $\\ge u_j$ (e.g., via <span style=\"color:#ffa500\">**binary search**</span>) and copy that particle. \n",
    "\n",
    "- Complexity: $O(J \\log J)$ with binary search.  \n",
    "\n",
    "- Simple but <span style=\"color:#ffa500\">**higher variance**</span>; a few high-weight particles may be chosen many times.\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#00703c\">**Stochastic universal sampling** (SUS)</span> \n",
    "\n",
    "- Build the CDF of <span style=\"color:#ffa500\">**normalized**</span> weights.\n",
    "\n",
    "- Draw a single random offset $r \\sim \\mathcal{U}(0, 1/J)$.  \n",
    "\n",
    "- Place $J$ equally spaced pointers at $r,\\, r+\\tfrac{1}{J},\\, r+\\tfrac{2}{J},\\dots, r+\\tfrac{J-1}{J}$. \n",
    "\n",
    "- For each pointer, select the first CDF bin $\\ge$ pointer and copy that particle.  \n",
    "\n",
    "- Complexity: $O(J)$ using one pass through the CDF.  \n",
    "\n",
    "- <span style=\"color:#ffa500\">**Low variance**</span>; allocations are closer to the expected counts, reducing sample impoverishment compared to roulette."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703f513",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c93f0",
   "metadata": {},
   "source": [
    "##### üéÆ `Python Example: Monte Carlo Localization in an Occupancy Map`\n",
    "\n",
    "This interactive, keyboard-driven demo implements MCL on a fixed occupancy grid using a <span style=\"color:#ffa500\">**likelihood-field**</span> sensor model (precomputed distance transform). \n",
    "\n",
    "Particles are <span style=\"color:#ffa500\">**snapped to free pixels**</span> and the displayed estimate <span style=\"color:#ffa500\">**starts at a random free pose**</span>. \n",
    "\n",
    "**Lightweight implementation tricks:**\n",
    "\n",
    "- <span style=\"color:#00703c\">**ESS-triggered systematic resampling + random injection:**</span> We resample only when the **effective sample size** drops (e.g., $N_\\text{eff}/N<\\tau$), using **systematic** resampling for low variance, then replace a small fraction of particles with **uniform free-space** samples. This keeps diversity high and improves recovery.\n",
    "\n",
    "- <span style=\"color:#00703c\">**Top-K weighted read-out:**</span> The pose estimate is computed from the **highest-weight K%** particles instead of the entire cloud. This reduces bias from distant modes and yields a steadier, more reliable read-out during global localization.\n",
    "\n",
    "- <span style=\"color:#00703c\">**EMA smoothing** (visual only):</span> We apply a light **exponential moving average** to the displayed estimate. It damps jitter from stochastic resampling while leaving the underlying filter state untouched.\n",
    "\n",
    "- <span style=\"color:#00703c\">**Beam subsampling + hit-only beams:**</span> Using every $s$-th beam cuts measurement cost by $\\sim s$ with minor accuracy loss, and **ignoring max-range (no-hit) beams** stabilizes the likelihood-field update in structured maps. Together, these keep updates fast and well-conditioned.\n",
    "\n",
    "We provide more details to some of the steps, as well as tips on the parameters, right after the `python` code.\n",
    "\n",
    "Press <span style=\"color:#ffa500\">**G**</span> to reset the particles, or <span style=\"color:#ffa500\">**K**</span> to reset the predicted pose. Press <span style=\"color:#ffa500\">**P**</span> to turn on/off the drawing of the particels. Press <span style=\"color:#ffa500\">**.**</span> or <span style=\"color:#ffa500\">**,**</span> to increase/decreas the number of beam subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829469dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# Fast & Stable MCL (Pixel-Quantized Particles)\n",
    "# GT (left) | MCL (right; red particles)\n",
    "# ===================================================\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# --- Helpers ---\n",
    "def wrap_angle(a: float) -> float:\n",
    "    return (a + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "def i2(p):\n",
    "    \"\"\"(x,y) -> (int,int)\"\"\"\n",
    "    return (int(p[0]), int(p[1]))\n",
    "\n",
    "def circ_mean_thetas(th: np.ndarray, w: np.ndarray) -> float:\n",
    "    \"\"\"Compute the circular mean of angles.\n",
    "    Args:\n",
    "        th: (N,) array of angles in radians\n",
    "        w:  (N,) array of weights (not necessarily normalized)\n",
    "    Returns:\n",
    "        single angle in radians\n",
    "    \"\"\"\n",
    "    s = np.sum(w * np.sin(th)); c = np.sum(w * np.cos(th))\n",
    "    return np.arctan2(s, c)\n",
    "\n",
    "def blend_pose(prev: np.ndarray, cur: np.ndarray, alpha=0.5) -> np.ndarray:\n",
    "    \"\"\"EMA smoothing of pose; angle blended on the circle.\n",
    "    Args:\n",
    "        prev: (3,) previous pose (x,y,theta) or None\n",
    "        cur:  (3,) current pose (x,y,theta)\n",
    "        alpha: blending factor (0 <= alpha <= 1)\n",
    "    Returns:\n",
    "        (3,) blended pose (x,y,theta)\n",
    "    \"\"\"\n",
    "    if prev is None: return cur.copy()\n",
    "    x = (1-alpha)*prev[0] + alpha*cur[0]\n",
    "    y = (1-alpha)*prev[1] + alpha*cur[1]\n",
    "    dth = wrap_angle(cur[2] - prev[2])\n",
    "    th  = wrap_angle(prev[2] + alpha*dth)\n",
    "    return np.array([x,y,th], dtype=np.float32)\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "class Config:\n",
    "    panel_w, panel_h = 600, 400\n",
    "    window_size = (panel_w*2, panel_h)\n",
    "    floor_img_path = '../figures/floor_plan.png'\n",
    "\n",
    "    # LiDAR\n",
    "    num_beams   = 180\n",
    "    fov_deg     = 360\n",
    "    scan_ms     = 120\n",
    "    ray_stride  = 2\n",
    "    max_range_px = 250\n",
    "    beam_subsample_step = 2\n",
    "\n",
    "    # Motion (odometry-style command dr1, dt, dr2)\n",
    "    trans_step = 12.0\n",
    "    rot_step   = np.deg2rad(12.0)\n",
    "\n",
    "    # Motion noise (smaller to reduce jitter)\n",
    "    a1 = 1.0e-3; a2 = 1.0e-3; a3 = 1.0e-3; a4 = 1.0e-3\n",
    "\n",
    "    # Likelihood-field model\n",
    "    sigma_hit = 8.0           # [px] std of endpoint distance to nearest wall\n",
    "    use_only_hit_beams = True # ignore max-range beams (poorly informative)\n",
    "\n",
    "    # Particles / resampling (note: particles are pixels)\n",
    "    Np = 1000\n",
    "    resample_neff_ratio = 0.8\n",
    "    random_injection_frac = 0.01\n",
    "\n",
    "    # Estimation\n",
    "    top_k_frac = 0.8          # estimate from top-K by weight (robust)\n",
    "    smooth_alpha = 0.5        # EMA smoothing on pose estimate\n",
    "\n",
    "    # Drawing\n",
    "    draw_particles = True\n",
    "    particle_color = (220, 40, 40)  # red like the screenshot\n",
    "    draw_top_k_particles = None     # None = draw all\n",
    "\n",
    "    seed = 0\n",
    "\n",
    "# --- Panel ---\n",
    "class Panel:\n",
    "    def __init__(self, screen, rect): self.screen, self.rect = screen, rect\n",
    "    @property\n",
    "    def ox(self): return self.rect[0]\n",
    "    def clear(self, color):\n",
    "        pygame.draw.rect(self.screen, color, self.rect)\n",
    "        pygame.draw.rect(self.screen, (200,200,200), self.rect, 2)\n",
    "    def blit(self, surf, at=(0,0)):\n",
    "        x,y,_,_ = self.rect; self.screen.blit(surf, (x+at[0], y+at[1]))\n",
    "    def polygon(self, color, pts):\n",
    "        x,y,_,_ = self.rect; P = [(x+int(px), y+int(py)) for (px,py) in pts]\n",
    "        pygame.draw.polygon(self.screen, color, P)\n",
    "    def circle(self, color, p, r):\n",
    "        x,y,_,_ = self.rect; pygame.draw.circle(self.screen, color, (x+int(p[0]), y+int(p[1])), r)\n",
    "    def text(self, font, s, color, pos):\n",
    "        x,y,_,_ = self.rect; self.screen.blit(font.render(s, True, color), (x+pos[0], y+pos[1]))\n",
    "\n",
    "# --- Map + distance field ---\n",
    "class Map2D:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.surface = pygame.transform.smoothscale(\n",
    "            pygame.image.load(cfg.floor_img_path), (cfg.panel_w, cfg.panel_h)\n",
    "        )\n",
    "        arr = pygame.surfarray.array3d(self.surface)  # (W,H,3) (x,y,RGB)\n",
    "        self.wall_mask = np.all(arr < 128, axis=2).astype(np.bool_)  # True=wall\n",
    "        self.free_mask = ~self.wall_mask\n",
    "        # Precompute list of free pixel coordinates (x,y) for fast sampling\n",
    "        free_xy = np.where(self.free_mask)          # tuple of (x_idx, y_idx)\n",
    "        self.free_coords = np.stack(free_xy, axis=1).astype(np.int32)  # (Nfree,2)\n",
    "        self.dist_field = self._build_distance_field()\n",
    "\n",
    "    def _build_distance_field(self):\n",
    "        W,H = self.wall_mask.shape\n",
    "        try:\n",
    "            import scipy.ndimage as ndi\n",
    "            return ndi.distance_transform_edt(self.free_mask).astype(np.float32)\n",
    "        except Exception:\n",
    "            # chamfer fallback\n",
    "            inf = 1e9\n",
    "            df = np.full((W, H), inf, dtype=np.float32)\n",
    "            df[self.wall_mask] = 0.0\n",
    "            # forward pass\n",
    "            for x in range(W):\n",
    "                xm1 = x-1\n",
    "                for y in range(H):\n",
    "                    d = df[x,y]\n",
    "                    if xm1 >= 0: d = min(d, df[xm1,y] + 1.0)\n",
    "                    ym1 = y-1\n",
    "                    if ym1 >= 0: d = min(d, df[x,ym1] + 1.0)\n",
    "                    if (xm1 >= 0) and (ym1 >= 0): d = min(d, df[xm1,ym1] + np.sqrt(2.0))\n",
    "                    xp1 = x+1\n",
    "                    if (xp1 < W) and (ym1 >= 0): d = min(d, df[xp1,ym1] + np.sqrt(2.0))\n",
    "                    df[x,y] = d\n",
    "            # backward pass\n",
    "            for x in range(W-1,-1,-1):\n",
    "                xp1 = x+1\n",
    "                for y in range(H-1,-1,-1):\n",
    "                    d = df[x,y]\n",
    "                    if xp1 < W: d = min(d, df[xp1,y] + 1.0)\n",
    "                    yp1 = y+1\n",
    "                    if yp1 < H: d = min(d, df[x,yp1] + 1.0)\n",
    "                    if (xp1 < W) and (yp1 < H): d = min(d, df[xp1,yp1] + np.sqrt(2.0))\n",
    "                    xm1 = x-1\n",
    "                    if (xm1 >= 0) and (yp1 < H): d = min(d, df[xm1,yp1] + np.sqrt(2.0))\n",
    "                    df[x,y] = d\n",
    "            return df\n",
    "\n",
    "    def cast_beam_fast(self, pos_xy: tuple, angle: float, max_r: float):\n",
    "        \"\"\"Cast a ray from pos_xy at given angle (radians) up to max_r pixels.\n",
    "        Args:\n",
    "            pos_xy: (x,y) start position in pixels (float)\n",
    "            angle: angle in radians\n",
    "            max_r: maximum range in pixels\n",
    "        Returns:\n",
    "            (x_hit, y_hit): hit position in pixels (int) or None if no hit\n",
    "            r: distance to hit in pixels (int) or max_r if no hit\n",
    "        \"\"\"\n",
    "        W, H = self.wall_mask.shape\n",
    "        x0, y0 = float(pos_xy[0]), float(pos_xy[1])\n",
    "        c, s = np.cos(angle), np.sin(angle)\n",
    "        for d in range(0, int(max_r), self.cfg.ray_stride):\n",
    "            x = int(x0 + d*c); y = int(y0 + d*s)\n",
    "            if not (0 <= x < W and 0 <= y < H):\n",
    "                return None, d\n",
    "            if self.wall_mask[x, y]:\n",
    "                return (x, y), d\n",
    "        return None, int(max_r)\n",
    "\n",
    "    def random_free_xy(self, rng: np.random.Generator):\n",
    "        \"\"\"Return a random FREE pixel (x,y) as float (center of pixel).\n",
    "        Args:\n",
    "            rng: np.random.Generator instance\n",
    "        Returns:\n",
    "            (x,y): coordinates of a FREE pixel (float)\n",
    "        \"\"\"\n",
    "        idx = rng.integers(0, self.free_coords.shape[0])\n",
    "        x, y = self.free_coords[idx]\n",
    "        return float(x), float(y)\n",
    "\n",
    "    def sample_free_pixels(self, rng: np.random.Generator, n: int, replace: bool = True):\n",
    "        \"\"\"Sample n FREE pixels (x,y) as integers.\n",
    "        Args:\n",
    "            rng: np.random.Generator instance\n",
    "            n: number of pixels to sample\n",
    "            replace: whether to sample with replacement\n",
    "        Returns:\n",
    "            (n,2) array of FREE pixel coordinates (int32)\n",
    "        \"\"\"\n",
    "        total = self.free_coords.shape[0]\n",
    "        replace = (n > total) or replace\n",
    "        idx = rng.choice(total, size=n, replace=replace)\n",
    "        return self.free_coords[idx].copy()  # (n,2) int32\n",
    "\n",
    "    def nearest_free_to(self, x_c: float, y_c: float):\n",
    "        \"\"\"Nearest FREE pixel to a given (x_c,y_c).\n",
    "        Args:\n",
    "            x_c: x coordinate (float)\n",
    "            y_c: y coordinate (float)\n",
    "        Returns:\n",
    "            (x,y): coordinates of the nearest FREE pixel (float)\n",
    "        \"\"\"\n",
    "        dx = self.free_coords[:,0] - x_c\n",
    "        dy = self.free_coords[:,1] - y_c\n",
    "        j = np.argmin(dx*dx + dy*dy)\n",
    "        fx, fy = self.free_coords[j]\n",
    "        return float(fx), float(fy)\n",
    "\n",
    "# --- LiDAR (GT scan) ---\n",
    "class Lidar:\n",
    "    def __init__(self, cfg: Config, world_map: Map2D):\n",
    "        self.cfg = cfg; self.map = world_map\n",
    "\n",
    "    def scan(self, pose_xyth: tuple, rng: np.random.Generator) -> tuple:\n",
    "        \"\"\"Simulate a LiDAR scan from given pose (x,y,theta).\n",
    "        Args:\n",
    "            pose_xyth: (x,y,theta) pose in world coordinates (float)\n",
    "            rng: np.random.Generator instance\n",
    "        Returns:\n",
    "            (Z_r, Z_phi): range and bearing measurements (numpy arrays)\n",
    "        \"\"\"\n",
    "        x, y, th = map(float, pose_xyth)\n",
    "        fov = np.deg2rad(self.cfg.fov_deg)\n",
    "        bearings = np.linspace(-fov/2, fov/2, self.cfg.num_beams, endpoint=False)\n",
    "        Z_r = np.empty(self.cfg.num_beams, dtype=np.float32)\n",
    "        Z_phi = np.empty_like(Z_r)\n",
    "        for i, rel in enumerate(bearings):\n",
    "            a = wrap_angle(th + rel)\n",
    "            _, dist = self.map.cast_beam_fast((x, y), a, self.cfg.max_range_px)\n",
    "            Z_r[i] = dist + rng.normal(0.0, 1.5)  # mild sensor noise\n",
    "            Z_phi[i] = rel\n",
    "        return Z_r, Z_phi\n",
    "\n",
    "# --- bilinear sampler ---\n",
    "def bilinear_sample(field: np.ndarray, xs: np.ndarray, ys: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Bilinear sampling of a 2D field at given (x,y) coordinates.\n",
    "    Args:\n",
    "        field: 2D array to sample from\n",
    "        xs: x coordinates (float)\n",
    "        ys: y coordinates (float)\n",
    "    Returns:\n",
    "        2D array of sampled values (float)\n",
    "    \"\"\"\n",
    "    W, H = field.shape\n",
    "    xs = np.clip(xs, 0.0, W-1.001); ys = np.clip(ys, 0.0, H-1.001)\n",
    "    x0 = np.floor(xs).astype(np.int32); y0 = np.floor(ys).astype(np.int32)\n",
    "    x1 = np.minimum(x0+1, W-1); y1 = np.minimum(y0+1, H-1)\n",
    "    wx = xs - x0; wy = ys - y0\n",
    "    v00 = field[x0, y0]; v10 = field[x1, y0]\n",
    "    v01 = field[x0, y1]; v11 = field[x1, y1]\n",
    "    return (v00*(1-wx)*(1-wy) + v10*wx*(1-wy) + v01*(1-wx)*wy + v11*wx*wy)\n",
    "\n",
    "# --- Particle Filter (MCL, particles at pixels) ---\n",
    "class ParticleFilterMCL:\n",
    "    def __init__(self, cfg: Config, world_map: Map2D, rng):\n",
    "        self.cfg, self.map, self.rng = cfg, world_map, rng\n",
    "        self.N = cfg.Np\n",
    "        self.x = np.zeros((self.N, 3), dtype=np.float32)   # (x,y,theta)\n",
    "        self.w = np.ones(self.N, dtype=np.float32) / self.N\n",
    "        self.global_initialize()\n",
    "\n",
    "    def _snap_to_pixel(self):\n",
    "        \"\"\"Round positions to nearest pixel center (integer coordinates).\"\"\"\n",
    "        self.x[:,0] = np.rint(self.x[:,0])\n",
    "        self.x[:,1] = np.rint(self.x[:,1])\n",
    "\n",
    "    def _repair_outside_or_wall(self, mask_bad: np.ndarray):\n",
    "        \"\"\"Reseed bad particles to random FREE pixels (keeps orientation).\n",
    "        Args:\n",
    "            mask_bad: (N,) boolean array, True for bad particles\n",
    "        \"\"\"\n",
    "        if not np.any(mask_bad): return\n",
    "        repl = self.map.sample_free_pixels(self.rng, int(mask_bad.sum()), replace=True)\n",
    "        self.x[mask_bad, 0] = repl[:,0]\n",
    "        self.x[mask_bad, 1] = repl[:,1]\n",
    "\n",
    "    def global_initialize(self):\n",
    "        # Sample FREE pixels (without replacement if possible)\n",
    "        coords = self.map.sample_free_pixels(self.rng, self.N, replace=False)\n",
    "        thetas = self.rng.uniform(-np.pi, np.pi, size=self.N).astype(np.float32)\n",
    "        self.x[:,0] = coords[:,0]; self.x[:,1] = coords[:,1]; self.x[:,2] = thetas\n",
    "        self.w.fill(1.0/self.N)\n",
    "\n",
    "    def predict(self, u: tuple):\n",
    "        \"\"\"Motion update (prediction) step with odometry-like command u = (dr1, dt, dr2).\n",
    "        Args:\n",
    "            u: (dr1, dt, dr2) odometry command (float)\n",
    "        \"\"\"\n",
    "        a1,a2,a3,a4 = self.cfg.a1, self.cfg.a2, self.cfg.a3, self.cfg.a4\n",
    "        dr1, dt, dr2 = float(u[0]), float(u[1]), float(u[2])\n",
    "        var_dr1 = a1*abs(dr1) + a2*abs(dt)\n",
    "        var_dt  = a3*abs(dt)  + a4*(abs(dr1) + abs(dr2))\n",
    "        var_dr2 = a1*abs(dr2) + a2*abs(dt)\n",
    "\n",
    "        n1 = self.rng.normal(0.0, np.sqrt(var_dr1), size=self.N)\n",
    "        n2 = self.rng.normal(0.0, np.sqrt(var_dt),  size=self.N)\n",
    "        n3 = self.rng.normal(0.0, np.sqrt(var_dr2), size=self.N)\n",
    "\n",
    "        dr1_s, dt_s, dr2_s = dr1 + n1, dt + n2, dr2 + n3\n",
    "        th = self.x[:, 2]\n",
    "        self.x[:, 0] += dt_s*np.cos(th + dr1_s)\n",
    "        self.x[:, 1] += dt_s*np.sin(th + dr1_s)\n",
    "        self.x[:, 2]  = np.array([wrap_angle(t + r1 + r2) for t, r1, r2 in zip(th, dr1_s, dr2_s)], dtype=np.float32)\n",
    "\n",
    "        # Snap to pixel grid\n",
    "        self._snap_to_pixel()\n",
    "\n",
    "        # Keep inside FREE pixels (vectorized)\n",
    "        W,H = self.map.wall_mask.shape\n",
    "        xi = self.x[:,0].astype(np.int32); yi = self.x[:,1].astype(np.int32)\n",
    "        inside = (xi >= 0) & (xi < W) & (yi >= 0) & (yi < H)\n",
    "        ok = np.zeros(self.N, dtype=bool)\n",
    "        ok[inside] = self.map.free_mask[xi[inside], yi[inside]]\n",
    "        bad = ~ok\n",
    "        self._repair_outside_or_wall(bad)\n",
    "\n",
    "    def update(self, Z_r: np.ndarray, Z_phi: np.ndarray):\n",
    "        \"\"\"Measurement update (correction) step with LiDAR scan Z = (Z_r, Z_phi).\n",
    "        Args:\n",
    "            Z_r: (M,) array of range measurements (float)\n",
    "            Z_phi: (M,) array of bearing measurements (float)\n",
    "        \"\"\"\n",
    "        if Z_r.size == 0: return\n",
    "        step = max(1, int(self.cfg.beam_subsample_step))\n",
    "        r = Z_r[::step].astype(np.float32)\n",
    "        phi = Z_phi[::step].astype(np.float32)\n",
    "        if self.cfg.use_only_hit_beams:\n",
    "            mask = r < (self.cfg.max_range_px - 1.5*self.cfg.ray_stride)\n",
    "            if np.any(mask):\n",
    "                r = r[mask]; phi = phi[mask]\n",
    "            else:\n",
    "                return\n",
    "        th = self.x[:, 2][:, None]                 # (N,1)\n",
    "        ang = th + phi[None, :]                    # (N,M)\n",
    "        ex = self.x[:, 0][:, None] + r[None, :]*np.cos(ang)\n",
    "        ey = self.x[:, 1][:, None] + r[None, :]*np.sin(ang)\n",
    "\n",
    "        d = bilinear_sample(self.map.dist_field, ex, ey)  # (N,M)\n",
    "        inv_2sig2 = 1.0 / (2.0 * self.cfg.sigma_hit * self.cfg.sigma_hit)\n",
    "        log_lik = -np.mean(d*d, axis=1) * inv_2sig2\n",
    "\n",
    "        logw = np.log(self.w + 1e-12) + log_lik\n",
    "        m = np.max(logw)\n",
    "        w = np.exp(logw - m); w /= (np.sum(w) + 1e-12)\n",
    "        self.w = w.astype(np.float32)\n",
    "\n",
    "    def neff(self):\n",
    "        \"\"\"Effective sample size.\"\"\"\n",
    "        return 1.0 / (np.sum(self.w**2) + 1e-12)\n",
    "\n",
    "    def resample_if_needed(self):\n",
    "        if self.neff() < self.cfg.resample_neff_ratio * self.N:\n",
    "            self.systematic_resample()\n",
    "            self.inject_random(int(self.cfg.random_injection_frac * self.N))\n",
    "\n",
    "    def systematic_resample(self):\n",
    "        N = self.N\n",
    "        positions = (self.rng.random() + np.arange(N)) / N\n",
    "        indexes = np.zeros(N, dtype=np.int32)\n",
    "        c = self.w[0]; i = 0\n",
    "        for j in range(N):\n",
    "            u = positions[j]\n",
    "            while u > c and i < N-1:\n",
    "                i += 1; c += self.w[i]\n",
    "            indexes[j] = i\n",
    "        self.x = self.x[indexes].copy()\n",
    "        self.w.fill(1.0/N)\n",
    "        # Ensure we remain snapped after resampling\n",
    "        self._snap_to_pixel()\n",
    "\n",
    "    def inject_random(self, k: int):\n",
    "        \"\"\"Inject k random particles (replacing worst k by weight).\n",
    "        Args:\n",
    "            k: number of particles to inject\n",
    "        \"\"\"\n",
    "        if k <= 0: return\n",
    "        repl = self.map.sample_free_pixels(self.rng, k, replace=True)\n",
    "        idx = self.rng.choice(self.N, size=k, replace=False)\n",
    "        self.x[idx, 0] = repl[:,0]; self.x[idx, 1] = repl[:,1]\n",
    "        self.x[idx, 2] = self.rng.uniform(-np.pi, np.pi, size=k).astype(np.float32)\n",
    "\n",
    "    def estimate_topk(self, frac: float=0.2) -> np.ndarray:\n",
    "        \"\"\"Estimate pose from top-K particles by weight.\n",
    "        Args:\n",
    "            frac: fraction of particles to use (0 < frac <= 1)\n",
    "        Returns:\n",
    "            (3,) estimated pose (x,y,theta)\n",
    "        \"\"\"\n",
    "        k = max(1, int(frac * self.N))\n",
    "        idx = np.argsort(self.w)[-k:]\n",
    "        w = self.w[idx]; w = w / (np.sum(w) + 1e-12)\n",
    "        x = float(np.sum(w * self.x[idx,0]))\n",
    "        y = float(np.sum(w * self.x[idx,1]))\n",
    "        th = float(circ_mean_thetas(self.x[idx,2], w))\n",
    "        return np.array([x,y,th], dtype=np.float32)\n",
    "\n",
    "# --- App ---\n",
    "class App:\n",
    "    def __init__(self, cfg: Config):\n",
    "        pygame.init()\n",
    "        self.cfg = cfg\n",
    "        self.screen = pygame.display.set_mode(cfg.window_size)\n",
    "        pygame.display.set_caption(\"GT (left) | MCL (right)\")\n",
    "        self.clock  = pygame.time.Clock()\n",
    "        self.font   = pygame.font.SysFont(None, 18)\n",
    "        self.rng    = np.random.default_rng(cfg.seed)\n",
    "\n",
    "        self.left  = Panel(self.screen, (0, 0, cfg.panel_w, cfg.panel_h))\n",
    "        self.right = Panel(self.screen, (cfg.panel_w, 0, cfg.panel_w, cfg.panel_h))\n",
    "\n",
    "        self.map   = Map2D(cfg)\n",
    "        self.lidar = Lidar(cfg, self.map)\n",
    "\n",
    "        # --- Start GT at the center (nearest FREE pixel) ---\n",
    "        cx, cy = cfg.panel_w//2, cfg.panel_h//2\n",
    "        gx, gy = self.map.nearest_free_to(cx, cy)\n",
    "        self.gt_pose = np.array([gx, gy, 0.0], dtype=np.float32)\n",
    "        self.gt_traj = [self.gt_pose.copy()]\n",
    "\n",
    "        self.pf = ParticleFilterMCL(cfg, self.map, self.rng)\n",
    "        self.frozen = True  # start frozen\n",
    "        rx, ry = self.map.random_free_xy(self.rng)\n",
    "        rth = self.rng.uniform(-np.pi, np.pi)\n",
    "        self.est_pose = np.array([rx, ry, rth], dtype=np.float32)\n",
    "\n",
    "        self.beam_angle = 0.0\n",
    "        self.beam_speed = 2*np.pi*10\n",
    "        self.SCAN_EVENT = pygame.USEREVENT + 1\n",
    "        pygame.time.set_timer(self.SCAN_EVENT, cfg.scan_ms)\n",
    "\n",
    "        self.last_scan = (np.array([], dtype=np.float32), np.array([], dtype=np.float32))\n",
    "        self.draw_particles = cfg.draw_particles\n",
    "\n",
    "    @staticmethod\n",
    "    def motion_model_odometry(u: tuple, x_prev: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply odometry-style motion model to pose x_prev with command u = (dr1, dt, dr2).\n",
    "        Args:\n",
    "            u: (dr1, dt, dr2) odometry command (float)\n",
    "            x_prev: (3,) previous pose (x,y,theta)\n",
    "        Returns:\n",
    "            (3,) new pose (x,y,theta)\n",
    "        \"\"\"\n",
    "        dr1, dt, dr2 = u\n",
    "        x_new = x_prev[0] + dt*np.cos(x_prev[2] + dr1)\n",
    "        y_new = x_prev[1] + dt*np.sin(x_prev[2] + dr1)\n",
    "        th_new= wrap_angle(x_prev[2] + dr1 + dr2)\n",
    "        return np.array([x_new, y_new, th_new], dtype=np.float32)\n",
    "\n",
    "    def step_motion(self, cmd: tuple):\n",
    "        \"\"\"\n",
    "        Apply motion model to ground truth pose and predict particle states.\n",
    "        \"\"\"\n",
    "        self.frozen = False\n",
    "        self.gt_pose = self.motion_model_odometry(cmd, self.gt_pose)\n",
    "        self.gt_traj.append(self.gt_pose.copy()); self.gt_traj = self.gt_traj[-300:]\n",
    "        self.pf.predict(cmd)\n",
    "\n",
    "    def step_scan(self):\n",
    "        \"\"\"\n",
    "        Perform a LiDAR scan and update the particle filter.\n",
    "        \"\"\"\n",
    "        Z_r, Z_phi = self.lidar.scan(self.gt_pose, self.rng)\n",
    "        self.last_scan = (Z_r, Z_phi)\n",
    "        if self.frozen:\n",
    "            return\n",
    "        self.pf.update(Z_r, Z_phi)\n",
    "        self.pf.resample_if_needed()\n",
    "        est_now = self.pf.estimate_topk(self.cfg.top_k_frac)\n",
    "        self.est_pose = blend_pose(self.est_pose, est_now, self.cfg.smooth_alpha)\n",
    "\n",
    "    # --- drawing ---\n",
    "    def draw_left(self):\n",
    "        self.left.clear((30,30,30))\n",
    "        self.left.blit(self.map.surface, (0,0))\n",
    "        # GT traj\n",
    "        for i in range(1, len(self.gt_traj)):\n",
    "            p0 = i2(self.gt_traj[i-1][:2]); p1 = i2(self.gt_traj[i][:2])\n",
    "            pygame.draw.line(self.screen, (0,150,255),\n",
    "                             (self.left.ox+p0[0], p0[1]), (self.left.ox+p1[0], p1[1]), 2)\n",
    "        # GT robot\n",
    "        gx,gy,gth = map(float, self.gt_pose)\n",
    "        pts = [\n",
    "            (gx + 15*np.cos(gth),     gy + 15*np.sin(gth)),\n",
    "            (gx + 10*np.cos(gth+2.5), gy + 10*np.sin(gth+2.5)),\n",
    "            (gx + 10*np.cos(gth-2.5), gy + 10*np.sin(gth-2.5))\n",
    "        ]\n",
    "        self.left.polygon((0,150,255), pts)\n",
    "        # rotating beam (eye candy)\n",
    "        bx,by = i2(self.gt_pose[:2])\n",
    "        hit, dist = self.map.cast_beam_fast(self.gt_pose[:2], self.beam_angle, self.cfg.max_range_px)\n",
    "        ex,ey = (hit if hit else (int(bx + self.cfg.max_range_px*np.cos(self.beam_angle)),\n",
    "                                  int(by + self.cfg.max_range_px*np.sin(self.beam_angle))))\n",
    "        pygame.draw.line(self.screen, (255,0,0), (self.left.ox+bx, by), (self.left.ox+ex, ey), 2)\n",
    "\n",
    "    def draw_right(self):\n",
    "        self.right.clear((230,230,230))\n",
    "        self.right.blit(self.map.surface, (0,0))\n",
    "        # Particles (dense red dots at pixel centers)\n",
    "        if self.draw_particles:\n",
    "            if self.cfg.draw_top_k_particles is None:\n",
    "                idx_to_draw = np.arange(self.pf.N)\n",
    "            else:\n",
    "                idx_to_draw = np.argsort(self.pf.w)[-self.cfg.draw_top_k_particles:]\n",
    "            for i in idx_to_draw:\n",
    "                x,y,_ = self.pf.x[i]\n",
    "                self.right.circle(self.cfg.particle_color, (x,y), 1)\n",
    "        # Estimated pose as green dot + heading tick (no traj)\n",
    "        if self.est_pose is not None:\n",
    "            ex,ey,eth = map(float, self.est_pose)\n",
    "            self.right.circle((0,180,120), (ex,ey), 5)\n",
    "            hx = ex + 14*np.cos(eth); hy = ey + 14*np.sin(eth)\n",
    "            pygame.draw.line(self.screen, (0,180,120),\n",
    "                             (self.right.ox+int(ex), int(ey)),\n",
    "                             (self.right.ox+int(hx), int(hy)), 2)\n",
    "        # HUD\n",
    "        fps = self.clock.get_fps()\n",
    "        neff = self.pf.neff()\n",
    "        step = self.cfg.beam_subsample_step\n",
    "        hud = (f\"FPS:{fps:4.1f} | N:{self.cfg.Np} | Neff:{neff:5.1f} \"\n",
    "               f\"| Beams:{self.cfg.num_beams}/{step} | œÉ_hit={self.cfg.sigma_hit:.1f}px \"\n",
    "               f\"| TopK:{int(self.cfg.top_k_frac*self.cfg.Np)}\")\n",
    "        self.right.text(self.font, hud, (10,10,10), (10,0))\n",
    "\n",
    "    # --- main loop ---\n",
    "    def run(self):\n",
    "        running = True\n",
    "        while running:\n",
    "            dt = self.clock.tick(60) / 1000.0\n",
    "            self.beam_angle = (self.beam_angle + self.beam_speed * dt) % (2*np.pi)\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    running = False\n",
    "                elif ev.type == pygame.KEYDOWN:\n",
    "                    if   ev.key == pygame.K_UP:\n",
    "                        cmd = np.array([0.0, self.cfg.trans_step, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_LEFT:\n",
    "                        cmd = np.array([-self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_RIGHT:\n",
    "                        cmd = np.array([ self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_g:\n",
    "                        self.pf.global_initialize()\n",
    "                        self.frozen = True\n",
    "                        rx, ry = self.map.random_free_xy(self.rng)\n",
    "                        rth    = self.rng.uniform(-np.pi, np.pi)\n",
    "                        self.est_pose = np.array([rx, ry, rth], dtype=np.float32)\n",
    "                        cmd=None\n",
    "                    elif ev.key == pygame.K_k:\n",
    "                        # Kidnap: teleport GT to center-nearest free again\n",
    "                        cx, cy = self.cfg.panel_w//2, self.cfg.panel_h//2\n",
    "                        gx, gy = self.map.nearest_free_to(cx, cy)\n",
    "                        self.gt_pose = np.array([gx, gy, self.rng.uniform(-np.pi,np.pi)], dtype=np.float32)\n",
    "                        self.gt_traj.clear(); self.est_pose = None; cmd=None\n",
    "                    elif ev.key == pygame.K_COMMA:\n",
    "                        self.cfg.beam_subsample_step = max(1, self.cfg.beam_subsample_step-1); cmd=None\n",
    "                    elif ev.key == pygame.K_PERIOD:\n",
    "                        self.cfg.beam_subsample_step = min(12, self.cfg.beam_subsample_step+1); cmd=None\n",
    "                    elif ev.key == pygame.K_p:\n",
    "                        self.draw_particles = not self.draw_particles; cmd=None\n",
    "                    else:\n",
    "                        cmd = None\n",
    "                    if cmd is not None:\n",
    "                        self.step_motion(cmd)\n",
    "                elif ev.type == self.SCAN_EVENT:\n",
    "                    self.step_scan()\n",
    "\n",
    "            self.draw_left()\n",
    "            self.draw_right()\n",
    "            pygame.display.flip()\n",
    "\n",
    "        pygame.quit(); sys.exit()\n",
    "\n",
    "# --- Run ---\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    App(cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30710436",
   "metadata": {},
   "source": [
    "#### </> <span style=\"color:#a4d4a3\">**What we implemented beyond the textbook MCL**</span>\n",
    "\n",
    "- <span style=\"color:#00703c\">**Likelihood-field sensor model** (endpoint distance):</span>  Instead of the full probabilistic <span style=\"color:#ffa500\">**beam model**</span>  (hit/short/random/max), we precompute a <span style=\"color:#ffa500\">**distance field**</span>  of the occupancy map and score each particle by how <span style=\"color:#ffa500\">**close the beam endpoints**</span>  fall to walls. This yields a fast, stable approximation.\n",
    "\n",
    "    - `sigma_hit = 8.0:` Std-dev (pixels) in the likelihood $w$, where $d$ is the distance from each predicted beam <span style=\"color:#ffa500\">**endpoint**</span> to the nearest obstacle (from the distance field), averaged over used beams. \n",
    "    - ‚Üë `sigma_hit` ‚Üí gentler updates, smoother but slower convergence.  \n",
    "    - ‚Üì `sigma_hit` ‚Üí sharper updates, faster lock-on but more jitter/collapse if map/scan are noisy.  \n",
    "\n",
    "- <span style=\"color:#00703c\">**Beam subsampling & ‚Äúhit-only‚Äù beams:**</span> For speed and stability, we can use every $s$-th beam and optionally <span style=\"color:#ffa500\">**ignore max-range**</span> beams (which are weakly informative in the likelihood-field model).\n",
    "\n",
    "    - `use_only_hit_beams = True:` Use only beams that <span style=\"color:#ffa500\">**hit**</span> walls (ignore max-range ‚Äúno-hit‚Äù beams). Stabilizes weighting in structured maps. Set to `False` only in very open spaces and ideally extend the sensor model (random/short components).\n",
    "\n",
    "- <span style=\"color:#00703c\">**Pixel-quantized particles:**</span> In theory $x,y$ are continuous. Here, each particle‚Äôs $(x,y)$ is <span style=\"color:#ffa500\">**snapped to integer pixel centers**</span>. This makes visualization crisp, simplifies map collision checks, and avoids particles drifting ‚Äúbetween‚Äù cells. We still keep $\\theta$ continuous.\n",
    "\n",
    "    - `Np = 1000:` number of particles. More particles improve coverage but also improve computational demands.  \n",
    "\n",
    "- <span style=\"color:#00703c\">**Top-K read-out + EMA smoothing:**</span> To avoid mean-of-modes jumps, we compute the estimate from the <span style=\"color:#ffa500\">**top-K% highest-weight**</span> particles and then apply a light <span style=\"color:#ffa500\">**exponential moving average**</span> (smoothing only affects the visualization/read-out, not the filter).\n",
    "\n",
    "    - `top_k_frac = 0.8:` compute pose from the <span style=\"color:#ffa500\">**top K%**</span> particles by weight. With large `Np`, you can use <span style=\"color:#ffa500\">**smaller K**</span> (e.g., 5‚Äì10%).\n",
    "\n",
    "    - `smooth_alpha = 0.25:` EMA smoothing of the pose estimate. \n",
    "    - ‚Üí `0:` very smooth/slow. \n",
    "    - ‚Üí `1:` no smoothing/fast, possibly jittery.  \n",
    "    - Typical <span style=\"color:#ffa500\">`0.2-0.4`</span>.\n",
    "\n",
    "- <span style=\"color:#00703c\">**Systematic resampling + random injection:**</span> We trigger resampling using the <span style=\"color:#ffa500\">**effective sample size**</span>, and after resampling we <span style=\"color:#ffa500\">**inject a small fraction of random free-space particles**</span> to combat impoverishment and recover from kidnapping.\n",
    "\n",
    "    - `random_injection_frac = 0.01:` fraction of particles replaced by random free-space samples <span style=\"color:#ffa500\">**after**</span> resampling (anti-impoverishment, helps kidnapped-robot).  \n",
    "    Higher ‚Üí better recovery, slower convergence; lower ‚Üí crisper but less robust.  \n",
    "    Typical **1‚Äì5%**. With 100k, 2.5% = **2 500** new particles per resample (non-trivial cost).\n",
    "\n",
    "    - `resample_neff_ratio = 0.8:` resample when $N_\\text{eff}/N_p < 0.5$, with $N_\\text{eff}=1/\\sum w_i^2$.  \n",
    "    - Higher `(‚âà0.7):` resample more ‚Üí less degeneracy, more noise.  \n",
    "    - Lower `(‚âà0.3):` resample less ‚Üí more diversity, risk of weight collapse.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0fc07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef8824",
   "metadata": {},
   "source": [
    "#### ‚úîÔ∏è <span style=\"color:#a4d4a3\">Summary</span>\n",
    "\n",
    "- Particle filters are <span style=\"color:#ffa500\">**non-parametric, recursive Bayes filters**</span>.\n",
    "\n",
    "- Posterior is represented by a <span style=\"color:#ffa500\">**set of weighted samples**</span>.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Propose**</span> to draw the samples.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Weight**</span> to account for the differences between the <span style=\"color:#ffa500\">**proposal**</span> and the <span style=\"color:#ffa500\">**target**</span>.\n",
    "\n",
    "- Work well in <span style=\"color:#ffa500\">**low-dimensional**</span> spaces.\n",
    "\n",
    "- The <span style=\"color:#00703c\">**Monte Carlo Localization**</span> is an instance of the <span style=\"color:#00703c\">**Particle Filter**</span> where:\n",
    "\n",
    "    - Particles are <span style=\"color:#ffa500\">**propagated**</span> according to the <span style=\"color:#ffa500\">**motion model**</span>.\n",
    "\n",
    "    - They are <span style=\"color:#ffa500\">**weighted**</span> according to the <span style=\"color:#ffa500\">**likelihood**</span> of the observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d0940",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddfb38",
   "metadata": {},
   "source": [
    "### üìö <span style=\"color:#a4d4a3\">**Reading Material**</span>\n",
    "\n",
    "**Particle Filter**\n",
    "- Thrun et al.: *\"Probabilistic Robotics\"*, **Chapter 3**\n",
    "\n",
    "**Monte Carlo Localization**\n",
    "- Thrun et al.: *\"Probabilistic Robotics\"*, **Chapter 8.3**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
