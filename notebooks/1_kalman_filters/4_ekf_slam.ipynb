{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff6feff",
   "metadata": {},
   "source": [
    "## <span style=\"color:#a4d4a3\">**Extended Kalman Filter (EKF) for SLAM**</span>\n",
    "\n",
    "\n",
    "### üìñ <span style=\"color:#a4d4a3\">**Definition of the SLAM Problem**</span>\n",
    "\n",
    "<span style=\"color:#00703c\">**Given:**</span>\n",
    "\n",
    "- The robot's controls: $\\quad u_{1:T} = \\{u_1, u_2, u_3, \\dots, u_T\\} $\n",
    "- Observations: $\\quad z_{1:T} = \\{z_1, z_2, z_3, \\dots, z_T\\} $\n",
    "\n",
    "<span style=\"color:#00703c\">**Wanted:**</span>\n",
    "\n",
    "- A map of the environment: $\\quad m $\n",
    "- The path of the robot: $\\quad x_{0:T} = \\{x_0, x_1, x_2, \\dots, x_T\\} $\n",
    "\n",
    "Typically, we aim to solve the <span style=\"color:#ffa500\">**online SLAM problem**</span>, focusing specifically on estimating the <span style=\"color:#ffa500\">**current state**</span> of the robot and <span style=\"color:#ffa500\">**landmarks**</span> at each timestep.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71400c1",
   "metadata": {},
   "source": [
    "\n",
    "### üß≠ <span style=\"color:#a4d4a3\">**EKF for Online SLAM**</span>\n",
    "\n",
    "We consider here the Kalman Filter as a solution to the online SLAM problem, representing the <span style=\"color:#ffa500\">**belief**</span> as:\n",
    "\n",
    "$$\n",
    "p(x_t, m \\mid z_{1:t}, u_{1:t})\n",
    "$$\n",
    "\n",
    "Our goal is to estimate the robot's pose and the locations of the landmarks in the environment <span style=\"color:#ffa500\">**simultaneously**</span>.\n",
    "\n",
    "<span style=\"color:#00703c\">**Assumption:**</span>\n",
    "\n",
    "- Known correspondences (data associations between landmarks and observations are known).\n",
    "\n",
    "We define the state space for a robot moving in a 2D plane, observing $ N $ landmarks, as:\n",
    "\n",
    "$$\n",
    "x_t = (\\underbrace{x, y, \\theta}_{robot\\,state}, \\underbrace{m_{1,x}, m_{1,y}}_{landmark\\,1}, \\underbrace{m_{2,x}, m_{2,y}}_{landmark\\,2}, \\dots, \\underbrace{m_{N,x}, m_{N,y}}_{landmark\\,N})^T\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b23afc",
   "metadata": {},
   "source": [
    "\n",
    "#### üìç <span style=\"color:#a4d4a3\">EKF SLAM: State Representation</span>\n",
    "\n",
    "We have a map with $ N $ landmarks, resulting in a state vector of dimension $ 3 + 2N $.\n",
    "\n",
    "The belief (state estimate and uncertainty) is represented by:\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Mean vector**</span> $ \\mu $ and <span style=\"color:#ffa500\">**covariance matrix**</span> $ \\Sigma $:\n",
    "$$\n",
    "\\mu = \n",
    "\\begin{pmatrix}\n",
    "\\color{#FFD93D} x \\\\\n",
    "\\color{#FFD93D} y \\\\\n",
    "\\color{#FFD93D} \\theta \\\\\n",
    "\\color{#4D96FF} m_{1,x} \\\\ \n",
    "\\color{#4D96FF} m_{1,y} \\\\\n",
    "\\color{#4D96FF} \\vdots \\\\\n",
    "\\color{#4D96FF} m_{N,x} \\\\\n",
    "\\color{#4D96FF} m_{N,y}\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\quad\\quad\n",
    "\n",
    "\\Sigma =\n",
    "\\left(\n",
    "\\begin{array}{ccc:ccccc}\n",
    "\\color{#FFD93D} \\sigma_{x,x} & \\color{#FFD93D} \\sigma_{x,y} & \\color{#FFD93D} \\sigma_{x,\\theta} & \\color{#6BCB77} \\sigma_{x,m_{1,x}} & \\color{#6BCB77} \\sigma_{x,m_{1,y}} & \\color{#6BCB77} \\cdots & \\color{#6BCB77} \\sigma_{x,m_{N,x}} & \\color{#6BCB77} \\sigma_{x,m_{N,y}} \\\\\n",
    "\\color{#FFD93D} \\sigma_{y,x} & \\color{#FFD93D} \\sigma_{y,y} & \\color{#FFD93D} \\sigma_{y,\\theta} & \\color{#6BCB77} \\sigma_{y,m_{1,x}} & \\color{#6BCB77} \\sigma_{y,m_{1,y}} & \\color{#6BCB77} \\cdots & \\color{#6BCB77} \\sigma_{y,m_{N,x}} & \\color{#6BCB77} \\sigma_{y,m_{N,y}} \\\\\n",
    "\\color{#FFD93D} \\sigma_{\\theta,x} & \\color{#FFD93D} \\sigma_{\\theta,y} & \\color{#FFD93D} \\sigma_{\\theta,\\theta} & \\color{#6BCB77} \\sigma_{\\theta,m_{1,x}} & \\color{#6BCB77} \\sigma_{\\theta,m_{1,y}} & \\color{#6BCB77} \\cdots & \\color{#6BCB77} \\sigma_{\\theta,m_{N,x}} & \\color{#6BCB77} \\sigma_{\\theta,m_{N,y}} \\\\\n",
    "\\hdashline\n",
    "\\color{#6BCB77} \\sigma_{m_{1,x},x} & \\color{#6BCB77} \\sigma_{m_{1,x},y} & \\color{#6BCB77} \\sigma_{m_{1,x},\\theta} & \\color{#4D96FF} \\sigma_{m_{1,x},m_{1,x}} & \\color{#4D96FF} \\sigma_{m_{1,x},m_{1,y}} & \\color{#4D96FF} \\cdots & \\color{#4D96FF} \\sigma_{m_{1,x},m_{N,x}} & \\color{#4D96FF} \\sigma_{m_{1,x},m_{N,y}} \\\\\n",
    "\\color{#6BCB77} \\sigma_{m_{1,y},x} & \\color{#6BCB77} \\sigma_{m_{1,y},y} & \\color{#6BCB77} \\sigma_{m_{1,y},\\theta} & \\color{#4D96FF} \\sigma_{m_{1,y},m_{1,x}} & \\color{#4D96FF} \\sigma_{m_{1,y},m_{1,y}} & \\color{#4D96FF} \\cdots & \\color{#4D96FF} \\sigma_{m_{1,y},m_{N,x}} & \\color{#4D96FF} \\sigma_{m_{1,y},m_{N,y}} \\\\\n",
    "\\color{#6BCB77} \\vdots & \\color{#6BCB77} \\vdots & \\color{#6BCB77} \\vdots & \\color{#4D96FF} \\vdots & \\color{#4D96FF} \\vdots & \\color{#4D96FF} \\ddots & \\color{#4D96FF} \\vdots & \\color{#4D96FF} \\vdots \\\\\n",
    "\\color{#6BCB77} \\sigma_{m_{N,x},x} & \\color{#6BCB77} \\sigma_{m_{N,x},y} & \\color{#6BCB77} \\sigma_{m_{N,x},\\theta} & \\color{#4D96FF} \\sigma_{m_{N,x},m_{1,x}} & \\color{#4D96FF} \\sigma_{m_{N,x},m_{1,y}} & \\color{#4D96FF} \\cdots & \\color{#4D96FF} \\sigma_{m_{N,x},m_{N,x}} & \\color{#4D96FF} \\sigma_{m_{N,x},m_{N,y}} \\\\\n",
    "\\color{#6BCB77} \\sigma_{m_{N,y},x} & \\color{#6BCB77} \\sigma_{m_{N,y},y} & \\color{#6BCB77} \\sigma_{m_{N,y},\\theta} & \\color{#4D96FF} \\sigma_{m_{N,y},m_{1,x}} & \\color{#4D96FF} \\sigma_{m_{N,y},m_{1,y}} & \\color{#4D96FF} \\cdots & \\color{#4D96FF} \\sigma_{m_{N,y},m_{N,x}} & \\color{#4D96FF} \\sigma_{m_{N,y},m_{N,y}} \\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "In compact notation, the EKF SLAM state and covariance are represented as:\n",
    "$\\quad \\mu = \\begin{pmatrix}\\color{#FFD93D} x \\\\ \\color{#4D96FF} m\\end{pmatrix}\\quad\\quad\\Sigma = \\begin{pmatrix}\\color{#FFD93D} \\Sigma_{xx} & \\color{#6BCB77} \\Sigma_{xm}\\\\\\color{#6BCB77} \\Sigma_{mx} & \\color{#4D96FF} \\Sigma_{mm}\\end{pmatrix}$\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em> In practice, we can start with only the robot's state and dynamically grow the matrix as landmarks are discovered.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35c2ac",
   "metadata": {},
   "source": [
    "\n",
    "#### ‚ôªÔ∏è <span style=\"color:#a4d4a3\">EKF SLAM: Filter Cycle</span>\n",
    "\n",
    "The EKF SLAM algorithm operates in cycles consisting of five steps:\n",
    "\n",
    "```js\n",
    "1. State Prediction \n",
    "2. Observation Prediction \n",
    "3. Measurement \n",
    "4. Data Association \n",
    "5. Update (Correction)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf2ca7",
   "metadata": {},
   "source": [
    "\n",
    "#### üîé <span style=\"color:#a4d4a3\">EKF SLAM: State Prediction</span>\n",
    "\n",
    "In the <span style=\"color:#ffa500\">**prediction step**</span>, only the robot's pose ($x, y, \\theta$) is directly affected by the control inputs $u_t$, while landmark positions remain unchanged.\n",
    "\n",
    "Thus, the covariance update is computationally efficient, with <span style=\"color:#ffa500\">**linear complexity**</span> in the number of landmarks $ N $:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\color{#6BCB77} x_R \\\\ m_1 \\\\ \\vdots \\\\ m_N\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "\\color{#6BCB77}  \\Sigma_{x_Rx_R} & \\color{#6BCB77} \\Sigma_{x_Rm_1} & \\color{#6BCB77} \\dots & \\color{#6BCB77} \\Sigma_{x_Rm_N}\\\\[6pt]\n",
    "\\color{#6BCB77} \\Sigma_{m_1x_R} & \\Sigma_{m_1m_1} & \\dots & \\Sigma_{m_1m_N}\\\\[6pt]\n",
    "\\color{#6BCB77} \\vdots & \\vdots & \\ddots & \\vdots \\\\[6pt]\n",
    "\\color{#6BCB77} \\Sigma_{m_Nx_R} & \\Sigma_{m_Nm_1} & \\dots & \\Sigma_{m_Nm_N}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### üõ†Ô∏è <span style=\"color:#a4d4a3\">EKF SLAM: Update Step</span>\n",
    "\n",
    "In the <span style=\"color:#ffa500\">**update step**</span>, both the robot's pose and landmark positions are updated based on new sensor measurements. Every landmark that the robot observes leads to updates in the state estimate, affecting both the <span style=\"color:#ffa500\">**robot pose**</span> and the <span style=\"color:#ffa500\">**landmark locations**</span>. \n",
    "\n",
    "Unlike the prediction step, this step involves updating the entire covariance matrix due to the correlation between landmarks and the robot pose, resulting in a computational complexity that's <span style=\"color:#ffa500\">**quadratic**</span> in the number of landmarks $ N $:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\color{#6BCB77} x_R \\\\[4pt]\n",
    "\\color{#6BCB77} m_1 \\\\[4pt]\n",
    "\\color{#6BCB77} \\vdots \\\\[4pt]\n",
    "\\color{#6BCB77} m_N\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "\\color{#6BCB77} \\Sigma_{x_Rx_R} & \\color{#6BCB77} \\Sigma_{x_Rm_1} & \\color{#6BCB77} \\dots & \\color{#6BCB77} \\Sigma_{x_Rm_N}\\\\[6pt]\n",
    "\\color{#6BCB77} \\Sigma_{m_1x_R} & \\color{#6BCB77} \\Sigma_{m_1m_1} & \\color{#6BCB77} \\dots & \\color{#6BCB77} \\Sigma_{m_1m_N}\\\\[6pt]\n",
    "\\color{#6BCB77} \\vdots & \\color{#6BCB77} \\vdots & \\color{#6BCB77} \\ddots & \\color{#6BCB77} \\vdots \\\\[6pt]\n",
    "\\color{#6BCB77} \\Sigma_{m_Nx_R} & \\color{#6BCB77} \\Sigma_{m_Nm_1} & \\color{#6BCB77} \\dots & \\color{#6BCB77} \\Sigma_{m_Nm_N}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em> The reason for quadratic complexity is that observing a landmark refines not only that landmark's position but also improves the estimates for the robot pose and other landmarks via correlations encoded in the covariance matrix. </em>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54690a",
   "metadata": {},
   "source": [
    "### üë©‚Äçüíª <span style=\"color:#a4d4a3\">**EKF SLAM: Complete Example +**</span> `Python implementation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113eda59",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">**1. Initialization**</span>\n",
    "\n",
    "\n",
    "- Initially, the robot starts in its <span style=\"color:#ffa500\">**own reference frame**</span>, and the landmarks are <span style=\"color:#ffa500\">**unknown**</span>.\n",
    "- The state vector has dimensions $2N + 3$.\n",
    "\n",
    "$$\n",
    "\\mu_0 = (0, 0, 0, \\dots, 0)^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_0 = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 & 0 & \\dots & 0 \\\\\n",
    "0 & 0 & 0 & 0 & \\dots & 0 \\\\\n",
    "0 & 0 & 0 & 0 & \\dots & 0 \\\\\n",
    "0 & 0 & 0 & \\infty & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & \\dots & \\infty\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e298ad",
   "metadata": {},
   "source": [
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em> In reality, landmarks are initialized as they are first observed, updating and expanding the state representation on-the-fly. </em>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d61dc5",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a4d4a3\">**2. Prediction Step** (Motion Model)</span>\n",
    "\n",
    "<span style=\"color:#ffa500\">**Goal:**</span> Update the robot‚Äôs state based on its motion.\n",
    "\n",
    "Assuming a velocity-based model, the robot's motion in the 2D plane can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x' \\\\ y' \\\\ \\theta'\n",
    "\\end{pmatrix} \n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x \\\\ y \\\\ \\theta\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos(\\theta) - \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "To map this into the full state space ($2N+3$ dimensions), we define an auxiliary matrix $F_x^T$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{pmatrix}\n",
    "x' \\\\ y' \\\\ \\theta' \\\\ \\vdots\n",
    "\\end{pmatrix} \n",
    "&=\n",
    "\\begin{pmatrix}\n",
    "x \\\\ y \\\\ \\theta \\\\ \\vdots\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\\n",
    "0 & 1 & 0 & 0 \\, \\ldots \\, 0 \\\\\n",
    "0 & 0 & 1 & \\underbrace{0 \\, \\ldots \\, 0}_{2\\,N\\,cols} \\\\\n",
    "\\end{pmatrix}^T}_{F_x^T}\n",
    "\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos(\\theta) - \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix} \\\\ \\\\\n",
    "&=\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "x \\\\ y \\\\ \\theta \\\\ \\vdots\n",
    "\\end{pmatrix}\n",
    "+ F_x^T\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos(\\theta) - \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t) \\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix}}_{g(u_t,x_t)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, our <span style=\"color:#ffa500\">**predicted state**</span> is:\n",
    "\n",
    "$$\n",
    "\\bar{\\mu}_t = g(u_t, \\mu_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a1e91",
   "metadata": {},
   "source": [
    "We can define two functions: one for constructing the auxiliary matrix (<span style=\"color:#6BCB77\"><tt>Fx_embed</tt></span>) and another for computing the motion increment (<span style=\"color:#6BCB77\"><tt>motion_increment</tt></span>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Auxiliary matrix ---\n",
    "def Fx_embed(n:int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the auxiliary matrix Fx to embed 3x3 matrices into \n",
    "    the top-left corner of nxn matrices.\n",
    "    Args:\n",
    "    - n (int): size of the full state (robot + landmarks)\n",
    "    Returns:\n",
    "    - Fx (np.ndarray): 3x3 identity matrix embedded in the top-left corner of a 3xn matrix\n",
    "    \"\"\"\n",
    "    Fx = np.zeros((3, n))\n",
    "    Fx[:3,:3] = np.eye(3)\n",
    "    return Fx\n",
    "\n",
    "# --- Incremental motion model ---\n",
    "def motion_increment(theta:float, u:np.ndarray, dt:float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the incremental motion given the current state, control input, and time step.\n",
    "    Args:\n",
    "    - theta (float): current orientation of the robot\n",
    "    - u (np.ndarray): control input (v, w) where v is linear velocity and w is angular velocity\n",
    "    - dt (float): time step \n",
    "    Returns:\n",
    "    - inc (np.ndarray): incremental motion as a numpy array [dx, dy, dtheta]\n",
    "    \"\"\"\n",
    "    v, w = u\n",
    "    # Handle straight line case\n",
    "    if abs(w) < 1e-9:\n",
    "        inc = np.array([\n",
    "            v * dt * np.cos(theta),\n",
    "            v * dt * np.sin(theta),\n",
    "            0.0\n",
    "        ])\n",
    "        return inc\n",
    "    # General case\n",
    "    th2 = theta + w*dt\n",
    "    inc = np.array([\n",
    "        -(v/w)*np.sin(theta) + (v/w)*np.sin(th2),\n",
    "        (v/w)*np.cos(theta) - (v/w)*np.cos(th2),\n",
    "        w*dt\n",
    "    ])\n",
    "    return inc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d8ba7",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">**3. Covariance Prediction** (Motion Model)</span>\n",
    "\n",
    "Next, we update the <span style=\"color:#ffa500\">**covariance matrix**</span> as follows:\n",
    "\n",
    "$$\n",
    "\\bar{\\Sigma}_t = G_t \\Sigma_{t-1} G_t^T + R_t\n",
    "$$\n",
    "\n",
    "Since the motion model $g$ only affects the robot pose, the Jacobian matrix $G_t$ has a particular block structure:\n",
    "\n",
    "$$\n",
    "G_t = \n",
    "\\begin{pmatrix}\n",
    "G_{t}^{x} & 0 \\\\[6pt]\n",
    "0 & I\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- $ G_{t}^{x} $ is the 3√ó3 <span style=\"color:#ffa500\">**Jacobian**</span> of the robot‚Äôs motion model.\n",
    "- $ I $ is the identity matrix (size $2N\\times2N$), indicating landmarks <span style=\"color:#ffa500\">**remain unchanged**</span>.\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Jacobian of the Motion Model:**</span>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G_{t}^{x} \n",
    "&= \n",
    "\\frac{\\partial}{\\partial(x,y,\\theta)^T}\n",
    "\\begin{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\ y \\\\ \\theta\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos(\\theta) - \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix}\n",
    "\\end{bmatrix} \\\\ \\\\ \n",
    "&= I +\n",
    "\\frac{\\partial}{\\partial(x,y,\\theta)^T}\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos(\\theta) - \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix}\\\\ \\\\\n",
    "&= I +\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & -\\frac{v_t}{w_t}\\cos(\\theta) + \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "0 & 0 & -\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}\\\\ \\\\\n",
    "&=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & -\\frac{v_t}{w_t}\\cos(\\theta) + \\frac{v_t}{w_t}\\cos(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "0 & 1 & -\\frac{v_t}{w_t}\\sin(\\theta) + \\frac{v_t}{w_t}\\sin(\\theta + w_t\\Delta t)\\\\[6pt]\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\end{aligned} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2be71d",
   "metadata": {},
   "source": [
    "The inner Jacobian can be implemented as a function like the one below (<span style=\"color:#6BCB77\"><tt>G_inner</tt></span>). Remember that the identity matrix $I$ must be added afterwards (or included directly in the function, depending on your implementation choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aaf5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inner Jacobian of motion model ---\n",
    "def G_inner(theta:float, u:np.ndarray, dt:float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the inner Jacobian of the motion model with respect to the state.\n",
    "    Args:\n",
    "    - theta (float): current orientation of the robot\n",
    "    - u (np.ndarray): control input (v, w) where v is linear velocity and w is angular velocity\n",
    "    - dt (float): time step\n",
    "    Returns:\n",
    "    - J (np.ndarray): 3x3 Jacobian matrix\n",
    "    \"\"\"\n",
    "    v, w = u\n",
    "    J = np.zeros((3,3))\n",
    "    # Handle straight line case\n",
    "    if abs(w) < 1e-9:\n",
    "        J[0,2] = -v*np.sin(theta)*dt\n",
    "        J[1,2] =  v*np.cos(theta)*dt\n",
    "        return J\n",
    "    # General case\n",
    "    th2 = theta + w*dt\n",
    "    J[0,2] = -(v/w)*np.cos(theta) + (v/w)*np.cos(th2)\n",
    "    J[1,2] = -(v/w)*np.sin(theta) + (v/w)*np.sin(th2)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d169eca",
   "metadata": {},
   "source": [
    "Evaluating the Jacobian gives us a concrete expression to be used in the <span style=\"color:#ffa500\">**covariance update**</span>:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{\\Sigma}_t \n",
    "&= G_t \\Sigma_{t-1} G_t^T + R_t\\quad \\\\ \\\\\n",
    "&=\n",
    "\\begin{pmatrix}\n",
    "G_t^x & 0 \\\\\n",
    "0 & I \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\Sigma_{xx} & \\Sigma_{xm} \\\\\n",
    "\\Sigma_{mx} & \\Sigma_{mm}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "(G_t^x)^T & 0 \\\\\n",
    "0 & I \n",
    "\\end{pmatrix}\n",
    "+ R_t \\\\ \\\\\n",
    "&=\n",
    "\\begin{pmatrix}\n",
    "G_{t}^{x}\\Sigma_{xx}(G_{t}^{x})^T & G_{t}^{x}\\Sigma_{xm}\\\\[6pt]\n",
    "\\Sigma_{mx}(G_{t}^{x})^T & \\Sigma_{mm}\n",
    "\\end{pmatrix}\n",
    "+ R_t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can clearly notice which parts change and which do not.\n",
    "- The original uncertainty in the robot's pose $\\Sigma_{xx}$ is updated based on $G_t^x$.\n",
    "- The correlation between the robot's pose and the landmarks $\\Sigma_{xm}, \\Sigma_{mx}$ are also updated based on $G_t^x$.\n",
    "- The landmarks' correlation $\\Sigma_{mm}$ remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8be21",
   "metadata": {},
   "source": [
    "Putting it all together, the covariance update becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Covariance update ---\n",
    "def covariance_update(Sigma_prev:np.ndarray, G_t:np.ndarray, R_t:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Update the covariance matrix using the motion model Jacobian and process noise.\n",
    "    Args:\n",
    "    - Sigma_prev (np.ndarray): previous covariance matrix\n",
    "    - G_t (np.ndarray): motion model Jacobian matrix\n",
    "    - R_t (np.ndarray): process noise covariance matrix\n",
    "    Returns:\n",
    "    - Sigma_new (np.ndarray): updated covariance matrix\n",
    "    \"\"\"\n",
    "    return G_t @ Sigma_prev @ G_t.T + R_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53f539",
   "metadata": {},
   "source": [
    "> üìù <span style=\"color:#0098ff\">**Note**:</span> <em>In practice, it is inefficient to update the entire covariance matrix as one single block. The landmark covariance $\\Sigma_{mm}$ constitutes the largest part and remains unchanged during the prediction step. Updating it unnecessarily results in increased computational complexity. Therefore, implementations commonly exploit the sparse structure to update only relevant sub-blocks, significantly reducing computational burden.</em>\n",
    "\n",
    "Bringing all components together, the mean and covariance prediction can now be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f000fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Angle wrapping (helper function) ---\n",
    "def wrap_angle(a:float) -> float:\n",
    "    \"\"\"\n",
    "    Wrap angle to [-pi, pi)\n",
    "    Args:\n",
    "    - a (float): angle in radians\n",
    "    Returns:\n",
    "    - (float) wrapped angle in radians within [-pi, pi)\n",
    "    \"\"\"\n",
    "    return (a + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "# --- EKF SLAM Prediction Step ---\n",
    "def EKF_SLAM_Prediction(mu_prev:np.ndarray, Sigma_prev:np.ndarray, u_t:np.ndarray, R_x:np.ndarray, dt:float) -> tuple:\n",
    "    \"\"\"\n",
    "    Perform the EKF SLAM prediction step.\n",
    "    Args:\n",
    "    - mu_prev (np.ndarray): previous mean state vector (robot pose + landmarks)\n",
    "    - Sigma_prev (np.ndarray): previous covariance matrix\n",
    "    - u_t (np.ndarray): control input (v, w)\n",
    "    - R_x (np.ndarray): process noise covariance matrix for the robot pose\n",
    "    - dt (float): time step\n",
    "    Returns:\n",
    "    - mu_bar (np.array): predicted mean state vector (robot pose + landmarks)\n",
    "    - Sigma_bar (np.ndarray): predicted covariance matrix\n",
    "    \"\"\"\n",
    "    n = mu_prev.size\n",
    "    Fx = Fx_embed(n)\n",
    "    # Compute motion increment\n",
    "    inc = motion_increment(mu_prev[2], u_t, dt)\n",
    "    # Predict mean\n",
    "    mu_bar = mu_prev.copy()\n",
    "    mu_bar[:3] = mu_prev[:3] + inc\n",
    "    mu_bar[2] = wrap_angle(mu_bar[2])\n",
    "    # Compute covariance\n",
    "    Gt = np.eye(n) + Fx.T @ G_inner(mu_prev[2], u_t, dt) @ Fx\n",
    "    Rt = Fx.T @ R_x @ Fx\n",
    "    # Predict covariance\n",
    "    Sigma_bar = covariance_update(Sigma_prev, Gt, Rt)\n",
    "    return mu_bar, Sigma_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bf33c",
   "metadata": {},
   "source": [
    "With this step, we have completed the prediction cycle of EKF-SLAM. \n",
    "\n",
    "To see it in action, we now apply the above functions to a simple example, demonstrating how the mean and covariance evolve during a circular trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47378ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "# --- Plot utility: 2D covariance ellipse (x,y block) ---\n",
    "def plot_ellipse(ax:plt.Axes, m:np.ndarray, P:np.ndarray, nsig:int = 2, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Draw a nsig-sigma ellipse for the (x,y) marginal of a 3x3 pose covariance.\n",
    "    Args:\n",
    "    - ax (plt.Axes): the axes to draw on.\n",
    "    - m (np.ndarray): (3,) pose mean [x, y, theta]\n",
    "    - P (np.ndarray): (3,3) pose covariance\n",
    "    - nsig (int): number of standard deviations for the ellipse (default 2)\n",
    "    - kwargs: additional keyword arguments passed to Ellipse patch\n",
    "    \"\"\"\n",
    "    C = P[:2, :2]\n",
    "    # Eigen-decomposition (sorted)\n",
    "    S, U = np.linalg.eigh(C)\n",
    "    order = S.argsort()[::-1]\n",
    "    S, U = S[order], U[:, order]\n",
    "    # Clamp tiny negative due to num. round-off\n",
    "    S = np.clip(S, 0.0, None)\n",
    "    a, b = nsig * np.sqrt(S)  # ellipse semi-axes\n",
    "    ang = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "    ax.add_patch(Ellipse(xy=m[:2], width=2*a, height=2*b, angle=ang, fill=False, **kwargs))\n",
    "\n",
    "\n",
    "# --- Configuration ---   \n",
    "cfg = SimpleNamespace(\n",
    "    seed        = 1,                          # set to None for nondeterministic runs\n",
    "    dt          = 0.10,                       # time step [s]\n",
    "    T           = 120,                        # number of steps\n",
    "    u_nom       = np.array([0.50, 0.15]),     # nominal [v, w] used by EKF for prediction\n",
    "    bias_v      = 1.07,                       # GT speed bias multiplier\n",
    "    bias_w      = 0.90,                       # GT turn-rate bias multiplier\n",
    "    R_exec      = np.diag([0.02**2,           # GT control noise on [v, w]\n",
    "                        (2.0*np.pi/180)**2]),  \n",
    "    R_x         = np.diag([0.01**2, 0.01**2,  # EKF process noise on [x, y, theta]\n",
    "                        (1.0*np.pi/180)**2]),  \n",
    "    mu0         = np.zeros(3),                # initial pose mean\n",
    "    Sigma0      = np.diag([0, 0, 0]),         # initial pose covariance\n",
    "    ellipse_steps = np.arange(0, 121, 10)     # which steps to draw ellipses; None -> auto\n",
    ")\n",
    "\n",
    "# --- Prediction-only rollout ---\n",
    "def run_prediction_only(cfg:SimpleNamespace) -> tuple:\n",
    "    \"\"\"\n",
    "    Runs a prediction-only rollout:\n",
    "    - Ground truth (GT) executes biased + noisy controls.\n",
    "    - EKF predicts using nominal controls and inflates covariance with R_x.\n",
    "    Args:\n",
    "    - cfg (SimpleNamespace): configuration namespace (see above)\n",
    "    Returns:\n",
    "    - MU (np.ndarray): EKF pose means over time.\n",
    "    - Sigma_hist (list): EKF pose covariances over time (length T+1).\n",
    "    - GT (np.ndarray): Ground-truth poses over time.\n",
    "    \"\"\"\n",
    "    if cfg.seed is not None:\n",
    "        np.random.seed(cfg.seed)\n",
    "\n",
    "    mu, Sigma = cfg.mu0.copy(), cfg.Sigma0.copy()\n",
    "    x_gt      = cfg.mu0.copy()  # start GT at same pose\n",
    "\n",
    "    MU     = [mu.copy()]\n",
    "    Sigma_hist = [Sigma.copy()]\n",
    "    GT     = [x_gt.copy()]\n",
    "\n",
    "    for _ in range(cfg.T):\n",
    "        # Ground truth executes biased + noisy controls\n",
    "        noise  = np.random.multivariate_normal([0, 0], cfg.R_exec)\n",
    "        u_exec = np.array([cfg.bias_v * cfg.u_nom[0],\n",
    "                           cfg.bias_w * cfg.u_nom[1]]) + noise\n",
    "        x_gt[:3] = x_gt[:3] + motion_increment(x_gt[2], u_exec, cfg.dt)\n",
    "        x_gt[2]  = wrap_angle(x_gt[2])\n",
    "\n",
    "        # EKF prediction with nominal controls\n",
    "        mu, Sigma = EKF_SLAM_Prediction(mu, Sigma, cfg.u_nom, cfg.R_x, cfg.dt)\n",
    "\n",
    "        # Store history\n",
    "        MU.append(mu.copy())\n",
    "        Sigma_hist.append(Sigma.copy())\n",
    "        GT.append(x_gt.copy())\n",
    "\n",
    "    return np.vstack(MU), Sigma_hist, np.vstack(GT)\n",
    "\n",
    "# --- Plotting helpers ---\n",
    "def plot_paths_and_ellipses(MU:np.ndarray, Sigma_hist:list, GT:np.ndarray, cfg:SimpleNamespace) -> tuple:\n",
    "    \"\"\"\n",
    "    GT vs EKF mean + a few 2œÉ ellipses.\n",
    "    Args:\n",
    "    - MU (np.ndarray): EKF pose means over time.\n",
    "    - Sigma_hist (list): EKF pose covariances over time (length T+1).\n",
    "    - GT (np.ndarray): Ground-truth poses over time.\n",
    "    - cfg (SimpleNamespace): configuration namespace (see above)\n",
    "    Returns:\n",
    "    - fig, ax : the figure and axes objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.plot(GT[:, 0], GT[:, 1], '.-',  lw=2, label='Ground truth')\n",
    "    ax.plot(MU[:, 0], MU[:, 1], '.--', lw=2, label='EKF mean (prediction)')\n",
    "\n",
    "    if cfg.ellipse_steps is None:\n",
    "        steps = [0, cfg.T // 3, 2 * cfg.T // 3, cfg.T]\n",
    "    else:\n",
    "        steps = [s for s in cfg.ellipse_steps if 0 <= s <= cfg.T]\n",
    "\n",
    "    for s in steps:\n",
    "        plot_ellipse(ax, MU[s], Sigma_hist[s], nsig=2, color='tab:red', lw=1.8)\n",
    "        ax.plot(MU[s, 0], MU[s, 1], 'o', color='tab:red', ms=4)\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('x [m]'); ax.set_ylabel('y [m]')\n",
    "    ax.set_title('Prediction only: GT vs EKF mean + covariance ellipses')\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "# --- Run + Plot ---\n",
    "MU, Sigma_hist, GT = run_prediction_only(cfg)\n",
    "plot_paths_and_ellipses(MU, Sigma_hist, GT, cfg)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d300b91",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a1350",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è <span style=\"color:#a4d4a3\">**EKF SLAM: Correction Step**</span>\n",
    "\n",
    "In the correction step, we incorporate sensor measurements to <span style=\"color:#ffa500\">**refine the current belief**</span> about the robot's pose and landmark positions.\n",
    "\n",
    "We have assumed:\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Known data association**</span> (each observation is correctly matched to its landmark).\n",
    "- The measurement at time $ t $ observes landmark $ j $, and $ C_t^i = j $.\n",
    "- Landmarks are initialized when observed for the first time.\n",
    "\n",
    "The correction procedure is as follows:\n",
    "\n",
    "#### <span style=\"color:#a4d4a3\">**1. Range-bearing Observation**</span>\n",
    "\n",
    "For a <span style=\"color:#ffa500\">**range-bearing sensor**</span>, each observation $ z_t^i $ at time $ t $ consists of a range and bearing measurement:\n",
    "\n",
    "$$\n",
    "z_t^i = (r_t^i, \\varphi_t^i)^T\n",
    "$$\n",
    "\n",
    "If a landmark $ j $ has <span style=\"color:#ffa500\">**not previously been observed**</span>, initialize it based on the current robot's pose estimate and the measurement:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\bar{\\mu}_{j,x} \\\\[6pt] \\bar{\\mu}_{j,y}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\bar{\\mu}_{t,x} \\\\[6pt] \\bar{\\mu}_{t,y}\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "r_t^i \\cos(\\varphi_t^i + \\bar{\\mu}_{t,\\theta}) \\\\[6pt]\n",
    "r_t^i \\sin(\\varphi_t^i + \\bar{\\mu}_{t,\\theta})\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $\\mu_{j,x}, \\mu_{j,y}\\,$ is the observed landmark's <span style=\"color:#ffa500\">**estimated global**</span> position.\n",
    "- $\\bar{\\mu}_{t,x}, \\bar{\\mu}_{t,y}\\,$ is the robot's <span style=\"color:#ffa500\">**estimated global**</span> position.\n",
    "- $r_t^i, \\varphi_t^i\\,$ is the <span style=\"color:#ffa500\">**relative measurement**</span> from the robot to landmark $ j $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ea555",
   "metadata": {},
   "source": [
    "The corresponding initialization can be implemented in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialization from a range‚Äìbearing observation ---\n",
    "def init_landmark_from_observation(mu:np.ndarray, seen_mask:np.ndarray, j:int, z:np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    If landmark j has never been seen, initialize it from the current robot pose and the range-bearing observation z = [r, phi].\n",
    "    Args:\n",
    "    - mu (np.ndarray): current mean state vector (robot pose + landmarks)\n",
    "    - seen_mask (np.ndarray): boolean array indicating which landmarks have been seen\n",
    "    - j (int): index of the landmark to initialize\n",
    "    - z (np.ndarray): range-bearing observation [r, phi]\n",
    "    Returns:\n",
    "    - mu (np.ndarray): updated mean state vector (robot pose + landmarks)\n",
    "    - seen_mask (np.ndarray): updated boolean array indicating which landmarks have been seen\n",
    "    \"\"\"\n",
    "    if not seen_mask[j]:\n",
    "        r, phi = z\n",
    "        mu[3 + 2*j]     = mu[0] + r * np.cos(phi + mu[2])\n",
    "        mu[3 + 2*j + 1] = mu[1] + r * np.sin(phi + mu[2])\n",
    "        seen_mask[j] = True\n",
    "    return mu, seen_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6aa8db",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">**2. Expected Observation**</span>\n",
    "\n",
    "Compute the <span style=\"color:#ffa500\">**expected observation**</span> according to the current estimate:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta &=\n",
    "\\begin{pmatrix}\n",
    "\\delta_x \\\\[6pt] \\delta_y\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\bar{\\mu}_{j,x} - \\bar{\\mu}_{t,x} \\\\[6pt]\n",
    "\\bar{\\mu}_{j,y} - \\bar{\\mu}_{t,y}\n",
    "\\end{pmatrix} \\\\ \\\\\n",
    "\n",
    "q & = \\delta^T \\delta \\\\ \\\\\n",
    "\n",
    "\\hat{z}_t^i &=\n",
    "\\begin{pmatrix}\n",
    "\\sqrt{q} \\\\[6pt]\n",
    "\\text{atan2}(\\delta_y,\\delta_x) - \\bar{\\mu}_{t,\\theta}\n",
    "\\end{pmatrix} \\\\ \\\\\n",
    "&= h(\\bar{\\mu}_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\delta \\,$ is the distance between the robot's pose and the landmark.\n",
    "- $q\\,$ is the squared Euclidean distance.\n",
    "- $\\hat{z}_t^i\\,$ maps the state of the robot to the predicted observation (range and bearing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba732f",
   "metadata": {},
   "source": [
    "In the Python implementation, the function returns three values: the predicted observation $\\hat{z}$, the difference vector $[\\delta x, \\delta y]$, and the squared distance $q$. We include $[\\delta x, \\delta y]$ and $q$ because they are reused when building the Jacobian and innovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ca6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expected observation ---\n",
    "def expected_observation(mu:np.ndarray, j:int) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute predicted range-bearing zhat to landmark j.\n",
    "    Args:\n",
    "    - mu (np.ndarray): current mean state vector (robot pose + landmarks)\n",
    "    - j (int): index of the landmark\n",
    "    Returns:\n",
    "    - zhat (np.ndarray): predicted range-bearing observation [r, phi]\n",
    "    - dx, dy (np.ndarray): difference vector from robot to landmark [dx, dy]\n",
    "    - q (np.ndarray): squared range from robot to landmark\n",
    "    \"\"\"\n",
    "    # Extract robot pose\n",
    "    x, y, th = mu[:3]\n",
    "    # Landmark j position\n",
    "    mx, my = mu[3 + 2 * j:3 + 2 * j + 2]\n",
    "    dx, dy = mx - x, my - y\n",
    "    q = dx*dx + dy*dy\n",
    "    r = np.sqrt(max(q, 1e-12))\n",
    "    phi = wrap_angle(np.arctan2(dy, dx) - th)\n",
    "    zhat = np.array([r, phi])\n",
    "    return zhat, np.array([dx, dy]), q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7b1fc",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:#a4d4a3\">**3. Jacobian of the Observation Model**</span>\n",
    "\n",
    "Compute the Jacobian of the observation (measurement) model $ h(\\bar{\\mu}_t) $:\n",
    "\n",
    "- In a low-dimensional space, focusing <span style=\"color:#ffa500\">**only on non-zero dimensions**</span> $(x,y,\\theta,m_{j,x},m_{j,y})$.\n",
    "- It is going to be a matrix of $2\\times5$ dimensions.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "^\\text{low}H_t^{i} &=\n",
    "\\frac{\\partial h(\\bar{\\mu}_t)}{\\partial \\bar{\\mu}_t} \\\\ \\\\\n",
    "&=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial \\sqrt{q}}{\\partial x} & \\frac{\\partial \\sqrt{q}}{\\partial y} & \\ldots \\\\\n",
    "\\frac{\\partial \\text{atan2}(\\ldots)}{\\partial x} & \\frac{\\partial \\text{atan2}(\\ldots)}{\\partial y} & \\ldots \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "By applying the <span style=\"color:#ffa500\">**chain rule**</span>, we get:\n",
    "\n",
    "$$\n",
    "^\\text{low}H_t^{i} = \\frac{1}{q}\n",
    "\\begin{pmatrix}\n",
    "-\\sqrt{q}\\,\\delta_x & -\\sqrt{q}\\,\\delta_y & 0 & \\sqrt{q}\\,\\delta_x & \\sqrt{q}\\,\\delta_y \\\\[6pt]\n",
    "\\delta_y & -\\delta_x & -q & -\\delta_y & \\delta_x\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Next, we need to map it to the <span style=\"color:#ffa500\">**full high-dimensional**</span> state-space using the <span style=\"color:#ffa500\">**auxiliary matrix**</span> $F_{x,j}$:\n",
    "\n",
    "$$\n",
    "H_t^i = {}^\\text{low}H_t^{i} \\, F_{x,j}\n",
    "$$\n",
    "\n",
    "Where $F_{x,j}$ extracts the robot's and landmark positions from the full state vector:\n",
    "\n",
    "$$\n",
    "F_{x,j} =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt]\n",
    "0 & 1 & 0 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt]\n",
    "0 & 0 & 1 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt]\n",
    "0 & 0 & 0 & 0 \\, \\dots \\, 0 & 1 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt]\n",
    "0 & 0 & 0 & \\underbrace{0 \\, \\dots \\, 0}_{2j-2} & 0 & 1 & \\underbrace{0 \\, \\ldots \\, 0}_{2N-2j} \\\\[3pt]\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c24f8",
   "metadata": {},
   "source": [
    "To keep the implementation modular, we define separate functions for computing $^\\text{low}H_t$ (the 2√ó5 observation Jacobian), the auxiliary matrix $F_{x,j}, and the full Jacobian $H_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56784092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute the Jacobian of the observation model --- \n",
    "def H_low(mu: np.ndarray, j: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute the 2x5 Jacobian of the observation model.\n",
    "    Args:\n",
    "    - mu (np.ndarray): current mean state vector (robot pose + landmarks)\n",
    "    - j (int): landmark index (0-based)\n",
    "    Returns:\n",
    "    - H_small (np.ndarray): (2,5) Jacobian wrt [x, y, theta, mx, my]\n",
    "    - zhat (np.ndarray): (2,) expected observation [range, bearing]\n",
    "    \"\"\"\n",
    "    zhat, delta, q = expected_observation(mu, j)\n",
    "    dx, dy = delta\n",
    "    r = zhat[0]\n",
    "    q = max(q, 1e-12)  # guard\n",
    "    H_small = (1.0/q) * np.array([\n",
    "        [-r*dx,  -r*dy,   0.0,  r*dx,  r*dy],\n",
    "        [  dy,    -dx,   -q,    -dy,    dx]\n",
    "    ])\n",
    "    return H_small, zhat\n",
    "\n",
    "# --- Auxiliary matrix to map into full state size ---\n",
    "def Fxj_embed(n:int, j:int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the auxiliary matrix Fxj to embed 5x5 matrices into the state vector of size n.\n",
    "    Args:\n",
    "    - n (int): size of the full state (robot + landmarks)\n",
    "    - j (int): landmark index (0-based)\n",
    "    Returns:\n",
    "    - Fxj (np.ndarray): (5,n) matrix to map 5x5 into full state size\n",
    "    \"\"\"\n",
    "    Fxj = np.zeros((5, n))\n",
    "    Fxj[:3,:3] = np.eye(3)\n",
    "    Fxj[3, 3+2*j]   = 1.0\n",
    "    Fxj[4, 3+2*j+1] = 1.0\n",
    "    return Fxj\n",
    "\n",
    "# --- Full Jacobian of the observation model ---\n",
    "def H_full(mu: np.ndarray, j: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Expand H_low into full state size using Fxj_embed.\n",
    "    Args:\n",
    "    - mu (np.ndarray): current mean state vector (robot pose + landmarks)\n",
    "    - j (int): landmark index (0-based)\n",
    "    Returns:\n",
    "    - H_i (np.ndarray): (2,n) Jacobian wrt full state vector\n",
    "    - zhat (np.ndarray): (2,) expected observation [range, bearing]\n",
    "    \"\"\"\n",
    "    n = mu.size\n",
    "    H_small, zhat = H_low(mu, j)\n",
    "    Fxj = Fxj_embed(n, j)\n",
    "    H_i = H_small @ Fxj\n",
    "    return H_i, zhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626dcf62",
   "metadata": {},
   "source": [
    "With this, we have derived all the components needed for the EKF-SLAM correction step. Combining them, we can now implement the correction function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0aaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Innovation ---\n",
    "def innovation(z: np.ndarray, zhat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Innovation, the difference between actual and expected observation.\n",
    "    Args:\n",
    "    - z (np.ndarray): actual observation [r, phi]\n",
    "    - zhat (np.ndarray): expected observation [r, phi]\n",
    "    Returns:\n",
    "    - v (np.ndarray): innovation difference [dr, dphi] with bearing wrapped to (-pi, pi]\n",
    "    \"\"\"\n",
    "    return np.array([z[0] - zhat[0], wrap_angle(z[1] - zhat[1])])\n",
    "\n",
    "# --- EKF SLAM Correction Step ---\n",
    "def EKF_SLAM_Correction(mu_bar: np.ndarray, Sigma_bar: np.ndarray, z_list: list, c_list: list, Q: np.ndarray, seen_mask: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    EKF-SLAM correction step.\n",
    "    Args:\n",
    "    - mu_bar (np.ndarray): predicted mean state vector (robot pose + landmarks)\n",
    "    - Sigma_bar (np.ndarray): predicted covariance matrix\n",
    "    - z_list (list): list of range-bearing observations [r, phi]\n",
    "    - c_list (list): list of landmark indices corresponding to z_list (0-based)\n",
    "    - Q (np.ndarray): observation noise covariance matrix\n",
    "    - seen_mask (np.ndarray): boolean array indicating which landmarks have been seen\n",
    "    Returns:\n",
    "    - mu (np.ndarray): updated mean state vector (robot pose + landmarks)\n",
    "    - Sigma (np.ndarray): updated covariance matrix\n",
    "    - seen_mask (np.ndarray): updated boolean array indicating which landmarks have been seen\n",
    "    \"\"\"\n",
    "    mu    = mu_bar.copy()\n",
    "    Sigma = Sigma_bar.copy()\n",
    "    I     = np.eye(mu.size)\n",
    "    # Process each observation\n",
    "    for z, j in zip(z_list, c_list):\n",
    "        # Initialize unseen landmarks\n",
    "        mu, seen_mask = init_landmark_from_observation(mu, seen_mask, j, z)\n",
    "        # Expected observation and Jacobians\n",
    "        H_small, zhat = H_low(mu, j)\n",
    "        # Full-state Jacobian H_i (2xn) via Fxj\n",
    "        n = mu.size\n",
    "        Fxj = Fxj_embed(n, j)\n",
    "        H_i = H_small @ Fxj\n",
    "        # Kalman gain\n",
    "        S = H_i @ Sigma @ H_i.T + Q\n",
    "        v = innovation(z, zhat)\n",
    "        K = Sigma @ H_i.T @ np.linalg.inv(S)\n",
    "        # Update state and covariance\n",
    "        mu    = mu + K @ v\n",
    "        mu[2] = wrap_angle(mu[2])     # normalize heading\n",
    "        Sigma = (I - K @ H_i) @ Sigma\n",
    "    return mu, Sigma, seen_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c9b8e",
   "metadata": {},
   "source": [
    "Next, we revisit the circular trajectory example and extend it by incorporating the correction step. In this setup, landmarks are randomly initialized, and for simplicity, we assume that the data associations are already known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# --- Sampling & plotting utils --\n",
    "def sample_landmarks(N:int, lo:np.ndarray, hi:np.ndarray, min_dist:float, seed:int=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample N landmark positions uniformly in [lo, hi]x[lo, hi],\n",
    "    ensuring they are at least min_dist from the origin.\n",
    "    Args:\n",
    "        N (int): number of landmarks\n",
    "        lo (np.ndarray): lower bound (2,)\n",
    "        hi (np.ndarray): upper bound (2,)\n",
    "        min_dist (float): minimum distance from origin\n",
    "        seed (int, optional): random seed. Defaults to None.\n",
    "    Returns:\n",
    "        L (np.ndarray): (N,2) landmark positions\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    L = rng.uniform(low=lo, high=hi, size=(N, 2))\n",
    "    mask = np.linalg.norm(L, axis=1) > min_dist\n",
    "    while not np.all(mask):\n",
    "        L[~mask] = rng.uniform(low=lo, high=hi, size=(np.sum(~mask), 2))\n",
    "        mask = np.linalg.norm(L, axis=1) > min_dist\n",
    "    return L\n",
    "\n",
    "def circular_trajectory_controls(T:int, speed:np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Generate a list of (v,w) controls to follow a circular trajectory.\n",
    "    Args:\n",
    "        T (int): number of time steps\n",
    "        speed (np.ndarray): nominal (v,w) speeds\n",
    "    Returns:\n",
    "        list: list of (v,w) controls for T steps\n",
    "    \"\"\"\n",
    "    v, w = float(speed[0]), float(speed[1])\n",
    "    return [np.array([v, w]) for _ in range(T)]\n",
    "\n",
    "# --- Full example (prediction + correction) ---\n",
    "cfg = SimpleNamespace(\n",
    "    seed          = 1,                         # set to None for nondeterministic runs\n",
    "    N_landmarks   = 4,                         # number of landmarks\n",
    "    lm_bounds_lo  = np.array([ 0.0, 0.0]),     # lower bounds for landmark sampling\n",
    "    lm_bounds_hi  = np.array([ 5.0, 5.0]),     # upper bounds for landmark sampling\n",
    "    lm_min_dist   = 0.5,                       # minimum distance of landmarks from origin\n",
    "    dt            = 0.10,                      # time step [s]                  \n",
    "    T             = 120,                       # number of steps\n",
    "    u_nom         = np.array([0.50, 0.15]),    # EKF prediction controls\n",
    "    R_x           = np.diag([0.01**2, 0.01**2, # EKF process noise on [x, y, theta]\n",
    "                            (1.0*np.pi/180)**2]),\n",
    "    Q             = np.diag([0.02**2,          # EKF observation noise on [r, phi]\n",
    "                            (2.0*np.pi/180)**2]),\n",
    "    bias_v        = 1.07,                      # GT speed bias multiplier\n",
    "    bias_w        = 0.96,                      # GT turn-rate bias multiplier\n",
    "    R_exec        = np.diag([0.02**2,          # GT control noise on [v, w]\n",
    "                            (2.0*np.pi/180)**2]),\n",
    "    Sigma0_pose   = np.diag([1e-4, 1e-4,       # initial pose covariance\n",
    "                            (1*np.pi/180)**2]),\n",
    "    Sigma0_lm_var = 1e6,                       # initial landmark variance (large = uninformative)\n",
    "    ellipse_steps = np.arange(0, 121, 10),     # which steps to draw ellipses; None -> auto\n",
    ")\n",
    "\n",
    "# --- Full EKF-SLAM rollout ---\n",
    "def run_full_stack(cfg):\n",
    "    # Landmarks & controls\n",
    "    L_true = sample_landmarks(cfg.N_landmarks, cfg.lm_bounds_lo, cfg.lm_bounds_hi, cfg.lm_min_dist, seed=cfg.seed)\n",
    "    u_seq  = circular_trajectory_controls(cfg.T, cfg.u_nom)\n",
    "\n",
    "    # Initial belief\n",
    "    n = 3 + 2*cfg.N_landmarks\n",
    "    mu    = np.zeros(n)\n",
    "    Sigma = np.block([\n",
    "        [cfg.Sigma0_pose, np.zeros((3, 2*cfg.N_landmarks))],\n",
    "        [np.zeros((2*cfg.N_landmarks, 3)), np.eye(2*cfg.N_landmarks)*cfg.Sigma0_lm_var]\n",
    "    ])\n",
    "    seen = np.zeros(cfg.N_landmarks, dtype=bool)\n",
    "\n",
    "    # Ground truth\n",
    "    x_gt = np.zeros(3)\n",
    "\n",
    "    # Logs\n",
    "    MU_hist, GT_hist = [mu.copy()], [x_gt.copy()]\n",
    "    Ppose_hist = [Sigma[:3,:3].copy()]\n",
    "\n",
    "    rng = np.random.default_rng(cfg.seed)\n",
    "    for k in range(cfg.T):\n",
    "        # --- GT executes biased + noisy controls\n",
    "        noise  = rng.multivariate_normal([0,0], cfg.R_exec)\n",
    "        u_exec = np.array([cfg.bias_v*cfg.u_nom[0], cfg.bias_w*cfg.u_nom[1]]) + noise\n",
    "        x_gt[:3] = x_gt[:3] + motion_increment(x_gt[2], u_exec, cfg.dt)\n",
    "        x_gt[2]  = wrap_angle(x_gt[2])\n",
    "\n",
    "        # --- Prediction ---\n",
    "        mu_bar, Sigma_bar = EKF_SLAM_Prediction(mu, Sigma, u_seq[k], cfg.R_x, cfg.dt)\n",
    "\n",
    "        # --- Measurements (all landmarks, known associations)\n",
    "        z_all, c_all = [], []\n",
    "        for j in range(cfg.N_landmarks):\n",
    "            dx, dy = L_true[j,0] - x_gt[0], L_true[j,1] - x_gt[1]\n",
    "            r      = np.hypot(dx, dy)\n",
    "            phi    = wrap_angle(np.arctan2(dy, dx) - x_gt[2])\n",
    "            z = np.array([\n",
    "                r   + rng.normal(0.0, np.sqrt(cfg.Q[0,0])),\n",
    "                wrap_angle(phi + rng.normal(0.0, np.sqrt(cfg.Q[1,1])))\n",
    "            ])\n",
    "            z_all.append(z); c_all.append(j)\n",
    "\n",
    "        # --- Correction ---\n",
    "        mu, Sigma, seen = EKF_SLAM_Correction(\n",
    "            mu_bar, Sigma_bar, z_all, c_all, cfg.Q, seen)\n",
    "\n",
    "        # --- Log ---\n",
    "        MU_hist.append(mu.copy()); GT_hist.append(x_gt.copy())\n",
    "        Ppose_hist.append(Sigma[:3,:3].copy())\n",
    "\n",
    "    return np.vstack(MU_hist), np.vstack(GT_hist), Ppose_hist, L_true\n",
    "\n",
    "# --- Run & plot ---\n",
    "MU_hist, GT_hist, Ppose_hist, L_true = run_full_stack(cfg)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "# Trajectories + ellipses\n",
    "ax.plot(GT_hist[:,0], GT_hist[:,1], '-',  lw=2, label='Ground truth')\n",
    "ax.plot(MU_hist[:,0], MU_hist[:,1], '--', lw=2, label='EKF estimate')\n",
    "for s in cfg.ellipse_steps:\n",
    "    plot_ellipse(ax, MU_hist[s], Ppose_hist[s], nsig=2, color='tab:red', lw=1.6)\n",
    "    ax.plot(MU_hist[s,0], MU_hist[s,1], 'o', color='tab:red', ms=4)\n",
    "ax.scatter(L_true[:,0], L_true[:,1], marker='*', s=120, label='True landmarks')\n",
    "estL = MU_hist[-1, 3:].reshape(-1, 2)\n",
    "ax.scatter(estL[:,0], estL[:,1], marker='x', s=80, label='Estimated landmarks')\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.grid(True); ax.set_xlabel('x [m]'); ax.set_ylabel('y [m]')\n",
    "ax.set_title(f'EKF-SLAM')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ffa0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea8ee2",
   "metadata": {},
   "source": [
    "\n",
    "### üóÇÔ∏è <span style=\"color:#a4d4a3\">**EKF SLAM Algorithm** (Summary)</span>\n",
    "\n",
    "Having completed both steps we can summarize the full <span style=\"color:#ffa500\">**EKF SLAM Algorithm**</span> as follows:\n",
    "\n",
    "> <tt> <span style=\"color:#FF2DD1\">1.</span> <span style=\"color:#4D96FF\">def</span> **<span style=\"color:#6BCB77\">EKF_SLAM_Prediction</span>($\\color{#ffa500}\\mu_{t-1}$, $\\color{#ffa500}\\Sigma_{t-1}$, $\\color{#ffa500}u_t$, $\\color{#ffa500}z_t$, $\\color{#ffa500}c_t$, $\\color{#ffa500}R_t$):**\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">2.</span> $F_x =  \n",
    "\\begin{pmatrix} \n",
    "1 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\ \n",
    "0 & 1 & 0 & 0 \\, \\ldots \\, 0 \\\\ \n",
    "0 & 0 & 1 & 0 \\, \\ldots \\, 0 \\\\ \n",
    "\\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Define low-to-high mapping</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">3.</span> $\\bar{\\mu}_t = \\bar{\\mu}_{t-1} + F_x^T\n",
    "\\begin{pmatrix}\n",
    "-\\frac{v_t}{w_t}\\sin \\mu_{t-1,\\theta} + \\frac{v_t}{w_t}\\sin(\\mu_{t-1,\\theta} + w_t\\Delta t) \\\\[6pt]\n",
    "\\frac{v_t}{w_t}\\cos \\mu_{t-1,\\theta} - \\frac{v_t}{w_t}\\cos(\\mu_{t-1,\\theta} + w_t\\Delta t) \\\\[6pt]\n",
    "w_t\\Delta t\n",
    "\\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Predict the mean</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">4.</span> $G_t = I + F_x^T \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & -\\frac{v_t}{w_t}\\cos \\mu_{t-1,\\theta} + \\frac{v_t}{w_t}\\cos(\\mu_{t-1,\\theta} + w_t\\Delta t) \\\\[6pt]\n",
    "0 & 0 & -\\frac{v_t}{w_t}\\sin \\mu_{t-1,\\theta} + \\frac{v_t}{w_t}\\sin(\\mu_{t-1,\\theta} + w_t\\Delta t) \\\\[6pt]\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix} F_x\\,\\,\\,\\,$ <span style=\"color:#948979\"># Compute the Jacobian</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">5.</span> $\\bar{\\Sigma}_t = G_t \\Sigma_{t-1} G_t^T + \\underbrace{F_x^T R_t^x F_x}_{R_t} \\,\\,\\,\\,$ <span style=\"color:#948979\"># Predict the covariance</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">6.</span> <span style=\"color:#e74c3c\">return</span> $\\bar{\\mu}_t,\\,\\bar{\\Sigma}_t$\n",
    ">\n",
    "><span style=\"color:#FF2DD1\">7.</span> <span style=\"color:#4D96FF\">def</span> **<span style=\"color:#6BCB77\">EKF_SLAM_Correction</span>($\\color{#ffa500}\\bar{\\mu}_t$, $\\color{#ffa500}\\bar{\\Sigma}_t$, $\\color{#ffa500}u_t$, $\\color{#ffa500}z_t$, $\\color{#ffa500}c_t$, $\\color{#ffa500}\\sigma_t$):**\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">8.</span> $Q_t = \\begin{pmatrix} \\sigma_r^2 & 0 \\\\ 0 & \\sigma_\\phi^2 \\\\ \\end{pmatrix} \\,\\,\\,\\,$ <span style=\"color:#948979\"># Define uncertainty of sensor</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">9.</span> <span style=\"color:#e74c3c\">for all</span> <span style=\"color:#ffa500\">observed features</span> $z_t^i = (r_t^i,\\phi_t^i)^T$ <span style=\"color:#e74c3c\">do</span>:\n",
    ">>\n",
    ">>><span style=\"color:#FF2DD1\">10.</span> $j = c_t^i\\,\\,\\,\\,$ <span style=\"color:#948979\"># Index of the feature</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">11.</span> <span style=\"color:#e74c3c\">if</span> <span style=\"color:#ffa500\">landmark</span> $j$ <span style=\"color:#e74c3c\"> never seen before</span>:\n",
    ">>>>\n",
    ">>>><span style=\"color:#FF2DD1\">12.</span> $\\begin{pmatrix} \\bar{\\mu}_{j,x} \\\\[6pt] \\bar{\\mu}_{j,y} \\end{pmatrix} = \\begin{pmatrix} \\bar{\\mu}_{t,x} \\\\[6pt] \\bar{\\mu}_{t,y}\\end{pmatrix} + \\begin{pmatrix} r_t^i \\cos(\\varphi_t^i + \\bar{\\mu}_{t,\\theta}) \\\\[6pt] r_t^i \\sin(\\varphi_t^i + \\bar{\\mu}_{t,\\theta}) \\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Initialize landmarks based on the robot's pose</span>\n",
    ">>>>\n",
    ">>><span style=\"color:#FF2DD1\">13.</span> <span style=\"color:#e74c3c\">endif</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">14.</span> $\\delta = \\begin{pmatrix} \\delta_x \\\\[6pt] \\delta_y \\end{pmatrix} = \\begin{pmatrix} \\bar{\\mu}_{j,x} - \\bar{\\mu}_{t,x} \\\\[6pt] \\bar{\\mu}_{j,y} - \\bar{\\mu}_{t,y} \\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Compute distance to landmark</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">15.</span> $q = \\delta^T \\delta\\,\\,\\,\\,$ <span style=\"color:#948979\"># Squared Euclidean distance</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">16.</span> $\\hat{z}_t^i = \\begin{pmatrix} \\sqrt{q} \\\\[6pt] \\text{atan2}(\\delta_y,\\delta_x) - \\bar{\\mu}_{t,\\theta} \\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Compute predicted observation</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">17.</span> $F_{x,j} = \\begin{pmatrix} 1 & 0 & 0 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt] 0 & 1 & 0 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt] 0 & 0 & 1 & 0 \\, \\dots \\, 0 & 0 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt] 0 & 0 & 0 & 0 \\, \\dots \\, 0 & 1 & 0 & 0 \\, \\ldots \\, 0 \\\\[3pt] 0 & 0 & 0 & \\underbrace{0 \\, \\dots \\, 0}_{2j-2} & 0 & 1 & \\underbrace{0 \\, \\ldots \\, 0}_{2N-2j} \\\\[3pt] \\end{pmatrix}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Define low-to-high mapping</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">18.</span> $H_t^{i} = \\frac{1}{q} \\begin{pmatrix} -\\sqrt{q}\\,\\delta_x & -\\sqrt{q}\\,\\delta_y & 0 & \\sqrt{q}\\,\\delta_x & \\sqrt{q}\\,\\delta_y \\\\[6pt] \\delta_y & -\\delta_x & -q & -\\delta_y & \\delta_x \\end{pmatrix} F_{x,j} \\,\\,\\,\\,$ <span style=\"color:#948979\"># Compute Jacobian of observation</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">19.</span> $K_t^i = \\bar{\\Sigma}_t \\, H_t^{iT} \\,(H_t^i \\, \\bar{\\Sigma}_t \\, H_t^{iT} + Q_t) ^{-1}\\,\\,\\,\\,$ <span style=\"color:#948979\"># Compute Kalman Gain</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">20.</span> $\\bar{\\mu}_t = \\bar{\\mu}_t + K_t^i(z_t^i - \\hat{z_t}^i)\\,\\,\\,\\,$ <span style=\"color:#948979\"># Update the mean</span>\n",
    ">>>\n",
    ">>><span style=\"color:#FF2DD1\">21.</span> $\\bar{\\Sigma}_t = (I - K_t^i \\, H_t^i) \\, \\bar{\\Sigma}_t\\,\\,\\,\\,$ <span style=\"color:#948979\"># Update the covariance</span>\n",
    ">>>\n",
    ">><span style=\"color:#FF2DD1\">22.</span> <span style=\"color:#e74c3c\">endfor</span>\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">23.</span> $\\mu_t = \\bar{\\mu}_t\\,\\,\\,\\,$ \n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">24.</span> $\\Sigma_t = \\bar{\\Sigma}_t\\,\\,\\,\\,$\n",
    ">>\n",
    ">><span style=\"color:#FF2DD1\">25.</span> <span style=\"color:#e74c3c\">return</span> $\\mu_t, \\Sigma_t\\,\\,\\,\\,$\n",
    "</tt>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe51bc9",
   "metadata": {},
   "source": [
    "\n",
    "#### üë©üèª‚Äçüíª <span style=\"color:#a4d4a3\">**Implementation Notes**</span>\n",
    "\n",
    "When implementing the full <span style=\"color:#ffa500\">**EKF-SLAM**</span> algorithm, keep the following in mind:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Batch updates:**</span> Always integrate all measurements from a single time step into <span style=\"color:#ffa500\">**one complete update cycle**</span>.  \n",
    "- <span style=\"color:#00703c\">**Angle normalization:**</span> Ensure angular components are wrapped to remain within $[-\\pi, \\pi]$.  \n",
    "- <span style=\"color:#00703c\">**Jacobian efficiency:**</span> Avoid explicitly forming the $F_{x,j}$ matrices unless necessary, use <span style=\"color:#ffa500\">**indexing operations**</span> instead for better efficiency.  \n",
    "\n",
    "In the following example, we revisit the <span style=\"color:#ffa500\">**Pygame simulation**</span> introduced earlier (during the motion-model section), where the trajectory and map drifted considerably due to noise and model inaccuracies. This time, we extend it with the EKF update step.\n",
    "\n",
    "Some practical implementation details are worth noting:\n",
    "\n",
    "1. <span style=\"color:#00703c\">**Landmark density:**</span> Since we are not extracting high-level features but instead treating every LiDAR point as a potential landmark, the state vector can grow very quickly, creating computational bottlenecks. To manage this, we <span style=\"color:#ffa500\">**discretize the 2D LiDAR image plane into pixel blocks**</span>, keeping only one landmark per block. This reduces the total number of landmarks significantly.  \n",
    "\n",
    "2. <span style=\"color:#00703c\">**Selective updates:** </span>Updating the entire state vector with all landmarks at every step is computationally expensive. Instead, we only update the <span style=\"color:#ffa500\">**nearest subset of landmarks**</span>. This keeps the updates efficient while still correcting the map consistently as landmarks are revisited.  \n",
    "\n",
    "3. <span style=\"color:#00703c\">**Consistency:**</span> As a result of these strategies, the reconstructed map becomes noticeably more stable.  \n",
    "   Depending on how many neighbors are selected, you can directly see how the nearest landmarks are corrected and reinforced over multiple observations.  \n",
    "\n",
    "Finally, as the system grows in size and complexity, structuring the code with dedicated <span style=\"color:#ffa500\">**classes**</span> and <span style=\"color:#ffa500\">**functions**</span> becomes essential for clarity and maintainability.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# EKF-SLAM Pygame Demo (GT left | EKF right)\n",
    "# ===========================================\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# --- Small helpers ---\n",
    "def wrap_angle(a: float) -> float:\n",
    "    return (a + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "def i2(p):\n",
    "    \"\"\"(x,y) -> (int,int)\"\"\"\n",
    "    return (int(p[0]), int(p[1]))\n",
    "\n",
    "# --- Config ---\n",
    "class Config:\n",
    "    # Window/panels\n",
    "    panel_w, panel_h = 600, 400\n",
    "    window_size = (panel_w*2, panel_h)\n",
    "\n",
    "    # Scan/visual\n",
    "    num_beams = 180\n",
    "    scan_ms   = 100\n",
    "    fov_deg   = 360\n",
    "    ray_stride = 2\n",
    "    traj_max   = 200\n",
    "\n",
    "    # Discretization (to limit LMs)\n",
    "    grid_px = 8           # one LM per grid cell\n",
    "    range_step_px = 4.0   # quantize range\n",
    "    bearing_step_deg = 2.0\n",
    "    bearing_step = np.deg2rad(bearing_step_deg)\n",
    "\n",
    "    # Landmark selection\n",
    "    use_nearest = True\n",
    "    nearest_k_seen = 25\n",
    "    chunk = None          # None or e.g. 24\n",
    "\n",
    "    # Motion (keyboard odometry)\n",
    "    trans_step = 10.0\n",
    "    rot_step   = np.deg2rad(15.0)\n",
    "\n",
    "    # Noises (pixels & radians)\n",
    "    R_x = np.diag([1.0**2, 1.0**2, (2.0*np.pi/180.0)**2]).astype(np.float32)  # process (pose)\n",
    "    Q   = np.diag([2.0**2, (2.0*np.pi/180.0)**2]).astype(np.float32)          # sensor (range px, bearing rad)\n",
    "\n",
    "# --- Panel (drawing with offset) ---\n",
    "class Panel:\n",
    "    def __init__(self, screen, rect):\n",
    "        self.screen = screen\n",
    "        self.rect   = rect     # (x,y,w,h)\n",
    "\n",
    "    @property\n",
    "    def ox(self): return self.rect[0]\n",
    "\n",
    "    def clear(self, color):\n",
    "        x,y,w,h = self.rect\n",
    "        self.screen.fill(color, self.rect)\n",
    "        pygame.draw.rect(self.screen, (200,200,200), self.rect, 2)\n",
    "\n",
    "    def blit(self, surf, at=(0,0)):\n",
    "        x,y,_,_ = self.rect\n",
    "        self.screen.blit(surf, (x+at[0], y+at[1]))\n",
    "\n",
    "    def line(self, color, p0, p1, width=1):\n",
    "        x,y,_,_ = self.rect\n",
    "        self.screen.draw_line = pygame.draw.line\n",
    "        pygame.draw.line(self.screen, color, (x+p0[0], y+p0[1]), (x+p1[0], y+p1[1]), width)\n",
    "\n",
    "    def circle(self, color, p, r):\n",
    "        x,y,_,_ = self.rect\n",
    "        pygame.draw.circle(self.screen, color, (x+int(p[0]), y+int(p[1])), r)\n",
    "\n",
    "    def polygon(self, color, pts):\n",
    "        x,y,_,_ = self.rect\n",
    "        P = [(x+int(px), y+int(py)) for (px,py) in pts]\n",
    "        pygame.draw.polygon(self.screen, color, P)\n",
    "\n",
    "    def text(self, font, s, color, pos):\n",
    "        x,y,_,_ = self.rect\n",
    "        self.screen.blit(font.render(s, True, color), (x+pos[0], y+pos[1]))\n",
    "\n",
    "# --- Map / occupancy ---\n",
    "class Map2D:\n",
    "    def __init__(self, cfg: Config, floor_img_path='../figures/floor_plan.png'):\n",
    "        self.cfg = cfg\n",
    "        self.surface = pygame.transform.smoothscale(\n",
    "            pygame.image.load(floor_img_path), (cfg.panel_w, cfg.panel_h)\n",
    "        )\n",
    "        arr = pygame.surfarray.array3d(self.surface)  # (w,h,3)\n",
    "        self.wall_mask = np.all(arr < 128, axis=2).astype(np.bool_)  # True=wall\n",
    "\n",
    "    def cast_beam_fast(self, pos_xy, angle, max_r):\n",
    "        W, H = self.wall_mask.shape\n",
    "        x0, y0 = float(pos_xy[0]), float(pos_xy[1])\n",
    "        c, s = np.cos(angle), np.sin(angle)\n",
    "        for d in range(0, int(max_r), self.cfg.ray_stride):\n",
    "            x = int(x0 + d*c); y = int(y0 + d*s)\n",
    "            if not (0 <= x < W and 0 <= y < H):  # left/top clipped by panel bounds\n",
    "                return None, d\n",
    "            if self.wall_mask[x, y]:\n",
    "                return (x, y), d\n",
    "        return None, int(max_r)\n",
    "\n",
    "# --- LiDAR (ID per grid cell) ---\n",
    "class Lidar:\n",
    "    def __init__(self, cfg: Config, world_map: Map2D):\n",
    "        self.cfg = cfg\n",
    "        self.map = world_map\n",
    "        self.id_by_cell = {}   # (cx,cy) -> lm_id\n",
    "        self.cell_by_id = []   # list indexed by lm_id: (cx,cy)\n",
    "\n",
    "    def cell_of_xy(self, x: float, y: float):\n",
    "        return (int(x)//self.cfg.grid_px, int(y)//self.cfg.grid_px)\n",
    "\n",
    "    def cell_center_xy(self, cell):\n",
    "        cx, cy = cell\n",
    "        g = self.cfg.grid_px\n",
    "        return (cx*g + 0.5*g, cy*g + 0.5*g)\n",
    "\n",
    "    def quantize_meas(self, r: float, phi: float):\n",
    "        rq = self.cfg.range_step_px * round(r / self.cfg.range_step_px)\n",
    "        pq = wrap_angle(self.cfg.bearing_step * round(phi / self.cfg.bearing_step))\n",
    "        return rq, pq\n",
    "\n",
    "    def ensure_id(self, cell):\n",
    "        if cell not in self.id_by_cell:\n",
    "            lm_id = len(self.cell_by_id)\n",
    "            self.id_by_cell[cell] = lm_id\n",
    "            self.cell_by_id.append(cell)\n",
    "        return self.id_by_cell[cell]\n",
    "\n",
    "    def scan(self, gt_pose, heading, rng, max_range_px=200):\n",
    "        fov = np.deg2rad(self.cfg.fov_deg)\n",
    "        angles = (heading + np.linspace(-fov/2, fov/2, self.cfg.num_beams, endpoint=False)) % (2*np.pi)\n",
    "\n",
    "        z_all, c_all = [], []\n",
    "        used_cells = set()\n",
    "        for a in angles:\n",
    "            hit, dist = self.map.cast_beam_fast(gt_pose[:2], a, max_range_px)\n",
    "            if not hit:\n",
    "                continue\n",
    "            hx, hy = hit\n",
    "            cell = self.cell_of_xy(hx, hy)\n",
    "            if cell in used_cells:\n",
    "                continue\n",
    "            used_cells.add(cell)\n",
    "\n",
    "            j = self.ensure_id(cell)\n",
    "\n",
    "            # noisy (r,phi) relative to GT, quantized\n",
    "            true_phi = wrap_angle(a - float(gt_pose[2]))\n",
    "            r_meas   = dist  + rng.normal(0.0, np.sqrt(float(self.cfg.Q[0,0])))\n",
    "            phi_meas = wrap_angle(true_phi + rng.normal(0.0, np.sqrt(float(self.cfg.Q[1,1]))))\n",
    "            r_q, phi_q = self.quantize_meas(r_meas, phi_meas)\n",
    "\n",
    "            z_all.append(np.array([r_q, phi_q], dtype=np.float32))\n",
    "            c_all.append(j)\n",
    "\n",
    "        return z_all, c_all\n",
    "\n",
    "# --- EKF-SLAM (odometry + range/bearing) ---\n",
    "class EKFSLAM:\n",
    "    def __init__(self, cfg: Config):\n",
    "        self.cfg = cfg\n",
    "        self.mu    = None          # [x,y,th, m1x,m1y, ...]\n",
    "        self.Sigma = None\n",
    "        self.seen  = None\n",
    "\n",
    "    # --- state sizing ---\n",
    "    def ensure_state_size(self, N: int, init_pose=None):\n",
    "        req_n = 3 + 2*N\n",
    "        if self.mu is None:\n",
    "            self.mu = np.zeros(req_n, dtype=np.float32)\n",
    "            if init_pose is not None:\n",
    "                self.mu[:3] = init_pose\n",
    "            self.Sigma = np.block([\n",
    "                [np.diag([1e-6, 1e-6, (1*np.pi/180.0)**2]).astype(np.float32), np.zeros((3, 2*N), dtype=np.float32)],\n",
    "                [np.zeros((2*N, 3), dtype=np.float32), np.eye(2*N, dtype=np.float32)*1e6]\n",
    "            ])\n",
    "            self.seen = np.zeros(N, dtype=bool)\n",
    "            return\n",
    "        currN = (self.mu.size - 3)//2\n",
    "        if N > currN:\n",
    "            addN = N - currN\n",
    "            self.mu = np.hstack([self.mu, np.zeros(2*addN, dtype=np.float32)])\n",
    "            top = np.hstack([self.Sigma, np.zeros((3+2*currN, 2*addN), dtype=np.float32)])\n",
    "            bot = np.hstack([np.zeros((2*addN, 3+2*currN), dtype=np.float32), np.eye(2*addN, dtype=np.float32)*1e6])\n",
    "            self.Sigma = np.vstack([top, bot])\n",
    "            self.seen = np.hstack([self.seen, np.zeros(addN, dtype=bool)])\n",
    "\n",
    "    def ensure_state(self, lidar: Lidar, init_pose=None):\n",
    "        self.ensure_state_size(len(lidar.cell_by_id), init_pose=init_pose)\n",
    "\n",
    "    # --- motion (odometry) ---\n",
    "    @staticmethod\n",
    "    def motion_model_odometry(u, x_prev):\n",
    "        dr1, dt, dr2 = u\n",
    "        x_new = x_prev[0] + dt*np.cos(x_prev[2] + dr1)\n",
    "        y_new = x_prev[1] + dt*np.sin(x_prev[2] + dr1)\n",
    "        th_new= wrap_angle(x_prev[2] + dr1 + dr2)\n",
    "        return np.array([x_new, y_new, th_new], dtype=np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def G_inner_odometry(th, u):\n",
    "        dr1, dt, _ = u\n",
    "        c = np.cos(th + dr1); s = np.sin(th + dr1)\n",
    "        return np.array([[0,0,-dt*s],[0,0,dt*c],[0,0,0]], dtype=np.float32)\n",
    "\n",
    "    def predict(self, u):\n",
    "        mu_pred = self.mu.copy()\n",
    "        mu_pred[:3] = self.motion_model_odometry(u, self.mu[:3])\n",
    "        mu_pred[2]  = wrap_angle(float(mu_pred[2]))\n",
    "\n",
    "        Œ£_xx = self.Sigma[:3,:3]\n",
    "        Œ£_xm = self.Sigma[:3,3:]\n",
    "        Gx = np.eye(3, dtype=np.float32) + self.G_inner_odometry(float(self.mu[2]), u)\n",
    "\n",
    "        Œ£_xx_new = Gx @ Œ£_xx @ Gx.T + self.cfg.R_x\n",
    "        Œ£_xm_new = Gx @ Œ£_xm\n",
    "\n",
    "        Sigma_pred = self.Sigma.copy()\n",
    "        Sigma_pred[:3,:3] = Œ£_xx_new\n",
    "        Sigma_pred[:3,3:] = Œ£_xm_new\n",
    "        Sigma_pred[3:,:3] = Œ£_xm_new.T\n",
    "\n",
    "        self.mu, self.Sigma = mu_pred, Sigma_pred\n",
    "\n",
    "    # --- observation / correction ---\n",
    "    @staticmethod\n",
    "    def innovation(z, zhat):\n",
    "        return np.array([float(z[0]) - float(zhat[0]), wrap_angle(float(z[1]) - float(zhat[1]))], dtype=np.float32)\n",
    "\n",
    "    def expected_observation(self, j):\n",
    "        x,y,th = float(self.mu[0]), float(self.mu[1]), float(self.mu[2])\n",
    "        mx,my  = float(self.mu[3+2*j]), float(self.mu[3+2*j+1])\n",
    "        dx,dy  = mx-x, my-y\n",
    "        q      = dx*dx + dy*dy\n",
    "        r      = np.sqrt(max(q, 1e-12))\n",
    "        phi    = wrap_angle(np.arctan2(dy,dx) - th)\n",
    "        return np.array([r,phi], dtype=np.float32), np.array([dx,dy], dtype=np.float32), float(q)\n",
    "\n",
    "    def init_landmark_at_xy(self, j, xy):\n",
    "        if not self.seen[j]:\n",
    "            self.mu[3+2*j]   = float(xy[0])\n",
    "            self.mu[3+2*j+1] = float(xy[1])\n",
    "            self.seen[j] = True\n",
    "\n",
    "    def correct_batch(self, z_list, c_list, lidar: Lidar):\n",
    "        n = self.mu.size\n",
    "        I = np.eye(n, dtype=np.float32)\n",
    "\n",
    "        M = len(z_list)\n",
    "        if M == 0: return\n",
    "\n",
    "        # 1) init unseen LMs at cell centers\n",
    "        for z, j in zip(z_list, c_list):\n",
    "            if not self.seen[j]:\n",
    "                cell = lidar.cell_by_id[j]\n",
    "                cx,cy = lidar.cell_center_xy(cell)\n",
    "                self.init_landmark_at_xy(j, (cx,cy))\n",
    "\n",
    "        # 2) stack H, v\n",
    "        H = np.zeros((2*M, n), dtype=np.float32)\n",
    "        v = np.zeros(2*M, dtype=np.float32)\n",
    "        for i, (z, j) in enumerate(zip(z_list, c_list)):\n",
    "            zhat, delta, q = self.expected_observation(j)\n",
    "            dx,dy = float(delta[0]), float(delta[1]); r = float(zhat[0]); q = max(q, 1e-12)\n",
    "            Hs = (1.0/q) * np.array([\n",
    "                [-r*dx,  -r*dy,   0.0,  r*dx,  r*dy],\n",
    "                [  dy,    -dx,   -q,    -dy,    dx]\n",
    "            ], dtype=np.float32)\n",
    "            r0 = 2*i\n",
    "            H[r0:r0+2, 0:3] = Hs[:,0:3]\n",
    "            cj = 3 + 2*j\n",
    "            H[r0:r0+2, cj:cj+2] = Hs[:,3:5]\n",
    "            v[r0:r0+2] = self.innovation(z, zhat)\n",
    "\n",
    "        R = np.kron(np.eye(M, dtype=np.float32), self.cfg.Q.astype(np.float32))\n",
    "        S = H @ self.Sigma @ H.T + R\n",
    "        V = self.Sigma @ H.T\n",
    "        X = np.linalg.solve(S, V.T).T\n",
    "        self.mu = self.mu + X @ v\n",
    "        self.mu[2] = wrap_angle(float(self.mu[2]))\n",
    "        self.Sigma = (I - X @ H) @ self.Sigma\n",
    "\n",
    "    # nearest-K seen for load shedding\n",
    "    def select_nearest_seen(self, max_k):\n",
    "        ids = np.where(self.seen)[0]\n",
    "        if ids.size == 0: return ids\n",
    "        robot_xy = self.mu[:2].astype(np.float32)\n",
    "        L = self.mu[3:].reshape(-1,2).astype(np.float32)[ids]\n",
    "        d = np.linalg.norm(L - robot_xy[None,:], axis=1)\n",
    "        order = np.argsort(d)\n",
    "        return ids[order[:min(max_k, ids.size)]]\n",
    "\n",
    "# --- App ---\n",
    "class App:\n",
    "    def __init__(self, cfg: Config):\n",
    "        pygame.init()\n",
    "        self.cfg = cfg\n",
    "        self.screen = pygame.display.set_mode(cfg.window_size)\n",
    "        pygame.display.set_caption(\"GT (left) | EKF-SLAM (right)\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.font  = pygame.font.SysFont(None, 18)\n",
    "\n",
    "        # Panels (right panel uses a Panel wrapper that offsets drawing)\n",
    "        self.left  = Panel(self.screen, (0, 0, cfg.panel_w, cfg.panel_h))\n",
    "        self.right = Panel(self.screen, (cfg.panel_w, 0, cfg.panel_w, cfg.panel_h))\n",
    "\n",
    "        # Map + lidar\n",
    "        self.map = Map2D(cfg)\n",
    "        self.lidar = Lidar(cfg, self.map)\n",
    "\n",
    "        # GT / EKF\n",
    "        self.gt_pose = np.array([cfg.panel_w//2, cfg.panel_h//2, 0.0], dtype=np.float32)\n",
    "        self.gt_traj = [self.gt_pose.copy()]\n",
    "\n",
    "        self.ekf = EKFSLAM(cfg)\n",
    "        self.ekf.ensure_state(self.lidar, init_pose=self.gt_pose)  # start aligned\n",
    "\n",
    "        self.ekf_traj = []\n",
    "\n",
    "        # beam sweep\n",
    "        self.beam_speed = 2*np.pi*10\n",
    "        self.beam_angle = 0.0\n",
    "        self.max_range_px = 200\n",
    "\n",
    "        # timer\n",
    "        self.SCAN_EVENT = pygame.USEREVENT + 1\n",
    "        pygame.time.set_timer(self.SCAN_EVENT, cfg.scan_ms)\n",
    "\n",
    "        self.rng = np.random.default_rng(0)\n",
    "\n",
    "    # --- input / steps ---\n",
    "    def step_motion(self, cmd):\n",
    "        # GT\n",
    "        self.gt_pose = self.ekf.motion_model_odometry(cmd, self.gt_pose)\n",
    "        self.gt_traj.append(self.gt_pose.copy()); self.gt_traj = self.gt_traj[-self.cfg.traj_max:]\n",
    "\n",
    "        # EKF predict\n",
    "        self.ekf.ensure_state(self.lidar)  # keep consistent\n",
    "        self.ekf.predict(cmd)\n",
    "        self.ekf_traj.append(self.ekf.mu[:3].copy()); self.ekf_traj = self.ekf_traj[-self.cfg.traj_max:]\n",
    "\n",
    "    def step_scan(self):\n",
    "        # heading (use EKF heading so FOV follows its estimate)\n",
    "        heading = float(self.ekf.mu[2]) if self.ekf.mu is not None else float(self.gt_pose[2])\n",
    "        z_all, c_all = self.lidar.scan(self.gt_pose, heading, self.rng, max_range_px=self.max_range_px)\n",
    "        if not z_all:\n",
    "            return\n",
    "\n",
    "        # NEW: grow EKF after scan (new lm IDs may have appeared)\n",
    "        self.ekf.ensure_state(self.lidar)\n",
    "\n",
    "        # keep ALL unseen\n",
    "        unseen = [(z,j) for z,j in zip(z_all, c_all) if not self.ekf.seen[j]]\n",
    "        # optionally thin seen via nearest-K\n",
    "        if self.cfg.use_nearest and np.any(self.ekf.seen):\n",
    "            allowed = set(int(i) for i in self.ekf.select_nearest_seen(self.cfg.nearest_k_seen))\n",
    "            seen_pairs = [(z,j) for z,j in zip(z_all, c_all) if (self.ekf.seen[j] and (j in allowed))]\n",
    "        else:\n",
    "            seen_pairs = [(z,j) for z,j in zip(z_all, c_all) if self.ekf.seen[j]]\n",
    "\n",
    "        batch = unseen + seen_pairs\n",
    "        if not batch: return\n",
    "\n",
    "        if self.cfg.chunk is None:\n",
    "            z_list, c_list = map(list, zip(*batch))\n",
    "            self.ekf.correct_batch(z_list, c_list, self.lidar)\n",
    "        else:\n",
    "            for s in range(0, len(batch), self.cfg.chunk):\n",
    "                z_chunk, c_chunk = map(list, zip(*batch[s:s+self.cfg.chunk]))\n",
    "                self.ekf.correct_batch(z_chunk, c_chunk, self.lidar)\n",
    "\n",
    "    # --- drawing ---\n",
    "    def draw_left(self):\n",
    "        self.left.clear((30,30,30))\n",
    "        self.left.blit(self.map.surface, (0,0))\n",
    "\n",
    "        # GT traj\n",
    "        for i in range(1, len(self.gt_traj)):\n",
    "            p0 = i2(self.gt_traj[i-1][:2]); p1 = i2(self.gt_traj[i][:2])\n",
    "            pygame.draw.line(self.screen, (0,150,255),\n",
    "                             (self.left.ox+p0[0], p0[1]), (self.left.ox+p1[0], p1[1]), 2)\n",
    "\n",
    "        # GT robot (triangle)\n",
    "        gx,gy,gth = map(float, self.gt_pose)\n",
    "        pts = [\n",
    "            (gx + 15*np.cos(gth),     gy + 15*np.sin(gth)),\n",
    "            (gx + 10*np.cos(gth+2.5), gy + 10*np.sin(gth+2.5)),\n",
    "            (gx + 10*np.cos(gth-2.5), gy + 10*np.sin(gth-2.5))\n",
    "        ]\n",
    "        self.left.polygon((0,150,255), pts)\n",
    "\n",
    "        # rotating beam (on GT)\n",
    "        bx,by = i2(self.gt_pose[:2])\n",
    "        hit, dist = self.map.cast_beam_fast(self.gt_pose[:2], self.beam_angle, self.max_range_px)\n",
    "        if hit:\n",
    "            ex,ey = hit\n",
    "        else:\n",
    "            ex = int(bx + self.max_range_px*np.cos(self.beam_angle))\n",
    "            ey = int(by + self.max_range_px*np.sin(self.beam_angle))\n",
    "        pygame.draw.line(self.screen, (255,0,0),\n",
    "                         (self.left.ox+bx, by), (self.left.ox+ex, ey), 2)\n",
    "\n",
    "    def draw_right(self):\n",
    "        # Everything drawn via Panel methods -> automatically centered to right panel\n",
    "        self.right.clear((255,255,255))\n",
    "\n",
    "        # EKF traj\n",
    "        for i in range(1, len(self.ekf_traj)):\n",
    "            p0 = i2(self.ekf_traj[i-1][:2]); p1 = i2(self.ekf_traj[i][:2])\n",
    "            pygame.draw.line(self.screen, (200,200,60),\n",
    "                             (self.right.ox+p0[0], p0[1]), (self.right.ox+p1[0], p1[1]), 2)\n",
    "\n",
    "        # EKF robot\n",
    "        if self.ekf.mu is not None:\n",
    "            px,py,pth = map(float, self.ekf.mu[:3])\n",
    "            self.right.circle((200,200,60), (px,py), 8)\n",
    "\n",
    "        # EKF landmarks\n",
    "        if (self.ekf.mu is not None) and (self.ekf.mu.size > 3):\n",
    "            estL = self.ekf.mu[3:].reshape(-1,2)\n",
    "            for (mx,my), seen in zip(estL, self.ekf.seen):\n",
    "                color = (255,0,0) if seen else (180,180,180)\n",
    "                self.right.circle(color, (mx,my), 2)\n",
    "\n",
    "        # HUD\n",
    "        fps = self.clock.get_fps()\n",
    "        hud = (f\"FPS:{fps:4.1f} | Beams:{self.cfg.num_beams} @ {1000//self.cfg.scan_ms}Hz | Grid:{self.cfg.grid_px}px | \"\n",
    "               f\"Nearest-K:{'ON' if self.cfg.use_nearest else 'OFF'}({self.cfg.nearest_k_seen}) | \"\n",
    "               f\"LMs:{len(self.lidar.cell_by_id)}\")\n",
    "        self.right.text(self.font, hud, (10,10,10), (10,10))\n",
    "\n",
    "    # --- main loop ---\n",
    "    def run(self):\n",
    "        running = True\n",
    "        while running:\n",
    "            dt = self.clock.tick(60) / 1000.0\n",
    "            self.beam_angle = (self.beam_angle + self.beam_speed*dt) % (2*np.pi)\n",
    "\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    running = False\n",
    "\n",
    "                elif ev.type == pygame.KEYDOWN:\n",
    "                    if   ev.key == pygame.K_UP:    cmd = np.array([0.0, self.cfg.trans_step, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_LEFT:  cmd = np.array([-self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_RIGHT: cmd = np.array([ self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_n:     self.cfg.use_nearest = not self.cfg.use_nearest; cmd = None\n",
    "                    else: cmd = None\n",
    "                    if cmd is not None:\n",
    "                        self.step_motion(cmd)\n",
    "\n",
    "                elif ev.type == self.SCAN_EVENT:\n",
    "                    self.step_scan()\n",
    "\n",
    "            # Draw\n",
    "            self.draw_left()\n",
    "            self.draw_right()\n",
    "            pygame.display.flip()\n",
    "\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "# -------------------- Run --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    App(cfg).run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca729f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b5fbc",
   "metadata": {},
   "source": [
    "### üå± <span style=\"color:#a4d4a3\">**What's next?**</span>\n",
    "\n",
    "While the **Extended Kalman Filter (EKF)** improved upon the standard **Kalman Filter (KF)** by handling non-linear models, there are still limitations.  \n",
    "We briefly introduce the **Unscented Kalman Filter (UKF)** as an alternative.\n",
    "\n",
    "<span style=\"color:#00703c\">**KF vs. EKF**</span>\n",
    "\n",
    "- EKF is an extension of the KF.  \n",
    "- Designed to handle non-linearities.  \n",
    "- Performs <span style=\"color:#ffa500\">**local linearizations**</span> around the current estimate.  \n",
    "- Works well in practice for <span style=\"color:#ffa500\">**moderate non-linearities**</span> and uncertainty.  \n",
    "\n",
    "#### ‚ú® <span style=\"color:#a4d4a3\">**Unscented Kalman Filter (UKF)**</span>\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "- KF requires strictly <span style=\"color:#ffa500\">**linear models**</span>.  \n",
    "- EKF approximates non-linear functions with a <span style=\"color:#ffa500\">**Taylor expansion**</span>.  \n",
    "\n",
    "üí° *Is there a better way to deal with non-linear transformations?*  \n",
    "\n",
    "The **UKF** avoids explicit Jacobians. Instead, it uses the **Unscented Transform**: it computes a set of carefully chosen <span style=\"color:#ffa500\">**sigma points**</span>, propagates them through the non-linear motion and measurement models, and then reconstructs a Gaussian distribution from the transformed points.\n",
    "\n",
    "<span style=\"color:#00703c\">**UKF vs. EKF**</span>\n",
    "\n",
    "- Produces the <span style=\"color:#ffa500\">**same results as EKF**</span> for linear models.  \n",
    "- Provides a <span style=\"color:#ffa500\">**better approximation**</span> for non-linear models.  \n",
    "- <span style=\"color:#ffa500\">**No Jacobians**</span> are required.  \n",
    "- Computational complexity is <span style=\"color:#ffa500\">**similar**</span>, but UKF can be slightly slower.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca25b2",
   "metadata": {},
   "source": [
    "### üìö <span style=\"color:#a4d4a3\">**Reading Material**</span>\n",
    "\n",
    "**EKF-SLAM**\n",
    "- Thrun et al.: *\"Probabilistic Robotics\"*, **Chapter 10**\n",
    "\n",
    "**Unscented Transform and UKF**\n",
    "- Thrun et al.: *\"Probabilistic Robotics\"*, **Chapter 3.4**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
