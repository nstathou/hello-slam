{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6dbe6e",
   "metadata": {},
   "source": [
    "## üìå <span style=\"color:#a4d4a3\">**Introduction to SLAM**</span>\n",
    "\n",
    "In this notebook we give a **short overview** of **Simultaneous Localization and Mapping (SLAM)** ‚Äî **what it is**, **why we need it**, and **how it works** at a high level. We will also outline the **main components**, the **approaches we‚Äôll study**, some **helpful prerequisites**, and provide **suggested readings**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70244764",
   "metadata": {},
   "source": [
    "\n",
    "### ü§î <span style=\"color:#a4d4a3\"> **What is SLAM?**</span>\n",
    "\n",
    "SLAM is the problem of estimating a robot‚Äôs <span style=\"color:#ffa500\">**pose**</span> and a <span style=\"color:#ffa500\">**map**</span> of the environment <span style=\"color:#ffa500\">**at the same time**</span>. Formally, given controls $u_{1:T}$ and observations $z_{1:T}$, SLAM estimates the joint posterior:\n",
    "\n",
    "$$ p(x_{1:T}, m | z_{1:T}, u_{1:T})$$\n",
    "\t‚Äã\n",
    "where $x_{1:T}$ ‚Äãare the robot poses and $m$ is the map.\n",
    "\n",
    "It is often described as a <span style=\"color:#ffa500\">**chicken-and-egg problem**</span>:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Localization:**</span> estimating the robot‚Äôs <span style=\"color:#ffa500\">**position**</span> and <span style=\"color:#ffa500\">**orientation**</span> (pose).  \n",
    "\n",
    "- <span style=\"color:#00703c\">**Mapping:**</span> building a <span style=\"color:#ffa500\">**consistent representation**</span> of the world.  \n",
    "\n",
    "- <span style=\"color:#00703c\">**SLAM:**</span> solving both <span style=\"color:#ffa500\">**simultaneously**</span>, where each depends on the other.\n",
    "\n",
    "This coupling makes SLAM challenging:\n",
    "\n",
    "- A map helps localization, but\n",
    "- <span style=\"color:#ffa500\">**Good localization**</span> is required to build a <span style=\"color:#ffa500\">**good map**</span>.\n",
    "\n",
    "Typical assumptions: \n",
    "\n",
    "- **static world** during mapping\n",
    "- **Markovian** process/measurement models\n",
    "- **Conditional independence** structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02b30d",
   "metadata": {},
   "source": [
    "\n",
    "### ‚ùî <span style=\"color:#a4d4a3\"> **Why SLAM?** </span>\n",
    "\n",
    "SLAM is a foundamental of **autonomous robotics**:  \n",
    "\n",
    "- Enables operation in <span style=\"color:#ffa500\">**unknown**</span> and infrastructure-free environments.\n",
    "- Underpins most <span style=\"color:#ffa500\">**navigation**</span> and exploration systems.\n",
    "- Critical for autonomous driving, search and rescue, inspection, warehouses, planetary exploration, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280aa49",
   "metadata": {},
   "source": [
    "\n",
    "### üí° <span style=\"color:#a4d4a3\"> **How does SLAM work?** </span>\n",
    "\n",
    "SLAM combines <span style=\"color:#ffa500\">**sensor data**</span> with <span style=\"color:#ffa500\">**probabilistic estimation**</span> to track both the robot‚Äôs poses and the state of the map.\n",
    "\n",
    "Common sensors:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Visual SLAM (vSLAM):**</span> monocular, stereo or RGB-D cameras that extract and <span style=\"color:#ffa500\">**track image features**</span> (lines, edges, etc) or directly align intensity/depth; great when there are distinct visual cues.  \n",
    "- <span style=\"color:#00703c\">**Range-based SLAM:**</span> 2D/3D LiDAR, radar, sonar producing sparse or dense point clouds; robust to lighting and often more geometrically accurate; primarly <span style=\"color:#ffa500\">**scan matching**</span>.\n",
    "- <span style=\"color:#00703c\">**Multi-modal fusion:**</span> fuses IMU, wheel odometry, GPS (if available), LiDAR or vision to increase robustness and reduce drift (e.g., LiDAR-Visual‚ÄìInertial odometry).\n",
    "\n",
    "Two main components:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Front-end:**</span> Acquires raw sensor data, **extracts key features**, and performs **data association**. It converts measurements into an <span style=\"color:#ffa500\">**intermediate representation**</span>, e.g., landmark observations or relative-pose constraints that can be fed to the estimator.\n",
    "- <span style=\"color:#00703c\">**Back-end:**</span> Performs **estimation** and **optimization** over those inputs to produce a consistent robot trajectory and map. It solves the underlying state-estimation/optimization problem to <span style=\"color:#ffa500\">**refine poses and landmarks**</span>.\n",
    "\n",
    "Both front-end and back-end operate in a <span style=\"color:#ffa500\">**loop**</span>, continuously updating the map and robot pose in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53d5ab",
   "metadata": {},
   "source": [
    "### üîë <span style=\"color:#a4d4a3\">**Main SLAM Approaches**</span>\n",
    "\n",
    "- <span style=\"color:#00703c\">**Kalman Filter Family (EKF/UKF):**</span>  Recursive **prediction + correction** using Gaussian models. EKF-SLAM was the first practical SLAM algorithm.  \n",
    "\n",
    "- <span style=\"color:#00703c\">**Particle Filters (FastSLAM):**</span> Represent uncertainty with **samples (particles)**. Particle filtering uses a set of particles to represent the posterior distribution of a stochastic process given the noisy and/or partial observations.  \n",
    "\n",
    "- <span style=\"color:#00703c\">**Least Squares (Graph-based):**</span> Model SLAM as a **graph optimization** problem: nodes = robot poses/landmarks, edges = constraints (odometry, observations). Optimize to find the most consistent solution that minimizes an objective function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb0620",
   "metadata": {},
   "source": [
    "### ‚è≥ <span style=\"color:#a4d4a3\">**SLAM Timeline**</span>\n",
    "\n",
    "- <span style=\"color:#00703c\">**1985‚Äì1990:**</span> <span style=\"color:#ffa500\">**Probabilistic foundations;</span>** mapping + localization as one estimation problem. Key idea: treat mapping and localization jointly, with correlations between landmarks and pose as the essential structure. Historical genesis commonly traced to conversations and papers around the 1986 IEEE ICRA; formalization of correlated uncertainties and consistent mapping followed. The term SLAM had not yet been coined, but the estimation structure was recognized.\n",
    "    - *R. Chatila and J.P. Laumond, ‚ÄúPosition referencing and consistent world modeling for mobile robots,‚Äù in Proc. IEEE Int. Conf. Robot. Automat., 1985, pp. 138‚Äì143.*\n",
    "    - *R. Smith and P. Cheesman, ‚ÄúOn the representation of spatial uncertainty,‚Äù International Journal of Robotic Research, vol. 5, no. 4, pp. 56‚Äì68, 1987.*\n",
    "    - *H. Durrant-Whyte, ‚ÄúUncertain geometry in robotics,‚Äù IEEE Trans. Robot. Automat., vol. 4, no. 1, pp. 23‚Äì31, 1988.*\n",
    "    - *N. Ayache and O. Faugeras, ‚ÄúBuilding, registrating, and fusing noisy visual maps,‚Äù Int. J. Robot. Res., vol. 7, no. 6, pp. 45‚Äì65, 1988.*\n",
    "    - *J. Crowley, ‚ÄúWorld modeling and position estimation for a mobile robot using ultra-sonic ranging,‚Äù in Proc. IEEE Int. Conf. Robot. Automat., 1989, pp. 674‚Äì681.*\n",
    "    - *R. Smith, M. Self, and P. Cheeseman, ‚ÄúEstimating uncertain spatial relationships in robotics,‚Äù in Autonomous Robot Vehicles, I.J. Cox and G.T. Wilfon, Eds. New York: Springer-Verlag, pp. 167‚Äì193, 1990.*\n",
    "    - *H. Durrant-Whyte and T. Bailey, \"Simultaneous localization and mapping: part I,\" in IEEE Robotics & Automation Magazine, vol. 13, no. 2, pp. 99-110, June 2006.* \n",
    "\n",
    "- <span style=\"color:#00703c\"> **1991‚Äì1995:** </span> <span style=\"color:#ffa500\">**Convergence results; the name SLAM;</span>** early implementations. Key idea: proofs/arguments that the joint estimation problem is convergent and that growing correlations are useful; the acronym SLAM appears in the mid‚Äë1990s survey/position literature; early EKF‚Äëbased implementations across domains (indoor, outdoor, underwater).\n",
    "    - *.J. Leonard and H.F. Durrant-Whyte, ‚ÄúSimultaneous map building and localisation for an autonomous mobile robot,‚Äù in Proc. IEEE Int. Workshop Intell. Robots Syst. (IROS), Osaka, Japan, 1991, pp. 1442‚Äì1447.*\n",
    "    - *J.J. Leonard and H.F. Durrant-Whyte, Directed Sonar Navigation. Norwell, MA: Kluwer, 1992.*\n",
    "    - *W.D. Renken, ‚ÄúConcurrent localization and map building for mobile robots using ultrasonic sensors,‚Äù in Proc. IEEE Int. Workshop Intell. Robots Syst. (IROS), 1993.*\n",
    "    - *H. Durrant-Whyte, D. Rye, and E. Nebot, ‚ÄúLocalisation of automatic guided vehicles,‚Äù in Robotics Research: The 7th International Symposium (ISRR‚Äô95), G. Giralt and G. Hirzinger, Eds. New York: Springer Verlag, pp. 613‚Äì625, 1996.*\n",
    "\n",
    "- <span style=\"color:#00703c\"> **1996‚Äì2000:** </span> <span style=\"color:#ffa500\">**EKF‚ÄëSLAM becomes the default;**</span> data association emerges as a central issue. Key idea: EKF‚ÄëSLAM matures; the community confronts computational complexity (quadratic scaling in map size), nonlinearity, and data association as key roadblocks; occupancy mapping in parallel for dense maps.\n",
    "    - *M. Csorba and H.F. Durrant-Whyte, ‚ÄúA new approach to simultaneous localisation and map building,‚Äù in Proc. SPIE Aerosense, Orlando, FL, 1996.*\n",
    "    - *J.A. Castellanos, J.D. Tard√≥s, and G. Schmidt, ‚ÄúBuilding a global map of the environment of a mobile robot: The importance of correlations,‚Äù in Proc. IEEE Int. Conf. Robot. Automat., 1997, pp. 1053‚Äì1059.*\n",
    "    - *S. Thrun, D. Fox, and W. Burgard, ‚ÄúA probabilistic approach to concurrent mapping and localization for mobile robots,‚Äù Mach. Learning, vol. 31, no. 1, pp. 29‚Äì53, 1998.*\n",
    "    - *K.S. Chong and L. Kleeman, ‚ÄúFeature-based mapping in real, large scale environments using an ultrasonic array,‚Äù Int. J. Robot. Res., vol. 18, no. 1, pp. 3‚Äì19, 1999.*\n",
    "    - *J. Hollerbach and D. Koditscheck, Eds., Robotics Research, The Ninth International Symposium (ISRR‚Äô99). New York: Springer-Verlag, 2000.*\n",
    "    - *J.J. Leonard and H.J.S. Feder, ‚ÄúA computational efficient method for large-scale concurrent mapping and localisation,‚Äù in Robotics Research, The Ninth International Symposium (ISRR‚Äô99), J. Hollerbach and D. Koditscheck, Eds. New York: Springer-Verlag, pp. 169‚Äì176, 2000.*\n",
    "    - *S.B. Williams, P. Newman, G. Dissanayake, and H.F. Durrant-Whyte, ‚ÄúAutonomous underwater simultaneous localisation and map building,‚Äù in Proc. IEEE Int. Conf. Robot. Automat. (ICRA), San Francisco, CA, Apr. 2000, pp. 1793‚Äì1798.*\n",
    "\n",
    "- <span style=\"color:#00703c\"> **2001‚Äì2005:** </span> <span style=\"color:#ffa500\">**Particle‚Äëfilter era; FastSLAM;**</span> scalable mapping with RBPF. Key idea: Rao‚ÄìBlackwellized particle filters (FastSLAM) factorize the problem (pose with particles, landmarks analytically), enabling much larger feature maps and grid maps; robustness to some nonlinearities/outliers improves relative to naive EKF.\n",
    "    - *J.E. Guivant and E.M. Nebot, ‚ÄúOptimization of the simultaneous localization and map-building algorithm for real-time implementation,‚Äù IEEE Trans. Robot. Automat., vol. 17, no. 3, pp. 242‚Äì257, 2001.*\n",
    "    - *G. Dissanayake, P. Newman, H.F. Durrant-Whyte, S. Clark, and M. Csobra, ‚ÄúA solution to the simultaneous localisation and mapping (SLAM) problem,‚Äù IEEE Trans. Robot. Automat., vol. 17, no. 3, pp. 229‚Äì241, 2001.*\n",
    "    - *D. Crisan and A. Doucet, ‚ÄúA survey of convergence results on particle filtering methods for practitioners,‚Äù IEEE Trans. Signal Processing, vol. 50, no. 3, pp. 736‚Äì746, 2002.*\n",
    "    - *J.J. Leonard, R.J. Rikoski, P.M. Newman, and M.C. Bosse, ‚ÄúMapping partially observable features from multiple uncertain vantage points,‚Äù Int. J. Robot. Res., vol. 21, no. 10‚Äì11, pp. 943‚Äì975, 2002.*\n",
    "    - *M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit, ‚ÄúFast-SLAM: A factored solution to the simultaneous localization and mapping problem,‚Äù in Proc. AAAI Nat. Conf. Artif. Intell., 2002, pp. 593‚Äì598.*\n",
    "    - *M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit, ‚ÄúFast-SLAM 2.0: An improved particle filtering algorithm for simultaneous localization and mapping that provably converges,‚Äù in Proc. Int. Joint Conf. Artif. Intell., 2003, pp. 1151‚Äì1156.*\n",
    "    - *A.J. Davison, Y.G. Cid, and N. Kita, ‚ÄúReal-time 3D SLAM with wide-angle vision,‚Äù in Proc. IFAC/EURON Symp. Intell. Auton. Vehicles, 2004.*\n",
    "    - *K. Konolige, ‚ÄúLarge-scale map-making,‚Äù in Proc. Nat. Conf. AI (AAAI), 2004, pp. 457‚Äì463.*\n",
    "    - *S. Thrun, Y. Liu, D. Koller, A. Ng, and H. Durrant-Whyte, ‚ÄúSimultaneous localisation and mapping with sparse extended information filters,‚Äù Int. J. Robot. Res., vol. 23, no. 7‚Äì8, pp. 693‚Äì716, 2004.*\n",
    "\n",
    "- <span style=\"color:#00703c\"> **2006‚Äì2010:** </span> <span style=\"color:#ffa500\">**Smoothing/optimization renaissance; graph‚Äëbased SLAM;**</span> iSAM. Key idea: exploit sparsity (information matrix / factor graphs); re‚Äëcast SLAM as nonlinear least squares on a graph of poses/landmarks; incremental smoothing (iSAM) and modern sparse linear algebra make large‚Äëscale SLAM practical and accurate.\n",
    "    - *H. Durrant‚ÄëWhyte and T. Bailey, ‚ÄúSimultaneous localization and mapping: Part I,‚Äù IEEE Robot. Autom. Mag., vol. 13, no. 2, pp. 99‚Äì110, 2006.*\n",
    "    - *T. Bailey and H. F. Durrant‚ÄëWhyte, ‚ÄúSimultaneous localization and mapping (SLAM): Part II,‚Äù IEEE Robot. Autom. Mag., vol. 13, no. 3, pp. 108‚Äì117, 2006.* \n",
    "    - *M. Kaess, A. Ranganathan, and F. Dellaert, ‚ÄúiSAM: Incremental smoothing and mapping,‚Äù IEEE Trans. Robot., vol. 24, no. 6, pp. 1365‚Äì1378, 2008.*\n",
    "    - *G. Grisetti, R. K√ºmmerle, C. Stachniss, and W. Burgard, ‚ÄúA tutorial on graph‚Äëbased SLAM,‚Äù IEEE Intell. Transp. Syst. Mag., vol. 2, no. 4, pp. 31‚Äì43, 2010.*\n",
    "    \n",
    "- <span style=\"color:#00703c\"> **2011‚Äì2015:**</span> <span style=\"color:#ffa500\">**Robust, general graph optimization;**</span> visual SLAM goes mainstream. Key idea: general(ized) graph optimizers (e.g., g2o) and mature front‚Äëends drive robust performance; visual SLAM systems achieve high accuracy and reliability. Direct (photometric) and feature‚Äëbased pipelines both advance.\n",
    "    - *R. K√ºmmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard, ‚Äúg2o: A general framework for (hyper) graph optimization,‚Äù in Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 3607‚Äì3613, 2011.*\n",
    "    - *M. Kaess, H. Johannsson, R. Roberts, V. Ila, J. J. Leonard, and F. Dellaert, ‚ÄúiSAM2: Incremental smoothing and mapping using the Bayes tree,‚Äù Int. J. Robot. Res., vol. 31, no. 2, pp. 216‚Äì235, 2012.*\n",
    "    - *J. Engel, T. Sch√∂ps, and D. Cremers, ‚ÄúLSD‚ÄëSLAM: Large‚Äëscale direct monocular SLAM,‚Äù in Proc. Eur. Conf. Comput. Vis. (ECCV), LNCS 8690, pp. 834‚Äì849, 2014.*\n",
    "    - *R. Mur‚ÄëArtal, J. M. M. Montiel, and J. D. Tard√≥s, ‚ÄúORB‚ÄëSLAM: A versatile and accurate monocular SLAM system,‚Äù IEEE Trans. Robot., vol. 31, no. 5, pp. 1147‚Äì1163, 2015.*\n",
    "\n",
    "- <span style=\"color:#00703c\"> **2016‚Äì2020:**</span> <span style=\"color:#ffa500\">**Visual‚Äìinertial smoothing;**</span> robust outlier handling; theory of certifiable methods. Key idea: tight visual‚Äìinertial smoothing with IMU preintegration on manifolds; robust back‚Äëends for outliers/loop closures; theory and algorithms for certifiably optimal pose‚Äëgraph optimization (PGO).\n",
    "    - *J. Engel, V. Koltun, and D. Cremers, ‚ÄúDirect sparse odometry,‚Äù IEEE Trans. Pattern Anal. Mach. Intell., vol. 40, no. 3, pp. 611‚Äì625, 2018.*\n",
    "    - *R. Mur‚ÄëArtal and J. D. Tard√≥s, ‚ÄúORB‚ÄëSLAM2: An open‚Äësource SLAM system for monocular, stereo, and RGB‚ÄëD cameras,‚Äù IEEE Trans. Robot., vol. 33, no. 5, pp. 1255‚Äì1262, 2017.*\n",
    "    - *T. Qin, P. Li, and S. Shen, ‚ÄúVINS‚ÄëMono: A robust and versatile monocular visual‚Äìinertial state estimator,‚Äù IEEE Trans. Robot., vol. 34, no. 4, pp. 1004‚Äì1020, 2018.*\n",
    "    - *T. Shan, B. Englot, D. Meyers, W. Wang, C. Ratti, and D. Rus, ‚ÄúLIO‚ÄëSAM: Tightly‚Äëcoupled lidar‚Äìinertial odometry via smoothing and mapping,‚Äù in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 5135‚Äì5142, 2020.*\n",
    "    - *C. Cadena et al., \"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age,\" in IEEE Trans. Robot., vol. 32, no. 6, pp. 1309-1332, 2016.*\n",
    "\n",
    "- <span style=\"color:#00703c\"> **2021‚Äì2025:**</span> <span style=\"color:#ffa500\">**Differentiable & learned SLAM;**</span> neural scene representations; towards Spatial AI. Key idea: end-to-end differentiable optimization (e.g., differentiable BA) and learned front-ends (optical flow, features) augment classical SLAM; neural radiance fields (NeRF) and 3D Gaussian Splatting become practical map representations integrated with SLAM. The DARPA Subterranean Challenge also accelerated advances in large-scale SLAM, multi-robot coordination, and sensor fusion under extreme conditions. At the same time, the field expands toward Spatial AI, where SLAM pipelines are enriched with metric-semantic mapping and 3D scene graphs, enabling robots to build joint geometric-semantic world models that support higher-level reasoning and task execution.\n",
    "    - *Z. Teed and J. Deng, ‚ÄúDROID‚ÄëSLAM: Deep visual SLAM for monocular, stereo, and RGB‚ÄëD cameras,‚Äù in Adv. Neural Inf. Process. Syst. (NeurIPS), pp. 16558‚Äì16569, 2021.*\n",
    "    - *Z. Zhu, S. Peng, V. Larsson, W. Xu, H. Bao, Z. Cui, M. R. Oswald, and M. Pollefeys, ‚ÄúNICE‚ÄëSLAM: Neural implicit scalable encoding for SLAM,‚Äù in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 12786‚Äì12796, 2022.*\n",
    "    - *W. Xu, Y. Cai, D. He, J. Lin, and F. Zhang, ‚ÄúFAST‚ÄëLIO2: Fast direct lidar‚Äìinertial odometry,‚Äù IEEE Trans. Robot., vol. 38, no. 4, pp. 2053‚Äì2073, 2022.*\n",
    "    - *Y. Chang et al., \"LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging Large-Scale Underground Environments,\" in IEEE Robot. and Auto. Letters, vol. 7, no. 4, pp. 9175-9182, 2022*\n",
    "    - *Hughes, N., Chang, Y., & Carlone, L. (2022). Hydra: A Real-time Spatial Perception System for 3D Scene Graph Construction and Optimization. Robotics: Science and Systems XVIII.*\n",
    "    - *Hughes N, Chang Y, Hu S, et al. Foundations of spatial perception for robotics: Hierarchical representations and real-time systems. The Inter. Jour. of Robot. Res.. 2024;43(10):1457-1505.*\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>üö® <strong><span style=\"color:#e74c3c\">Disclaimer:</span></strong></summary>\n",
    "\n",
    "This list highlights a <span style=\"color:#ffa500\">**small subset**</span> of the vast SLAM literature. The SLAM community is built on the contributions of <span style=\"color:#ffa500\">**hundreds of researchers worldwide**</span>, and every work plays an important role in advancing the field. If you are diving deeper, please explore beyond these references ‚Äî from early Kalman filter‚Äìbased methods to modern learning-based and multi-robot SLAM systems.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fc44e",
   "metadata": {},
   "source": [
    "### üìú <span style=\"color:#a4d4a3\">**Prerequisites** (nice to have)</span>\n",
    "\n",
    "Having knowledge on the following will help better understand and derive the main SLAM concepts, no need to be an expert.\n",
    "\n",
    "- **Probability/statistics:** Bayes rule, Gaussians, MAP/MLE, etc.\n",
    "- **Linear algebra:** vectors, matrix multiplication, eigen decomposition, etc.\n",
    "- **Calculus and Analysis:** Taylor-expansion, derivatives, etc.\n",
    "- **Optimization:** Gauss-Newton, Levenberg‚ÄìMarquardt, etc.\n",
    "- **Programming:** Python (for the code notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebdf76",
   "metadata": {},
   "source": [
    "### üìö <span style=\"color:#a4d4a3\">**Reading Material**</span>\n",
    "\n",
    "##### **Videos**\n",
    "\n",
    "- If you are serious about SLAM and want an in-depth study, this series is <span style=\"color:#ffa500\">**a must**</span>:\n",
    "    - [Full SLAM Course on Youtube by Prof. Cyrill Stachniss](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_)\n",
    "\n",
    "- A nice tutorial on running SLAM in ROS2:\n",
    "    - [Easy SLAM with ROS using slam_toolbox](https://www.youtube.com/watch?v=ZaiA3hWaRzE)\n",
    "\n",
    "##### **Books**\n",
    "\n",
    "- An excellent book on probabilistic robotics with an indepth treatment:\n",
    "    - [Sebastian Thrun, Wolfram Burgard, and Dieter Fox. 2005. Probabilistic Robotics (Intelligent Robotics and Autonomous Agents). The MIT Press.](https://mitpress.mit.edu/9780262201629/probabilistic-robotics/)\n",
    "\n",
    "- An introduction to robotics in general that includes Localizition:\n",
    "    - [Peter Corke. 2017. Robotics, Vision and Control: Fundamental Algorithms In MATLAB, Second Edition (2nd. ed.). Springer Publishing Company, Incorporated](https://link.springer.com/book/10.1007/978-3-319-54413-7)\n",
    "\n",
    "- Pure State Estimation for Robotics book:\n",
    "    - [Timothy D. Barfoot. 2024. State Estimation for Robotics (2nd. ed.). Cambridge University Press, USA.](https://www.cambridge.org/us/universitypress/subjects/computer-science/computer-graphics-image-processing-and-robotics/state-estimation-robotics-second-edition-2nd-edition?format=HB&isbn=9781009299893&utm_source=chatgpt.com)\n",
    "\n",
    "- The most recent and complete handbook on SLAM:\n",
    "    - [From Localization and Mapping to Spatial Intelligence (SLAM Handbook)](https://github.com/SLAM-Handbook-contributors/slam-handbook-public-release)\n",
    "\n",
    "- A Tutorial Approach to Simultaneous Localization and Mapping:\n",
    "    - [SLAM for Dummies](https://dspace.mit.edu/bitstream/handle/1721.1/119149/16-412j-spring-2005/contents/projects/1aslam_blas_repo.pdf)\n",
    "\n",
    "##### **Papers**\n",
    "\n",
    "- A brief overview on the history of SLAM and the solutions:\n",
    "    - [Simultaneous Localization and Mapping Part I](https://ieeexplore.ieee.org/document/1638022) & [II](https://ieeexplore.ieee.org/document/1678144)\n",
    "\n",
    "- A tutorial specifically for Graph-based SLAM:\n",
    "    - [A Tutorial on Graph-Based SLAM](https://ieeexplore.ieee.org/document/5681215)\n",
    "\n",
    "- A tutorial specifically for Particle Filter localization:\n",
    "    - [A particle filter tutorial for mobile robot localization](https://www.researchgate.net/publication/244978679_A_particle_filter_tutorial_for_mobile_robot_localization)\n",
    "\n",
    "\n",
    "##### **Other**\n",
    "\n",
    "- A book on Bayesian and Kalman Filters with Python implementations: [Kalman-and-Bayesian-Filters-in-Python](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)\n",
    "    - By *Roger Labbe*\n",
    "\n",
    "- SLides on an overview of the SLAM methods: [SLAM Tutorial Slides](https://www.cs.columbia.edu/~allen/F19/NOTES/slam_pka.pdf)\n",
    "    - By *Marios Xanthidis, C. Stachniss, P. Allen, C. Fermuller, Paul Furgale , Margarita Chli, Marco Hutter, Martin Rufli, Davide Scaramuzza, Roland Siegwart*\n",
    "- A github with some python functions for SLAM: [SLAM-python](https://github.com/DanielsKraus/SLAM-python/tree/master) \n",
    "    - By *Daniels Kraus*\n",
    "\n",
    "- A nice blog post on Gaph SLAM: [Graph SLAM: From Theory to Implementation](https://federicosarrocco.com/blog/graph-slam-tutorial)\n",
    "    - By *Federico Sarrocco*\n",
    "\n",
    "- Pose Graph SLAM 2D/3D implementations using GTSAM: [Pose-Graph-SLAM](https://github.com/DhyeyR-007/Pose-Graph-SLAM)\n",
    "    - By *Dhyey Manish Rajani*\n",
    "\n",
    "- More on Recursive Bayesian Filtering: [Introduction to recursive Bayesian filtering](https://people.csail.mit.edu/mrub/talks/filtering.pdf)\n",
    "    - By *Michael Rubinstein*\n",
    "\n",
    "- Last but not least, the SLAM toolbox for ROS2: [slam_toolbox](https://github.com/SteveMacenski/slam_toolbox)\n",
    "    - By *Steve Macenski*\n",
    "\n",
    "<span style=\"color:#00703c\">**-**</span>\n",
    "<span style=\"color:#a4d4a3\">**-**</span>\n",
    "<span style=\"color:#ffa500\">**-**</span>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
