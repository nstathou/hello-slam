{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdbbdcc",
   "metadata": {},
   "source": [
    "# <span style=\"color:#a4d4a3\">**Feature-based SLAM with Particle Filters (FastSLAM 1.0)**</span>\n",
    "\n",
    "Within this module we <span style=\"color:#ffa500\">**formulate and implement**</span> a feature-based SLAM using a <span style=\"color:#ffa500\">**Rao‚ÄìBlackwellized Particle Filter**</span> (FastSLAM).\n",
    "\n",
    "### <span style=\"color:#a4d4a3\">**Particle Representation**</span>\n",
    "\n",
    "As we saw in the previous module, the particles are a <span style=\"color:#00703c\">**set of weighted samples**</span>:\n",
    "\n",
    "$$\n",
    "\\mathcal{X} = \\left\\{\\left\\langle x^{[i]},\\,w^{[i]}\\right\\rangle\\right\\}_{i=1,\\ldots,N}\n",
    "$$\n",
    "\n",
    "where each sample is a <span style=\"color:#ffa500\">**hypothesis about the state**</span>.\n",
    "\n",
    "As we saw in the Kalman Filter modules, for feature‚Äìbased SLAM, the state is:\n",
    "\n",
    "$$\n",
    "x=(x_{1:t}, m_{1,x}, m_{1,y}, m_{2,x}, m_{2,y}, \\ldots, m_{M,x}, m_{M,y})^T\n",
    "$$\n",
    "\n",
    "where $x_{1:t}$ are robot <span style=\"color:#ffa500\">**poses**</span> and $m_j$ are the <span style=\"color:#ffa500\">**landmark positions**</span>.\n",
    "\n",
    "##### üìè <span style=\"color:#a4d4a3\">Dimensionality Problem</span>\n",
    "\n",
    "The Particle Filters are effective in <span style=\"color:#ffa500\">**low-dimensional**</span> spaces as the likely regions of the state space need to be covered with samples. The above state space is <span style=\"color:#ffa500\">**high-dimensional!**</span>\n",
    "\n",
    "*Can we exploit <span style=\"color:#00703c\">**dependencies between the different dimensions**</span> of the state space?*\n",
    "\n",
    "- *If we <span style=\"color:#00703c\">**know the poses**</span> of the robot, <span style=\"color:#00703c\">**mapping is easy!</span>***\n",
    "\n",
    "<span style=\"color:#ffa500\">**Key Idea:**</span>\n",
    "\n",
    "- If we use the particle set only to model the robot's path, <span style=\"color:#ffa500\">**each sample is a path hypothesis**</sample>. \n",
    "\n",
    "- For each sample, we can compute <span style=\"color:#ffa500\">**an individual map of landmarks**</span>.\n",
    "\n",
    "##### ‚õèÔ∏è <span style=\"color:#a4d4a3\">Rao-Blackwellization</span>\n",
    "\n",
    "Rao-Blackwellization is a trivial <span style=\"color:#ffa500\">**factorization**</span> that exploits dependencies between variables:\n",
    "\n",
    "$$\n",
    "p(a, b) = p(b \\mid a) \\cdot p(a)\n",
    "$$\n",
    "\n",
    "If $p(b \\mid a)$ can be <span style=\"color:#ffa500\">**computed efficiently**</span>, then represent only $p(a)$ with samples and compute $p(b \\mid a)$ for every sample.\n",
    "\n",
    "<span style=\"color:#00703c\">**In our case:**</span>\n",
    "\n",
    "- $a$ is the trajectory of the robot\n",
    "- $b$ is the map\n",
    "\n",
    "Thus we can say, <span style=\"color:#ffa500\">**instead of computing**</span> $p(a,b)$, let's <span style=\"color:#ffa500\">**take only**</span> $p(a)$, <span style=\"color:#ffa500\">**represent it with samples**</span>, then compute $p(b \\mid a)$, <span style=\"color:#ffa500\">**which is the map given the trajectory**</span>. \n",
    "\n",
    "Because we said that for grid maps, <span style=\"color:#ffa500\">**mapping is easy if we know the poses!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093dca6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f338007",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è <span style=\"color:#a4d4a3\">**Rao-Blackwellization for SLAM**</span>\n",
    "\n",
    "Let's apply this factorization to the SLAM posterior:\n",
    "\n",
    "$$\n",
    "p(x_{0:t}, m_{1:M} \\mid z_{1:t},u_{1:t}) = p(x_{0:t} \\mid z_{1:t}, u_{1:t}) \\cdot p(m_{1:M} \\mid x_{0:t}, z_{1:t}) \\quad\\quad (1)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $p(x_{0:t} \\mid z_{1:t}, u_{1:t})$ is the <span style=\"color:#ffa500\">**path posterior**</span>.\n",
    "- $p(m_{1:M} \\mid x_{0:t}, z_{1:t})$ is the <span style=\"color:#ffa500\">**map posterior**</span>.\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em>This was first introduced for SLAM by Murphy in 1999. </em>\n",
    "\n",
    "*Now, how do we <span style=\"color:#ffa500\">**compute the map posterior**</span> efficiently?*\n",
    "\n",
    "Because we factor the problem into the robot path and the map, and compute the map given the poses, the <span style=\"color:#ffa500\">**landmarks are conditionally independent given the poses**</span>; hence, from Eq. (1) we can write:\n",
    "\n",
    "$$\n",
    "p(x_{0:t}, m_{1:M} \\mid z_{1:t},u_{1:t}) = p(x_{0:t} \\mid z_{1:t}, u_{1:t}) \\cdot \\prod_{i=1}^{M} p(m_i \\mid x_{0:t}, z_{1:t})\n",
    "$$\n",
    "\n",
    "With this factorization, we use:\n",
    "\n",
    "- <span style=\"color:#ffa500\">**MCL**</span> to estimate the <span style=\"color:#ffa500\">**robot poses**</span> \n",
    "- <span style=\"color:#ffa500\">**2-D EKFs**</span> (one per landmark) to maintain <span style=\"color:#ffa500\">**the map**</span>. \n",
    "\n",
    "Managing M independent 2√ó2 EKFs is more efficient than a single large joint filter over all landmarks.\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em>This was first exploited in FastSLAM by Montemerlo et al., in 2002. </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e21387",
   "metadata": {},
   "source": [
    "### üõ£Ô∏è <span style=\"color:#a4d4a3\">**Modeling the Robot's Path**</span>\n",
    "\n",
    "We use the <span style=\"color:#ffa500\">**sample-based representation**</span> for $p(x_{0:t} \\mid z_{1:t}, u_{1:t})$\n",
    "\n",
    "Each sample is a path hypothesis:\n",
    "\n",
    "- $x_0$ starting location, typically $(0,0,0)$\n",
    "- $x_1$ pose hypothesis at time $t=1$\n",
    "- $x_2$ pose hypothesis at time $t=2$\n",
    "- $\\ldots$\n",
    "\n",
    "Since the Particle Filter <span style=\"color:#ffa500\">**does not update past poses**</span> if a mistake was made since they are not revised, we <span style=\"color:#ffa500\">**do not need to maintain them**</span> in the sample set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f61a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a67c7",
   "metadata": {},
   "source": [
    "### ‚ö°Ô∏è <span style=\"color:#a4d4a3\">**FastSLAM**</span>\n",
    "\n",
    "This leads to the <span style=\"color:#ffa500\">**first efficient SLAM implementation**</span>, known as FastSLAM by *Montemerlo et al.* in 2002.\n",
    "\n",
    "- Each <span style=\"color:#ffa500\">**landmark**</span> is represented by a <span style=\"color:#ffa500\">**2√ó2 EKF**</span>.\n",
    "- Each particle maintains <span style=\"color:#ffa500\">**$M$ independent**</span> EKFs for its landmarks.\n",
    "\n",
    "We have two updates:\n",
    "  - <span style=\"color:#00703c\">**Action update:**</span> sample a new pose using the proposal distribution (motion model).\n",
    "  - <span style=\"color:#00703c\">**Sensor update:**</span> EKF on observed landmarks.\n",
    "\n",
    "ADD FIGURES HERE.\n",
    "\n",
    "##### üîë <span style=\"color:#a4d4a3\"> **Key Steps of FastSLAM 1.0** </span>\n",
    "\n",
    "1. The first step is to <span style=\"color:#ffa500\">**extend**</span> the path posterior by <span style=\"color:#ffa500\">**sampling**</span> a new pose for each sample\n",
    "    \n",
    "    $$\n",
    "    x_t^{[k]} \\sim p(x_t \\mid x_{t-1}^{[k]}, u_t)\n",
    "    $$\n",
    "\n",
    "2. Then we the <span style=\"color:#ffa500\">**compute particle weights**</span> via the observation likelihood\n",
    "   \n",
    "   $$\n",
    "   w^{[k]}= |2 \\pi Q|^{-1/2} \\exp{\\Big(-\\tfrac{1}{2}\\,(z_t- \\hat{z}^{[k]})^T Q^{-1} (z_t - \\hat{z}^{[k]})\\Big)}\n",
    "   $$\n",
    "\n",
    "3. <span style=\"color:#ffa500\">**Update**</span> the belief of the <span style=\"color:#ffa500\">**observed**</span> landmarks using the EKF(s) update rule.\n",
    "\n",
    "4. <span style=\"color:#ffa500\">**Resample**</span> particles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ea5d0",
   "metadata": {},
   "source": [
    "#### üë®üèª‚Äçüíª <span style=\"color:#a4d4a3\">**FastSLAM 1.0 Algorithm**</span>\n",
    "\n",
    "The complete <span style=\"color:#ffa500\">****FastSLAM 1.0**</span> algorithm can be summarized as follows:\n",
    "\n",
    "> <tt> <span style=\"color:#4D96FF\">def</span> **<span style=\"color:#6BCB77\">FastSLAM1.0</span>($\\color{#ffa500}\\mathcal{X}_{t-1}, \\color{#ffa500}c_t, \\color{#ffa500}u_t, \\color{#ffa500}z_t$):** \n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">1.</span> <span style=\"color:#e74c3c\">for</span> $k=1$ <span style=\"color:#ffa500\">to</span> $N$ <span style=\"color:#e74c3c\">do</span>: $\\quad$ <span style=\"color:#948979\"># Loop over all particles</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">2.</span> <span style=\"color:#e74c3c\">Let</span> $\\big\\langle x_{t-1}^{[k]}, \\langle \\mu_{1,t-1}^{[k]}, \\Sigma_{1,t-1}^{[k]}\\rangle, \\ldots \\big\\rangle$ <span style=\"color:#ffa500\">be particle</span> $k$ <span style=\"color:#e74c3c\">in</span> $\\mathcal{X}_{t-1}$\n",
    ">>> \n",
    ">>> <span style=\"color:#FF2DD1\">3.</span> $x_{t}^{[k]} \\sim p(x_t \\mid x_{t-1}^{[k]}, u_t) \\quad$ <span style=\"color:#948979\"># Sample pose</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">4.</span> $j = c_t \\quad $ <span style=\"color:#948979\"># Observed feature</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">5.</span> <span style=\"color:#e74c3c\">if</span> <span style=\"color:#ffa500\"> feature</span> $j$ <span style=\"color:#ffa500\">Never seen before</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">6.</span> $\\mu_{j,t}^{[k]} = h^{-1}(z_t, x_t^{[k]})\\quad $ <span style=\"color:#948979\"># Initialize mean</span>\n",
    ">>>> \n",
    ">>>> <span style=\"color:#FF2DD1\">7.</span> $H = h'(\\mu_{j,t}^{[k]}, x_t^{[k]}) \\quad$ <span style=\"color:#948979\"># Calculate Jacobian</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">8.</span> $\\Sigma_{j,t}^{[k]} = H^{-1}\\,Q_t\\,(H^{-1})^T \\quad$ <span style=\"color:#948979\"># Initialize covariance</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">9.</span> $w^{[k]} = p_0 \\quad$ <span style=\"color:#948979\"># Default importance weight</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">10.</span> <span style=\"color:#e74c3c\">else</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">11.</span> $\\hat{z}^{[k]} = h(\\mu_{j,t-1}^{[k]}, x_t^{[k]}) \\quad$ <span style=\"color:#948979\"># Measurement Prediction</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">12.</span> $H = h'(\\mu_{j,t-1}^{[k]}, x_t^{[k]}) \\quad$ <span style=\"color:#948979\"># Calculate Jacobian</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">13.</span> $Q = H\\,\\Sigma_{j,t-1}^{[k]}\\,H^T + Q_t \\quad$ <span style=\"color:#948979\"># Compute measurement covariance</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">14.</span> $K = \\Sigma_{j,t-1}^{[k]}\\,H^T \\, Q^{-1} \\quad$ <span style=\"color:#948979\"># Calculate Kalman gain</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">15.</span> $\\mu_{j,t}^{[k]} = \\mu_{j,t-1}^{[k]} + K\\,(z_t - \\hat{z}^{[k]})^T \\quad$ <span style=\"color:#948979\"># Update mean</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">16.</span> $\\Sigma_{j,t}^{[k]} = (I - K\\,H)\\,\\Sigma_{j,t-1}^{[k]} \\quad$ <span style=\"color:#948979\"># Update covariance</span>\n",
    ">>>> \n",
    ">>>> <span style=\"color:#FF2DD1\">17.</span> $w^{[k]} = | 2 \\pi Q |^{-1/2} \\exp{\\Big(-\\tfrac{1}{2} (z_t - \\hat{z}^{[k]})^T Q^{-1} (z_t - \\hat{z}^{[k]})\\Big)} \\quad$ <span style=\"color:#948979\"># Compute importance facotr</span>\n",
    ">>>> \n",
    ">>> <span style=\"color:#FF2DD1\">18.</span> <span style=\"color:#e74c3c\">endif</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">19.</span> <span style=\"color:#e74c3c\">for</span> <span style=\"color:#ffa500\"> all unobserved features</span> $j'$ <span style=\"color:#e74c3c\">do</span>\n",
    ">>>>\n",
    ">>>> <span style=\"color:#FF2DD1\">20.</span> $\\langle \\mu_{j',t}^{[k]}, \\Sigma_{j',t}^{[k]} \\rangle = \\langle \\mu_{j',t-1}^{[k]}, \\Sigma_{j',t-1}^{[k]} \\rangle \\quad$ <span style=\"color:#948979\"># Leave unchanged</span>\n",
    ">>>\n",
    ">>> <span style=\"color:#FF2DD1\">21.</span> <span style=\"color:#e74c3c\">endfor</span>\n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">22.</span> <span style=\"color:#e74c3c\">endfor</span>\n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">23.</span> $\\mathcal{X}_t = $ <span style=\"color:#6BCB77\">Resample</span>($\\big\\langle x_t^{[k]}, \\langle \\mu_{1,t}^{[k]}, \\Sigma_{1,t}^{[k]} \\rangle,\\ldots, w^{[k]} \\big\\rangle_{k=1..N}$)  \n",
    ">>\n",
    ">> <span style=\"color:#FF2DD1\">24.</span> <span style=\"color:#e74c3c\">return</span> $\\mathcal{X}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f9e46",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825917f0",
   "metadata": {},
   "source": [
    "### ‚öñÔ∏è <span style=\"color:#a4d4a3\">**The Importance Weight**</span>\n",
    "\n",
    "As we mentioned earlier <span style=\"color:#ffa500\">**the weight is a result from the Importance Sampling Principle**</span>.\n",
    "\n",
    "- Importance weight is given by the ratio of target and proposal in $x^{[k]}$\n",
    "\n",
    "    $$\n",
    "    w^{[k]} = \\frac{\\text{target}({x^{[k]}})}{\\text{proposal}(x^{[k]})} \\quad\\quad (2)\n",
    "    $$\n",
    "\n",
    "Let's see the mathematical derivation of it.\n",
    "\n",
    "- The <span style=\"color:#ffa500\">**target distribution**</span> is the path of the robot:\n",
    "\n",
    "    $$\n",
    "    p(x_{1:t} \\mid z_{1:t}, u_{1:t})\n",
    "    $$\n",
    "\n",
    "- The <span style=\"color:#ffa500\">**proposal distribution**</span> is all the odometry information, except the last observation:\n",
    "\n",
    "    $$\n",
    "    p(x_{1:t} \\mid z_{1:t-1}, u_{1:t})\n",
    "    $$\n",
    "\n",
    "- We can write the proposal in a <span style=\"color:#ffa500\">**recursive**</span> step-by-step:\n",
    "\n",
    "    $$\n",
    "    p(x_{1:t} \\mid z_{1:t-1}, u_{1:t}) = \\underbrace{p(x_{t} \\mid x_{t-1}, u_{t})}_{\\text{from } \\mathcal{X}_{t-1} \\text{ to } \\bar{\\mathcal{X}}_t} \\cdot \\underbrace{p(x_{1:t-1} \\mid z_{1:t-1}, u_{1:t-1})}_{\\mathcal{X}_{t-1}}\n",
    "    $$\n",
    "\n",
    "Replacing the target and proposal distributions in Eq. (2) we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w^{[k]} &= \\frac{\\text{target}({x^{[k]}})}{\\text{proposal}(x^{[k]})} \\\\\n",
    "&= \\frac{p(x_{1:t}^{[k]} \\mid z_{1:t}, u_{1:t})}{p(x_{t}^{[k]} \\mid x_{t-1}^{[k]}, u_{t}) \\cdot p(x_{1:t-1}^{[k]} \\mid z_{1:t-1}, u_{1:t-1})} \\quad\\quad (3) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now if we apply <span style=\"color:#ffa500\">**Bayes' rule**</span> and <span style=\"color:#ffa500\">**factorization**</span> to Eq. (3), we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w^{[k]} &= \\frac{\\text{target}({x^{[k]}})}{\\text{proposal}(x^{[k]})} \\\\\n",
    "&= \\frac{p(x_{1:t}^{[k]} \\mid z_{1:t}, u_{1:t})}{p(x_{t}^{[k]} \\mid x_{t-1}^{[k]}, u_{t}) \\cdot p(x_{1:t-1}^{[k]} \\mid z_{1:t-1}, u_{1:t-1})} \\\\\n",
    "&= \\frac{\\eta \\cdot p(z_{t} \\mid x_{1:t}^{[k]}, z_{1:t-1}) \\cdot \\cancel{p(x_{t}^{[k]} \\mid x_{t-1}^{[k]}, u_t)} \\cdot \\cancel{p(x_{1:t-1}^{[k]} \\mid z_{1:t-1}, u_{1:t-1})}}{\\cancel{p(x_{t}^{[k]} \\mid x_{t-1}^{[k]}, u_{t})} \\cdot \\cancel{p(x_{1:t-1}^{[k]} \\mid z_{1:t-1}, u_{1:t-1})}} \\\\\n",
    "&= \\eta \\cdot p(z_{t} \\mid x_{1:t}^{[k]}, z_{1:t-1}) \\quad\\quad (4) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "By integrating over the observed landmark position, we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w^{[k]} &= \\eta \\cdot p(z_{t} \\mid x_{1:t}^{[k]}, z_{1:t-1}) \\\\\n",
    "&= \\eta \\int p(z_{t} \\mid x_{1:t}^{[k]}, z_{1:t-1}, m_j) \\cdot p(m_j \\mid x_{1:t}^{[k]}, z_{1:t-1}) \\cdot dm_j \\\\\n",
    "&= \\eta \\int \\underbrace{p(z_{t} \\mid x_{t}^{[k]}, m_j)}_{\\mathcal{N}(z_t;\\hat{z}^{[k]},Q_t)} \\cdot \\underbrace{p(m_j \\mid x_{1:t}^{[k]}, z_{1:t-1})}_{\\mathcal{N}(m_j;\\mu_{j,t-1}^{[k]}, \\Sigma_{j,t-1}^{[k]})} \\cdot dm_j \\\\  \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here we have:\n",
    "\n",
    "- $p(m_j \\mid x_{1:t}^{[k]}, z_{1:t-1})$: the <span style=\"color:#ffa500\">**landmark prior**</span> in particle $k$, a Gaussian $\\mathcal{N}\\!\\big(m_j;\\, \\mu_{j,t-1}^{[k]}, \\Sigma_{j,t-1}^{[k]}\\big)$.\n",
    "\n",
    "- $p(z_t \\mid x_t^{[k]}, m_j)$: the <span style=\"color:#ffa500\">**measurement model**</span> with sensor noise $Q_t$, $\\,\\mathcal{N}\\!\\big(z_t;\\, h(x_t^{[k]}, m_j),\\, Q_t\\big)$.\n",
    "\n",
    "- $\\hat z^{[k]} \\approx h\\!\\big(x_t^{[k]}, \\mu_{j,t-1}^{[k]}\\big)$: the <span style=\"color:#ffa500\">**predicted measurement**</span> (using a first-order linearization w.r.t. the landmark).\n",
    "\n",
    "The total measurement covariance is the <span style=\"color:#ffa500\">**projected landmark uncertainty**</span> plus the <span style=\"color:#ffa500\">**sensor noise**</span>:\n",
    "\n",
    "$$\n",
    "Q \\;=\\; H\\,\\Sigma_{j,t-1}^{[k]} H^\\top \\;+\\; Q_t .\n",
    "$$\n",
    "\n",
    "where $H$ is the <span style=\"color:#ffa500\">**Jacobian**</span> of the measurement model w.r.t. the landmark. \n",
    "\n",
    "The <span style=\"color:#ffa500\">**marginal likelihood**</span> after integrating out $m_j$ is Gaussian, so\n",
    "\n",
    "$$\n",
    "w^{[k]} \\;\\approx\\; |2\\pi Q|^{-1/2}\\,\n",
    "\\exp\\!\\Big(-\\tfrac12\\,(z_t-\\hat z^{[k]})^\\top Q^{-1}(z_t-\\hat z^{[k]})\\Big).\n",
    "$$\n",
    "\n",
    "> üìù <span style=\"color:#0098ff\">**Note:**</span> <em>The weight tells us how consistent is the world representation each sample generated with respect to what the system actually perceives. </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117ff76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa56128",
   "metadata": {},
   "source": [
    "##### üéÆ `Python Example: FastSLAM - Feature-based SLAM`\n",
    "\n",
    "Since the desired algorithm has <span style=\"color:#ffa500\">**grown in complexity**</span>, we break it into the following three blocks.\n",
    "\n",
    "1. **FastSLAM core**\n",
    "2. **Map and LiDAR handling**\n",
    "3. **Pygame demo app**\n",
    "\n",
    "##### ‚öô <span style=\"color:#a4d4a3\">**FastSLAM Core** (RBPF with per-landmark EKFs)</span>\n",
    "\n",
    "We start with this cell which implements a solution similar to what <span style=\"color:#00703c\">**FastSLAM 1.0**</span> proposed:\n",
    "\n",
    "- A Rao-Blackwellized Particle Filter over the <span style=\"color:#ffa500\">**robot pose**</span> where each particle carries an <span style=\"color:#ffa500\">**independent landmark map**</span> represented by tiny 2√ó2 EKFs (position only).\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Assumptions / scope:**</span>\n",
    "\n",
    "- <span style=\"color:#00703c\">**Known data association:**</span> the front-end provides an integer landmark ID for each measurement; the core does *not* solve association.\n",
    "- <span style=\"color:#00703c\">**2D state:** </span>robot pose $(x,y,\\theta)$; each landmark $m_j \\in \\mathbb{R}^2$.\n",
    "- <span style=\"color:#00703c\">**Measurements:**</span> range-bearing $z = (r,\\phi)$ w.r.t. the robot frame with Gaussian noise $Q\\in\\mathbb{R}^{2\\times2}$.\n",
    "- <span style=\"color:#00703c\">**Motion model:**</span> odometry $(\\Delta r_1,\\Delta t,\\Delta r_2)$ with Gaussian noise $R_x$.\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Per-time-step flow:**</span>\n",
    "\n",
    "1. <span style=\"color:#00703c\">**Predict (particles):**</span> sample each particle pose from the odometry proposal.\n",
    "2. <span style=\"color:#00703c\">**Correct (EKFs inside each particle):**</span>\n",
    "   - Measurement model $h(x,m)$.\n",
    "   - Jacobian $H = \\partial h/\\partial m \\in \\mathbb{R}^{2\\times2}$.\n",
    "   - For a new landmark ID, initialize $\\mu_j$ via inverse sensor model and $\\Sigma_j$ from a local linearization.\n",
    "   - For an existing landmark, do an EKF update. We compute the Kalman gain via a numerically stable linear solve rather than explicit matrix inversion ($K = \\Sigma H^T (H \\Sigma )$).\n",
    "   - Accumulate the measurement log-likelihood to update the particle weight.\n",
    "3.  <span style=\"color:#00703c\">**Normalize weights**</span> and compute the effective sample size $N_\\mathrm{eff}$.\n",
    "4.  <span style=\"color:#00703c\">**Systematic resampling**</span> when $N_\\mathrm{eff} < \\text{ratio}\\times N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc1e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# FastSLAM 1.0 Pygame Demo (GT left | FastSLAM right)\n",
    "# ====================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Small helpers ---\n",
    "def wrap_angle(a: float) -> float:\n",
    "    return (a + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "# --- FastSLAM core ---\n",
    "class FastSLAM:\n",
    "    class Particle:\n",
    "        __slots__ = (\"x\", \"y\", \"th\", \"w\", \"map\") \n",
    "        def __init__(self, x=0.0, y=0.0, th=0.0, w=1.0):\n",
    "            self.x  = float(x)\n",
    "            self.y  = float(y)\n",
    "            self.th = float(th)\n",
    "            self.w  = float(w)\n",
    "            # map: lm_id -> [mu(2,), Sigma(2,2), seen_bool]\n",
    "            self.map = {}\n",
    "\n",
    "    # --- Constructor ---\n",
    "    def __init__(self,\n",
    "                 N: int,\n",
    "                 Q: np.ndarray,\n",
    "                 R_x: np.ndarray,\n",
    "                 rng: np.random.Generator,\n",
    "                 resample_neff_ratio: float = 0.5):\n",
    "        \"\"\"\n",
    "        FastSLAM 1.0 with known data association and per-landmark EKFs.\n",
    "        Args:\n",
    "            N: number of particles\n",
    "            Q: measurement noise covariance (2x2)\n",
    "            R_x: odometry noise covariance (3x3, diagonal)\n",
    "            rng: numpy random number generator\n",
    "            resample_neff_ratio: trigger resampling when N_eff < ratio * N\n",
    "        \"\"\"\n",
    "        self.N = int(N)\n",
    "        self.Q = np.asarray(Q, dtype=np.float32)\n",
    "        self.R_x = R_x\n",
    "        self.std = np.sqrt(np.diag(R_x))\n",
    "        self.rng = rng\n",
    "        self.resample_neff_ratio = float(resample_neff_ratio)\n",
    "        self.p = [self.Particle() for _ in range(self.N)]\n",
    "\n",
    "\n",
    "    # --- Initialization ---\n",
    "    def global_initialize(self, cx: float, cy: float,\n",
    "                          th_sd_deg: float = 10.0, pos_sd: float = 3.0) -> None:\n",
    "        \"\"\"\n",
    "        Spread particles around (cx,cy) with small heading noise.\n",
    "        Args:\n",
    "            cx, cy: center position\n",
    "            th_sd_deg: heading stddev in degrees\n",
    "            pos_sd: position stddev in world units\n",
    "        \"\"\"\n",
    "        th_sd = np.deg2rad(th_sd_deg)\n",
    "        invN = 1.0 / self.N\n",
    "        # vectorized sampling of random offsets\n",
    "        xs = cx + self.rng.normal(0.0, pos_sd, size=self.N)\n",
    "        ys = cy + self.rng.normal(0.0, pos_sd, size=self.N)\n",
    "        ths = self.rng.normal(0.0, th_sd, size=self.N)\n",
    "        for i, pr in enumerate(self.p):\n",
    "            pr.x  = float(xs[i])\n",
    "            pr.y  = float(ys[i])\n",
    "            pr.th = float(ths[i])\n",
    "            pr.w  = invN\n",
    "            pr.map.clear()\n",
    "\n",
    "    # --- Motion / Prediction ---\n",
    "    def predict(self, u: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Odometry motion with additive diagonal Gaussian noise.\n",
    "        Args:\n",
    "            u: odometry 3-vector (dr1, dt, dr2)\n",
    "        Modifies:\n",
    "            self.p: list of particles (in-place)\n",
    "        \"\"\"\n",
    "        dr1, dt, dr2 = map(float, u)\n",
    "        n = self.N\n",
    "\n",
    "        x  = np.empty(n, np.float64)\n",
    "        y  = np.empty(n, np.float64)\n",
    "        th = np.empty(n, np.float64)\n",
    "        for i, pr in enumerate(self.p):\n",
    "            x[i] = pr.x; y[i] = pr.y; th[i] = pr.th\n",
    "\n",
    "        # Odometry motion (noiseless)\n",
    "        th_mid = th + dr1\n",
    "        ct = np.cos(th_mid); st = np.sin(th_mid)\n",
    "        x_new  = x  + dt * ct\n",
    "        y_new  = y  + dt * st\n",
    "        th_new = th + dr1 + dr2\n",
    "\n",
    "        # Add independent Gaussian noise per component\n",
    "        std = self.std  # [œÉx, œÉy, œÉŒ∏]\n",
    "        eps = self.rng.normal(0.0, std, size=(n,3))\n",
    "\n",
    "        # Rotate translational noise from body to world\n",
    "        ex_b = eps[:, 0]\n",
    "        ey_b = eps[:, 1]\n",
    "        eth  = eps[:, 2]\n",
    "\n",
    "        ex_w = ct * ex_b - st * ey_b\n",
    "        ey_w = st * ex_b + ct * ey_b\n",
    "\n",
    "        x  = x_new + ex_w\n",
    "        y  = y_new + ey_w\n",
    "        th = (th_new + eth + np.pi) % (2*np.pi) - np.pi\n",
    "\n",
    "        for i, pr in enumerate(self.p):\n",
    "            pr.x = float(x[i]); pr.y = float(y[i]); pr.th = float(th[i])\n",
    "\n",
    "    # --- Measurement model ---\n",
    "    @staticmethod\n",
    "    def _h_and_H(pose_xyth: tuple, mu_j: np.ndarray) -> tuple:\n",
    "        \"\"\"\n",
    "        Range-bearing measurement model and Jacobian wrt landmark state.\n",
    "        Args:\n",
    "            pose_xyth: robot pose (x, y, theta)\n",
    "            mu_j: landmark position (2-vector)\n",
    "        Returns:\n",
    "            zhat: predicted measurement (2-vector)\n",
    "            H: Jacobian wrt landmark (2x2)\n",
    "        \"\"\"\n",
    "        x, y, th = map(float, pose_xyth)\n",
    "        dx = float(mu_j[0]) - x\n",
    "        dy = float(mu_j[1]) - y\n",
    "        q  = dx*dx + dy*dy + 1e-12\n",
    "        r  = np.sqrt(q)\n",
    "        zhat = np.array([r, wrap_angle(np.arctan2(dy, dx) - th)], dtype=np.float32)\n",
    "        H = np.array([[dx/r,  dy/r],\n",
    "                      [-dy/q,  dx/q]], dtype=np.float32)\n",
    "        return zhat, H\n",
    "\n",
    "    # --- Landmark initialization from first measurement ---\n",
    "    @staticmethod\n",
    "    def _init_from_meas(pose_xyth: tuple, z: np.ndarray, Q: np.ndarray) -> tuple:\n",
    "        \"\"\"\n",
    "        Initialize landmark position and covariance from first range-bearing measurement.\n",
    "        Args:\n",
    "            pose_xyth: robot pose (x, y, theta)\n",
    "            z: measurement (r, bearing)\n",
    "            Q: measurement noise covariance (2x2)\n",
    "        Returns:\n",
    "            mu: landmark position (2-vector)\n",
    "            Sigma: landmark covariance (2x2)\n",
    "        \"\"\"\n",
    "        x, y, th = map(float, pose_xyth)\n",
    "        r, b = map(float, z)\n",
    "        mx = x + r * np.cos(th + b)\n",
    "        my = y + r * np.sin(th + b)\n",
    "        mu = np.array([mx, my], dtype=np.float32)\n",
    "\n",
    "        _, H = FastSLAM._h_and_H((x, y, th), mu)\n",
    "        # Landmark covariance via inverse (H·µÄ Q^{-1} H)^{-1} but avoid explicit inverse:\n",
    "        # Solve H X = I  =>  X = H^{-1}; then Sigma = X Q X·µÄ\n",
    "        I2 = np.eye(2, dtype=np.float32)\n",
    "        try:\n",
    "            X = np.linalg.solve(H, I2).astype(np.float32)\n",
    "            Sigma = (X @ Q @ X.T).astype(np.float32)\n",
    "        except np.linalg.LinAlgError:\n",
    "            Sigma = np.diag([100.0, 100.0]).astype(np.float32)\n",
    "\n",
    "        # Add tiny floor to keep Œ£ well-conditioned\n",
    "        Sigma += np.eye(2, dtype=np.float32) * 1e-6\n",
    "        return mu, Sigma\n",
    "\n",
    "    # --- Correction / Update ---\n",
    "    def update(self, z_list: list, id_list: list) -> None:\n",
    "        \"\"\"\n",
    "        EKF update for each landmark in each particle + weight update.\n",
    "        Args:\n",
    "            z_list: list of measurements (each a 2-vector)\n",
    "            id_list: list of landmark IDs (integers)\n",
    "        Modifies:\n",
    "            self.p: list of particles (in-place)\n",
    "        \"\"\"\n",
    "        if not z_list:\n",
    "            return\n",
    "\n",
    "        Q = self.Q\n",
    "        I2 = np.eye(2, dtype=np.float32)\n",
    "\n",
    "        # Update each particle\n",
    "        for pr in self.p:\n",
    "            logw = 0.0\n",
    "            pose = (pr.x, pr.y, pr.th)\n",
    "            # Process each measurement\n",
    "            for z, j in zip(z_list, id_list):\n",
    "                if j not in pr.map:\n",
    "                    mu, Sigma = self._init_from_meas(pose, z, Q)\n",
    "                    pr.map[j] = [mu, Sigma, True]\n",
    "                    continue\n",
    "\n",
    "                mu, Sigma, _ = pr.map[j]\n",
    "\n",
    "                # Predict measurement\n",
    "                zhat, H = self._h_and_H(pose, mu)\n",
    "                nu = np.array([z[0] - zhat[0], wrap_angle(z[1] - zhat[1])], dtype=np.float32)\n",
    "\n",
    "                # Innovation cov S = H Œ£ H·µÄ + Q\n",
    "                S = H @ Sigma @ H.T + Q\n",
    "\n",
    "                # Kalman gain via linear solve (stable; no explicit inverse)\n",
    "                # K = Œ£ H·µÄ S^{-1}\n",
    "                HS = (H @ Sigma).astype(np.float32)  # (2,2)\n",
    "                try:\n",
    "                    KT = np.linalg.solve(S.T, HS)    # (2,2)\n",
    "                # If S is singular / ill-conditioned, add tiny noise and retry\n",
    "                except np.linalg.LinAlgError:\n",
    "                    S = (S + np.eye(2, dtype=np.float32) * 1e-6).astype(np.float32)\n",
    "                    KT = np.linalg.solve(S.T, HS)\n",
    "                K = KT.T.astype(np.float32)          # (2,2)\n",
    "\n",
    "                # Landmark EKF update\n",
    "                mu    = (mu + K @ nu).astype(np.float32)\n",
    "                Sigma = ((I2 - K @ H) @ Sigma).astype(np.float32)\n",
    "                pr.map[j] = [mu, Sigma, True]\n",
    "\n",
    "                # Particle weight update\n",
    "                # log w += -0.5 * (nu·µÄ S^{-1} nu + log|S| + 2 log(2œÄ))\n",
    "                try:\n",
    "                    # Solve S y = nu\n",
    "                    y = np.linalg.solve(S, nu.astype(np.float32))\n",
    "                    m = float(nu.T @ y)\n",
    "                    sign, logdet = np.linalg.slogdet(S.astype(np.float64))\n",
    "                    if sign <= 0:\n",
    "                        logdet = np.log(np.maximum(np.linalg.det(S.astype(np.float64)), 1e-9))\n",
    "                    logw += -0.5 * (m + logdet + 2.0 * np.log(2.0 * np.pi))\n",
    "                # If S is singular / ill-conditioned, skip weight update \n",
    "                except np.linalg.LinAlgError:\n",
    "                    pass\n",
    "            # Update particle weight\n",
    "            pr.w = float(pr.w) * float(np.exp(logw))\n",
    "\n",
    "        # Normalize weights\n",
    "        W = np.array([pr.w for pr in self.p], dtype=np.float64)\n",
    "        s = float(W.sum())\n",
    "        if s <= 0.0 or not np.isfinite(s):\n",
    "            W[:] = 1.0 / self.N\n",
    "        else:\n",
    "            W /= s\n",
    "        for i, pr in enumerate(self.p):\n",
    "            pr.w = float(W[i])\n",
    "\n",
    "        # Resample if needed\n",
    "        neff = 1.0 / (np.sum(W * W) + 1e-12)\n",
    "        if neff < self.resample_neff_ratio * self.N:\n",
    "            self._systematic_resample(W)\n",
    "\n",
    "\n",
    "    # --- Resampling ---\n",
    "    def _systematic_resample(self, W: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Systematic resampling of particles according to weights W.\n",
    "        Args:\n",
    "            W: normalized weights (N-vector)\n",
    "        Modifies:\n",
    "            self.p: list of particles (in-place)\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        # vectorized positions and index selection via searchsorted\n",
    "        u0 = np.random.rand() / N\n",
    "        positions = u0 + (np.arange(N, dtype=np.float64) / N)\n",
    "        cdf = np.cumsum(W, dtype=np.float64)\n",
    "        indexes = np.searchsorted(cdf, positions, side=\"left\").astype(np.int32)\n",
    "\n",
    "        invN = 1.0 / N\n",
    "        new = []\n",
    "        for k in indexes:\n",
    "            src = self.p[int(k)]\n",
    "            q = self.Particle(src.x, src.y, src.th, invN)\n",
    "            # deep copy landmark states\n",
    "            q.map = {lm_id: [mu.copy(), Sigma.copy(), seen]\n",
    "                     for lm_id, (mu, Sigma, seen) in src.map.items()}\n",
    "            new.append(q)\n",
    "        self.p = new\n",
    "\n",
    "    # --- Pose estimation ---\n",
    "    def estimate_pose(self, top_k_frac: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Weighted average of top-k% particles (poses only).\n",
    "        Args:\n",
    "            top_k_frac: fraction of top particles to use (0,1]\n",
    "        Returns:\n",
    "            est: estimated pose (3-vector)\n",
    "        \"\"\"\n",
    "        W = np.array([pr.w for pr in self.p], dtype=np.float64)\n",
    "        idx = np.argsort(W)\n",
    "        K = max(5, int(top_k_frac * len(self.p)))\n",
    "        sel = idx[-K:]\n",
    "        Wk = W[sel]\n",
    "        Wk = Wk / (float(Wk.sum()) + 1e-12)\n",
    "        xs = np.array([[self.p[i].x, self.p[i].y] for i in sel], dtype=np.float64)\n",
    "        ths = np.array([self.p[i].th for i in sel], dtype=np.float64)\n",
    "        ex, ey = np.sum(Wk[:, None] * xs, axis=0)\n",
    "        c = np.sum(Wk * np.cos(ths))\n",
    "        s = np.sum(Wk * np.sin(ths))\n",
    "        eth = np.arctan2(s, c)\n",
    "        return np.array([float(ex), float(ey), float(eth)], dtype=np.float32)\n",
    "\n",
    "    # --- Utility ---\n",
    "    def best_particle(self) -> Particle:\n",
    "        return max(self.p, key=lambda t: t.w)\n",
    "\n",
    "    def neff(self) -> float:\n",
    "        W = np.array([pr.w for pr in self.p], dtype=np.float64)\n",
    "        return float(1.0 / (np.sum(W * W) + 1e-12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73b354",
   "metadata": {},
   "source": [
    "##### ‚òÑ <span style=\"color:#a4d4a3\">**Map & LiDAR Front-End** (grid-ID landmarks + quantized measurements)</span>\n",
    "\n",
    "This cell provides a minimal <span style=\"color:#ffa500\">**front-end**</span> for the FastSLAM core: a map with fast ray-casting and a simulated  <span style=\"color:#ffa500\">**2D LiDAR**</span> that outputs range‚Äìbearing measurements  <span style=\"color:#ffa500\">**with known correspondences**</span> (each hit is mapped to a persistent landmark ID defined by a grid cell).\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Map model** (Map2D):</span>\n",
    "\n",
    "- Loads a floor-plan image and binarizes it: <span style=\"color:#00703c\">**dark pixels = walls**</span>, the rest = free.\n",
    "\n",
    "- Stores a boolean `wall_mask` of shape `(W,H)` (True for wall), and supports:\n",
    "\n",
    "  - `nearest_free_to(xy)`: spawn helper returning the closest free pixel.\n",
    "\n",
    "  - `cast_beam_fast(pos_xy, angle, max_r)`: ray-march along `angle` until the first wall hit or the boundary.\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Performance dials**</span>\n",
    "\n",
    "- Fewer beams (`num_beams`), larger `ray_stride`, and coarser `grid_px` all speed up the front-end.\n",
    "\n",
    "- Larger `range_step_px` / `bearing_step_deg` reduce landmarks and EKF load.\n",
    "\n",
    "- If you need *even more* speed, subsample beams before passing to the SLAM back-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5546271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# --- 2D map with fast ray-casting ---\n",
    "class Map2D:\n",
    "    \"\"\"Loads a floor-plan image; black-ish pixels are walls; others free.\"\"\"\n",
    "    def __init__(self, panel_w: int, panel_h: int, ray_stride=2, floor_img_path='../figures/floor_plan.png'):\n",
    "        self.panel_w = panel_w\n",
    "        self.panel_h = panel_h\n",
    "        self.ray_stride = int(ray_stride)\n",
    "\n",
    "        # Try to load the map; fall back to blank free space if missing.\n",
    "        try:\n",
    "            surf = pygame.image.load(floor_img_path)\n",
    "            surf = pygame.transform.smoothscale(surf, (panel_w, panel_h)).convert()\n",
    "            self.surface = surf\n",
    "            arr = pygame.surfarray.array3d(surf)  # (w, h, 3)\n",
    "            self.wall_mask = np.all(arr < 128, axis=2).astype(np.bool_)  # True=wall\n",
    "        except Exception:\n",
    "            self.surface = pygame.Surface((panel_w, panel_h)).convert()\n",
    "            self.surface.fill((240,240,240))\n",
    "            self.wall_mask = np.zeros((panel_w, panel_h), dtype=np.bool_)\n",
    "\n",
    "        self.free_mask = ~self.wall_mask\n",
    "        free_xy = np.where(self.free_mask)\n",
    "        self.free_coords = (np.stack(free_xy, axis=1).astype(np.int32)\n",
    "                            if free_xy[0].size > 0 else np.zeros((0,2), dtype=np.int32))\n",
    "\n",
    "    # --- Utility ---\n",
    "    def nearest_free_to(self, target_xy: tuple) -> tuple:\n",
    "        \"\"\"\n",
    "        Return the nearest free pixel to target_xy (or center if none).\n",
    "        Args:\n",
    "            target_xy: (x,y) pixel coordinates\n",
    "        Returns:\n",
    "            (x,y) of nearest free pixel (float)\n",
    "        \"\"\"\n",
    "        tx, ty = int(target_xy[0]), int(target_xy[1])\n",
    "        if 0<=tx<self.panel_w and 0<=ty<self.panel_h and (not self.wall_mask[tx, ty]):\n",
    "            return float(tx), float(ty)\n",
    "        if self.free_coords.shape[0] == 0:\n",
    "            return float(self.panel_w//2), float(self.panel_h//2)\n",
    "        # Vectorized nearest-neighbor over precomputed free pixels\n",
    "        dif = self.free_coords - np.array([tx, ty], dtype=np.int32)[None, :]\n",
    "        j = int(np.argmin(np.sum(dif.astype(np.int64)**2, axis=1)))\n",
    "        x, y = self.free_coords[j]\n",
    "        return float(x), float(y)\n",
    "\n",
    "    def cast_beam_fast(self, pos_xy: tuple, angle: float, max_r: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Ray-march along angle until first wall hit or boundary.\n",
    "        Args:\n",
    "            pos_xy: (x,y) pixel coordinates of ray start\n",
    "            angle: angle in radians\n",
    "            max_r: max range in pixels  \n",
    "        Returns:\n",
    "            (hit_xy, distance_px): hit pixel (x,y) or None if no hit; distance in pixels\n",
    "        \"\"\"\n",
    "        W, H = self.wall_mask.shape\n",
    "        x0, y0 = float(pos_xy[0]), float(pos_xy[1])\n",
    "        c, s = np.cos(angle), np.sin(angle)\n",
    "        stride = max(1, int(self.ray_stride))\n",
    "\n",
    "        # Vectorized march\n",
    "        r = np.arange(0, int(max_r), stride, dtype=np.int32)             # (S,)\n",
    "        X = (x0 + r * c).astype(np.int32)                                 # (S,)\n",
    "        Y = (y0 + r * s).astype(np.int32)                                 # (S,)\n",
    "        oob = (X < 0) | (X >= W) | (Y < 0) | (Y >= H)                     # (S,)\n",
    "        hit_wall = np.zeros_like(oob, dtype=bool)\n",
    "        inb = ~oob\n",
    "        if np.any(inb):\n",
    "            hit_wall[inb] = self.wall_mask[X[inb], Y[inb]]\n",
    "\n",
    "        hit = oob | hit_wall\n",
    "        if not np.any(hit):\n",
    "            return None, int(max_r)\n",
    "\n",
    "        k = int(np.argmax(hit))  # first hit index\n",
    "        d = int(r[k])\n",
    "        if oob[k]:\n",
    "            return None, d\n",
    "        else:\n",
    "            return (int(X[k]), int(Y[k])), d\n",
    "\n",
    "# --- 2D LiDAR with known correspondences ---\n",
    "class Lidar:\n",
    "    \"\"\"\n",
    "    Emits (r, bearing) with noise and **known correspondence**:\n",
    "    - Each grid cell that a beam hits becomes a unique landmark ID.\n",
    "    \"\"\"\n",
    "    def __init__(self, panel_w: int, panel_h: int, grid_px: int=20,\n",
    "                 range_step_px: float=8.0, bearing_step_deg: float=1.0,\n",
    "                 Q: np.ndarray = np.diag([4.0, np.deg2rad(5.0)**2]),\n",
    "                 world_map: Map2D = None,\n",
    "                 rng: np.random.Generator = None):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            panel_w, panel_h: map dimensions in pixels\n",
    "            grid_px: size of grid cell for landmark IDs (pixels)\n",
    "            range_step_px: quantization step for range (pixels)\n",
    "            bearing_step_deg: quantization step for bearing (degrees)\n",
    "            Q: measurement noise covariance (2x2)\n",
    "            world_map: Map2D instance\n",
    "            rng: numpy random number generator\n",
    "        \"\"\"\n",
    "        self.panel_w = panel_w\n",
    "        self.panel_h = panel_h\n",
    "        self.grid_px = int(grid_px)\n",
    "        self.range_step_px = float(range_step_px)\n",
    "        self.bearing_step = np.deg2rad(float(bearing_step_deg))\n",
    "        self.Q = Q.astype(np.float32)\n",
    "        self.map = world_map\n",
    "        self.rng = rng or np.random.default_rng(0)\n",
    "\n",
    "        self.id_by_cell = {}  # (cx,cy) -> lm_id\n",
    "        self.cell_by_id = []  # list index = lm_id -> (cx,cy)\n",
    "\n",
    "    # --- Utility ---\n",
    "    def cell_of_xy(self, x: float, y: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Return (cx,cy) grid cell coordinates for pixel (x,y).\n",
    "        Args:\n",
    "            x, y: pixel coordinates (float)\n",
    "        Returns:\n",
    "            (cx, cy): grid cell coordinates (int)\n",
    "        \"\"\"\n",
    "        return (int(x)//self.grid_px, int(y)//self.grid_px)\n",
    "\n",
    "    def cell_center_xy(self, cell: tuple) -> tuple:\n",
    "        \"\"\"\n",
    "        Return (x,y) pixel coordinates of the center of the given grid cell.\n",
    "        Args:\n",
    "            cell: (cx, cy) grid cell coordinates (int)\n",
    "        Returns:\n",
    "            (x, y): pixel coordinates of cell center (float)\n",
    "        \"\"\"\n",
    "        cx, cy = cell\n",
    "        g = self.grid_px\n",
    "        return (cx*g + 0.5*g, cy*g + 0.5*g)\n",
    "\n",
    "    def _quantize_meas(self, r: float, phi: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Quantize range and bearing to nearest steps.\n",
    "        Args:\n",
    "            r: range (float)\n",
    "            phi: bearing (float)\n",
    "        Returns:\n",
    "            (rq, pq): quantized range and bearing (float)\n",
    "        \"\"\"\n",
    "        rq = self.range_step_px * round(r / self.range_step_px)\n",
    "        pq = ((self.bearing_step * round(phi / self.bearing_step) + np.pi) % (2*np.pi)) - np.pi\n",
    "        return rq, pq\n",
    "\n",
    "    def _ensure_id(self, cell: tuple) -> int:\n",
    "        \"\"\"\n",
    "        Ensure the given cell has a landmark ID; return it.\n",
    "        Args:\n",
    "            cell: (cx, cy) grid cell coordinates (int)\n",
    "        Returns:\n",
    "            lm_id: landmark ID (int)\n",
    "        \"\"\"\n",
    "        if cell not in self.id_by_cell:\n",
    "            lm_id = len(self.cell_by_id)\n",
    "            self.id_by_cell[cell] = lm_id\n",
    "            self.cell_by_id.append(cell)\n",
    "        return self.id_by_cell[cell]\n",
    "\n",
    "    def scan(self, gt_pose: tuple, heading: float, max_range_px: int=200,\n",
    "             num_beams: int=180, fov_deg: int=360) -> tuple:\n",
    "        \"\"\"\n",
    "        Simulate a LiDAR scan from the given pose and heading.\n",
    "        Args:\n",
    "            gt_pose: ground-truth robot pose (x, y, theta)\n",
    "            heading: LiDAR heading relative to robot (radians)\n",
    "            max_range_px: max range in pixels\n",
    "            num_beams: number of beams to simulate\n",
    "            fov_deg: field of view in degrees\n",
    "        Returns:\n",
    "            (z_all, c_all): list of measurements (each a 2-vector) and\n",
    "                            corresponding landmark IDs (integers)\n",
    "        \"\"\" \n",
    "        fov = np.deg2rad(fov_deg)\n",
    "        angles = (heading + np.linspace(-fov/2, fov/2, num_beams, endpoint=False)) % (2*np.pi)\n",
    "\n",
    "        # -------- Vectorized cast for all beams --------\n",
    "        W, H = self.map.wall_mask.shape\n",
    "        stride = max(1, int(self.map.ray_stride))\n",
    "        S = int(max_range_px // stride) + 1\n",
    "        r = (np.arange(S, dtype=np.int32) * stride)[None, :]          # (1,S)\n",
    "        A = angles[:, None].astype(np.float32)                         # (B,1)\n",
    "\n",
    "        x0, y0 = float(gt_pose[0]), float(gt_pose[1])\n",
    "        X = (x0 + r * np.cos(A)).astype(np.int32)                      # (B,S)\n",
    "        Y = (y0 + r * np.sin(A)).astype(np.int32)                      # (B,S)\n",
    "\n",
    "        oob = (X < 0) | (X >= W) | (Y < 0) | (Y >= H)                  # (B,S)\n",
    "        inb = ~oob\n",
    "        wall = np.zeros_like(oob, dtype=bool)\n",
    "        if np.any(inb):\n",
    "            wall[inb] = self.map.wall_mask[X[inb], Y[inb]]\n",
    "        hit = oob | wall\n",
    "        has_hit = np.any(hit, axis=1)\n",
    "        first_idx = np.argmax(hit, axis=1)                             # (B,)\n",
    "        dists = np.where(has_hit, r.squeeze()[first_idx], float(max_range_px)).astype(np.float32)\n",
    "        first_is_wall = np.zeros_like(has_hit, dtype=bool)\n",
    "        if np.any(has_hit):\n",
    "            first_is_wall[has_hit] = wall[np.arange(angles.size)[has_hit], first_idx[has_hit]]\n",
    "\n",
    "        # keep only real wall hits\n",
    "        keep = first_is_wall\n",
    "        if not np.any(keep):\n",
    "            return [], []\n",
    "\n",
    "        # Hit pixels for kept beams\n",
    "        rows = np.arange(angles.size, dtype=np.int32)[keep]\n",
    "        cols = first_idx[keep].astype(np.int32)\n",
    "        hx = X[rows, cols].astype(np.int32)\n",
    "        hy = Y[rows, cols].astype(np.int32)\n",
    "\n",
    "        # Cells and de-dup per scan (keep first occurrence)\n",
    "        cx = (hx // self.grid_px).astype(np.int32)\n",
    "        cy = (hy // self.grid_px).astype(np.int32)\n",
    "        cells = np.stack([cx, cy], axis=1)                              # (K,2)\n",
    "        # unique cells preserving first occurrence order\n",
    "        if cells.shape[0] > 1:\n",
    "            view = np.ascontiguousarray(cells).view(\n",
    "                np.dtype((np.void, cells.dtype.itemsize * cells.shape[1]))\n",
    "            )\n",
    "            _, idx_first = np.unique(view, return_index=True)\n",
    "            keep_idx = np.sort(idx_first)\n",
    "        else:\n",
    "            keep_idx = np.array([0], dtype=np.int32)\n",
    "\n",
    "        beams_idx = rows[keep_idx]\n",
    "        cells_sel = cells[keep_idx]\n",
    "        d_sel = dists[keep][keep_idx]                                   # (K,)\n",
    "\n",
    "        # Vectorized noisy measurements\n",
    "        rng_std = np.sqrt(float(self.Q[0,0]))\n",
    "        brg_std = np.sqrt(float(self.Q[1,1]))\n",
    "        r_meas = d_sel + self.rng.normal(0.0, rng_std, size=d_sel.size).astype(np.float32)\n",
    "\n",
    "        # true phi = world angle - robot heading\n",
    "        phi_true = ((angles[beams_idx] - float(gt_pose[2]) + np.pi) % (2*np.pi)) - np.pi\n",
    "        phi_meas = phi_true + self.rng.normal(0.0, brg_std, size=phi_true.size).astype(np.float32)\n",
    "\n",
    "        # Quantize (vectorized)\n",
    "        r_q = self.range_step_px * np.round(r_meas / self.range_step_px)\n",
    "        p_step = self.bearing_step\n",
    "        phi_q = ((p_step * np.round(phi_meas / p_step) + np.pi) % (2*np.pi)) - np.pi\n",
    "\n",
    "        # Form outputs (lists as before)\n",
    "        z_all = [np.array([float(rq), float(pq)], dtype=np.float32) for rq, pq in zip(r_q, phi_q)]\n",
    "        c_all = []\n",
    "        for (cx_i, cy_i) in cells_sel:\n",
    "            j = self._ensure_id((int(cx_i), int(cy_i)))\n",
    "            c_all.append(j)\n",
    "\n",
    "        return z_all, c_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9886130",
   "metadata": {},
   "source": [
    "##### üì≤ <span style=\"color:#a4d4a3\">**FastSLAM Pygame Demo**  (two-panel UI)</span>\n",
    "\n",
    "This cell wires the <span style=\"color:#ffa500\">**front-end**</span> (Map2D, Lidar) and the <span style=\"color:#ffa500\">**FastSLAM core**</span> into an interactive `Pygame` demo with a <span style=\"color:#ffa500\">**two-panel layout**</span>:\n",
    "\n",
    "- <span style=\"color:#00703c\">**Left panel:**</span> ground-truth robot on the floor-plan (image), plus a rotating visualization beam.\n",
    "\n",
    "- <span style=\"color:#00703c\">**Right panel** (static world frame):</span> estimated robot pose, particle cloud, best-particle landmarks (with optional covariance ellipses), and estimated trajectory.\n",
    "\n",
    "The default map path is `../figures/floor_plan.png` (falls back to a blank free map if not found), but you can also change it with an occupancy map that you built in the first module.\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Controls**</span>\n",
    "\n",
    "- <span style=\"color:#ffa500\">**,**</span> / <span style=\"color:#ffa500\">**.**</span> decrease/increase <span style=\"color:#ffa500\">**beam subsampling**</span> (trade accuracy vs. speed)\n",
    "\n",
    "- <span style=\"color:#ffa500\">**N**</span> toggle <span style=\"color:#ffa500\">**nearest-K**</span> thinning of measurements (limits EKF load)\n",
    "\n",
    "- <span style=\"color:#ffa500\">**P**</span> toggle particle rendering\n",
    "\n",
    "- <span style=\"color:#ffa500\">**C**</span> toggle covariance ellipses\n",
    "\n",
    "- <span style=\"color:#ffa500\">**G**</span> re-initialize particles (around current map center)\n",
    "\n",
    "- <span style=\"color:#ffa500\">**K**</span> reset <span style=\"color:#ffa500\">**GT**</span> and <span style=\"color:#ffa500\">**EST**</span> pose to map center; clear trajectories\n",
    "\n",
    "<span style=\"color:#a4d4a3\">**Performance tips**</span>\n",
    "\n",
    "- For smoother rendering: reduce `num_beams`, increase `beam_subsample_step` or `ray_stride`, reduce `Np`, increase `grid_px`, or press <span style=\"color:#ffa500\">**C**</span> to disable covariance ellipses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f4ad78",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#--- Main application with Pygame ---\n",
    "import sys\n",
    "import numpy as np\n",
    "import pygame\n",
    "from collections import deque\n",
    "\n",
    "# --- Small helper ---\n",
    "def i2(p):\n",
    "    \"\"\"(x,y) -> (int,int)\"\"\"\n",
    "    return (int(p[0]), int(p[1]))\n",
    "\n",
    "# --- Config ---\n",
    "class Config:\n",
    "    # Window/panels\n",
    "    panel_w, panel_h = 500, 400\n",
    "    window_size = (panel_w*2, panel_h)\n",
    "\n",
    "    # Scan/visual\n",
    "    num_beams = 180\n",
    "    scan_ms   = 180\n",
    "    fov_deg   = 360\n",
    "    ray_stride = 2\n",
    "    traj_max   = 200\n",
    "\n",
    "    # Discretization (one landmark id per grid cell hit by LiDAR)\n",
    "    grid_px = 16\n",
    "    range_step_px = 4.0\n",
    "    bearing_step_deg = 4.0\n",
    "\n",
    "    # Motion (keyboard odometry: [dr1, dt, dr2])\n",
    "    trans_step = 12.0\n",
    "    rot_step   = np.deg2rad(12.0)\n",
    "\n",
    "    # Sensor noise (pixels & radians)\n",
    "    Q = np.diag([2.0**2, (2.0*np.pi/180.0)**2]).astype(np.float32)\n",
    "    R_x = np.diag([1.0**2, 1.0**2, (2.0*np.pi/180.0)**2]).astype(np.float32)\n",
    "    \n",
    "    # FastSLAM params\n",
    "    Np = 75   # number of particles\n",
    "    resample_neff_ratio = 0.5   # resample when N_eff < ratio * N\n",
    "\n",
    "    # Landmark thinning\n",
    "    use_nearest = True\n",
    "    nearest_k_seen = 25\n",
    "\n",
    "    # Beam sub-sampling\n",
    "    beam_subsample_step = 2\n",
    "\n",
    "    # Drawing perf\n",
    "    particle_draw_stride = 2\n",
    "\n",
    "    # Start seed\n",
    "    seed = 0\n",
    "\n",
    "#--- Simple panel wrapper ---\n",
    "class Panel:\n",
    "    def __init__(self, screen, rect): \n",
    "        self.screen, self.rect = screen, rect\n",
    "    @property\n",
    "    def ox(self): return self.rect[0]\n",
    "    def clear(self, color):\n",
    "        pygame.draw.rect(self.screen, color, self.rect)\n",
    "        pygame.draw.rect(self.screen, (200,200,200), self.rect, 2)\n",
    "    def blit(self, surf, at=(0,0)):\n",
    "        x,y,_,_ = self.rect; self.screen.blit(surf, (x+at[0], y+at[1]))\n",
    "    def polygon(self, color, pts):\n",
    "        x,y,_,_ = self.rect; P = [(x+int(px), y+int(py)) for (px,py) in pts]\n",
    "        pygame.draw.polygon(self.screen, color, P)\n",
    "    def circle(self, color, p, r, width=0):\n",
    "        \"\"\"width=0 => filled; width>0 => outline.\"\"\"\n",
    "        x,y,_,_ = self.rect\n",
    "        pygame.draw.circle(self.screen, color, (x+int(p[0]), y+int(p[1])), int(r), width)\n",
    "    def line(self, color, p0, p1, w=1):\n",
    "        x,y,_,_ = self.rect; pygame.draw.line(self.screen, color, (x+int(p0[0]), y+int(p0[1])), (x+int(p1[0]), y+int(p1[1])), w)\n",
    "    def text(self, font, s, color, pos):\n",
    "        x,y,_,_ = self.rect; self.screen.blit(font.render(s, True, color), (x+pos[0], y+pos[1]))\n",
    "\n",
    "# --- Main application ---\n",
    "class App:\n",
    "    def __init__(self, cfg: Config, floor_img_path='../figures/floor_plan.png'):\n",
    "        pygame.init()\n",
    "        self.cfg = cfg\n",
    "        self.screen = pygame.display.set_mode(cfg.window_size)\n",
    "        pygame.display.set_caption(\"GT (left) | FastSLAM (right, static map)\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.font  = pygame.font.SysFont(None, 18)\n",
    "        self.rng   = np.random.default_rng(cfg.seed)\n",
    "\n",
    "        # Panels\n",
    "        self.left  = Panel(self.screen, (0, 0, cfg.panel_w, cfg.panel_h))\n",
    "        self.right = Panel(self.screen, (cfg.panel_w, 0, cfg.panel_w, cfg.panel_h))\n",
    "\n",
    "        # Map + lidar\n",
    "        self.map = Map2D(cfg.panel_w, cfg.panel_h, ray_stride=cfg.ray_stride, floor_img_path=floor_img_path)\n",
    "        self.lidar = Lidar(cfg.panel_w, cfg.panel_h, grid_px=cfg.grid_px,\n",
    "                           range_step_px=cfg.range_step_px,\n",
    "                           bearing_step_deg=cfg.bearing_step_deg,\n",
    "                           Q=cfg.Q, world_map=self.map, rng=self.rng)\n",
    "\n",
    "        # GT start at CENTER (nearest free)\n",
    "        cx, cy = cfg.panel_w//2, cfg.panel_h//2\n",
    "        gx, gy = self.map.nearest_free_to((cx, cy))\n",
    "        gth    = 0.0\n",
    "        self.gt_pose = np.array([gx, gy, gth], dtype=np.float32)\n",
    "        self.gt_traj = []\n",
    "\n",
    "        # FastSLAM core (independent)\n",
    "        self.fs  = FastSLAM(N=cfg.Np, Q=cfg.Q, R_x=cfg.R_x, rng=self.rng,\n",
    "                            resample_neff_ratio=cfg.resample_neff_ratio)\n",
    "        self.fs.global_initialize(gx, gy, th_sd_deg=10.0, pos_sd=3.0)\n",
    "\n",
    "        self.est_pose = np.array([gx, gy, 0.0], dtype=np.float32)\n",
    "        self.est_traj = []\n",
    "\n",
    "        # Scan timer\n",
    "        self.SCAN_EVENT = pygame.USEREVENT + 1\n",
    "        pygame.time.set_timer(self.SCAN_EVENT, cfg.scan_ms)\n",
    "        self.beam_angle = 0.0\n",
    "        self.beam_speed = 2*np.pi*10\n",
    "        self.max_range_px = 300\n",
    "\n",
    "        # UI toggles\n",
    "        self.draw_particles = True\n",
    "        self.draw_cov = True\n",
    "\n",
    "    # --- Motion model (shared helper) ---\n",
    "    @staticmethod\n",
    "    def motion_model_odometry(u, x_prev: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply odometry u = [dr1, dt, dr2] to previous pose x_prev = [x,y,th].\n",
    "        Args:\n",
    "            u: odometry 3-vector (dr1, dt, dr2)\n",
    "            x_prev: previous pose (3-vector)\n",
    "        Returns:\n",
    "            x_new: new pose (3-vector)\n",
    "        \"\"\"\n",
    "        dr1, dt, dr2 = u\n",
    "        x_new = x_prev[0] + dt*np.cos(x_prev[2] + dr1)\n",
    "        y_new = x_prev[1] + dt*np.sin(x_prev[2] + dr1)\n",
    "        th_new= wrap_angle(x_prev[2] + dr1 + dr2)\n",
    "        return np.array([x_new, y_new, th_new], dtype=np.float32)\n",
    "\n",
    "    # --- Step motion + FastSLAM predict ---\n",
    "    def step_motion(self, cmd: np.ndarray):\n",
    "        \"\"\"Apply odometry command to GT and FastSLAM.\n",
    "        Args:\n",
    "            cmd: odometry command (3-vector)\n",
    "        \"\"\"\n",
    "        self.gt_pose = self.motion_model_odometry(cmd, self.gt_pose)\n",
    "        self.gt_traj.append(self.gt_pose.copy())\n",
    "        self.gt_traj = self.gt_traj[-self.cfg.traj_max:]\n",
    "\n",
    "        self.fs.predict(cmd)\n",
    "        self.est_pose = self.fs.estimate_pose(top_k_frac=1.0)\n",
    "        self.est_traj.append(self.est_pose.copy())\n",
    "        self.est_traj = self.est_traj[-self.cfg.traj_max:]\n",
    "\n",
    "    # --- Scan + FastSLAM update ---\n",
    "    def step_scan(self):\n",
    "        \"\"\"Simulate a LiDAR scan from GT pose; FastSLAM update.\"\"\"\n",
    "        heading = float(self.gt_pose[2])\n",
    "        z_all, c_all = self.lidar.scan(self.gt_pose, heading,\n",
    "                                      max_range_px=self.max_range_px,\n",
    "                                      num_beams=self.cfg.num_beams,\n",
    "                                      fov_deg=self.cfg.fov_deg)\n",
    "        if not z_all:\n",
    "            return\n",
    "\n",
    "        # Nearest-K thinning (optional)\n",
    "        if self.cfg.use_nearest and (self.est_pose is not None):\n",
    "            cx, cy = float(self.est_pose[0]), float(self.est_pose[1])\n",
    "            ids = np.array(list(set(int(j) for j in c_all)), dtype=np.int32)\n",
    "            centers = np.array([self.lidar.cell_center_xy(self.lidar.cell_by_id[j]) for j in ids],\n",
    "                               dtype=np.float32)\n",
    "            d = np.linalg.norm(centers - np.array([cx,cy], dtype=np.float32)[None,:], axis=1)\n",
    "            k = min(self.cfg.nearest_k_seen, ids.size)\n",
    "            keep = np.argpartition(d, k-1)[:k]\n",
    "            keep_ids = set(int(i) for i in ids[keep])\n",
    "            batch = [(z,j) for (z,j) in zip(z_all, c_all) if (j in keep_ids)]\n",
    "            if batch:\n",
    "                z_all, c_all = map(list, zip(*batch))\n",
    "\n",
    "        # Subsample beams\n",
    "        if self.cfg.beam_subsample_step > 1:\n",
    "            z_all = z_all[::self.cfg.beam_subsample_step]\n",
    "            c_all = c_all[::self.cfg.beam_subsample_step]\n",
    "\n",
    "        # RBPF correct\n",
    "        self.fs.update(z_all, c_all)\n",
    "        self.est_pose = self.fs.estimate_pose(top_k_frac=1.0)\n",
    "\n",
    "    # --- Drawing ---\n",
    "    def draw_left(self):\n",
    "        self.left.clear((30,30,30))\n",
    "        self.left.blit(self.map.surface, (0,0))\n",
    "\n",
    "        # GT traj\n",
    "        for i in range(1, len(self.gt_traj)):\n",
    "            p0 = i2(self.gt_traj[i-1][:2]); p1 = i2(self.gt_traj[i][:2])\n",
    "            pygame.draw.line(self.screen, (0,150,255), (self.left.ox+p0[0], p0[1]),\n",
    "                             (self.left.ox+p1[0], p1[1]), 2)\n",
    "\n",
    "        # GT robot (triangle)\n",
    "        gx,gy,gth = map(float, self.gt_pose)\n",
    "        pts = [\n",
    "            (gx + 15*np.cos(gth),     gy + 15*np.sin(gth)),\n",
    "            (gx + 10*np.cos(gth+2.5), gy + 10*np.sin(gth+2.5)),\n",
    "            (gx + 10*np.cos(gth-2.5), gy + 10*np.sin(gth-2.5))\n",
    "        ]\n",
    "        self.left.polygon((0,150,255), pts)\n",
    "\n",
    "        # rotating beam visualization\n",
    "        bx,by = i2(self.gt_pose[:2])\n",
    "        hit, dist = self.map.cast_beam_fast(self.gt_pose[:2], self.beam_angle, self.max_range_px)\n",
    "        ex,ey = (hit if hit else (int(bx + self.max_range_px*np.cos(self.beam_angle)),\n",
    "                                 int(by + self.max_range_px*np.sin(self.beam_angle))))\n",
    "        pygame.draw.line(self.screen, (255,0,0), (self.left.ox+bx, by), (self.left.ox+ex, ey), 2)\n",
    "\n",
    "    def draw_right(self):\n",
    "        self.right.clear((255,255,255))\n",
    "\n",
    "        # Estimated trajectory\n",
    "        if len(self.est_traj) >= 2:\n",
    "            for i in range(1, len(self.est_traj)):\n",
    "                p0 = self.est_traj[i-1][:2]; p1 = self.est_traj[i][:2]\n",
    "                self.right.line((120,200,160), p0, p1, 2)\n",
    "\n",
    "        # Particles\n",
    "        if self.draw_particles:\n",
    "            stride = max(1, self.cfg.particle_draw_stride)\n",
    "            for idx, pr in enumerate(self.fs.p):\n",
    "                if (idx % stride) == 0:\n",
    "                    self.right.circle((0,180,120), (pr.x, pr.y), 1)\n",
    "\n",
    "        # Estimated robot\n",
    "        if self.est_pose is not None:\n",
    "            px,py,pth = map(float, self.est_pose)\n",
    "            self.right.circle((0,180,120), (px,py), 6, width=2)  # hollow outline\n",
    "            hx = px + 14*np.cos(pth); hy = py + 14*np.sin(pth)\n",
    "            self.right.line((0,180,120), (px,py), (hx,hy), 2)\n",
    "\n",
    "        # Landmarks from best particle\n",
    "        best = self.fs.best_particle()\n",
    "        for lm_id, (mu, Sigma, seen) in best.map.items():\n",
    "            if not seen: continue\n",
    "            self.right.circle((255,0,0), (float(mu[0]), float(mu[1])), 2)\n",
    "            if self.draw_cov:\n",
    "                self.draw_cov_ellipse_world(mu, Sigma, (120,60,60))\n",
    "\n",
    "        # HUD\n",
    "        fps = self.clock.get_fps(); neff = self.fs.neff(); bstep = self.cfg.beam_subsample_step\n",
    "        hud1 = (f\"FPS:{fps:4.1f} | N:{self.cfg.Np} | Neff:{neff:5.1f} \"\n",
    "                f\"| Beams:{self.cfg.num_beams}/{bstep} | Grid:{self.cfg.grid_px}px \"\n",
    "                f\"| LMs:{len(self.lidar.cell_by_id)}\")\n",
    "        self.right.text(self.font, hud1, (10,10,10), (10,0))\n",
    "\n",
    "    def draw_cov_ellipse_world(self, mu, Sigma, color, nsig=2.0):\n",
    "        # Guard against NaN/inf or absurd positions\n",
    "        if not np.all(np.isfinite(mu)) or not np.all(np.isfinite(Sigma)):\n",
    "            return\n",
    "        if abs(mu[0]) > 1e6 or abs(mu[1]) > 1e6:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            vals, vecs = np.linalg.eigh(Sigma)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return\n",
    "        vals = np.maximum(vals, 1e-12)\n",
    "        order = np.argsort(vals)[::-1]\n",
    "        vals = vals[order]; vecs = vecs[:, order]\n",
    "        w = 2*nsig*np.sqrt(vals[0]); h = 2*nsig*np.sqrt(vals[1])\n",
    "        ang = np.degrees(np.arctan2(vecs[1,0], vecs[0,0]))\n",
    "\n",
    "        rect = pygame.Rect(0, 0, max(1, int(w)), max(1, int(h)))\n",
    "        try:\n",
    "            rect.center = (int(mu[0]), int(mu[1]))\n",
    "        except Exception:\n",
    "            return  # safety, in case mu still misbehaves\n",
    "\n",
    "        el = pygame.Surface(rect.size, pygame.SRCALPHA)\n",
    "        pygame.draw.ellipse(el, color, el.get_rect(), 2)\n",
    "        rot = pygame.transform.rotate(el, -ang)\n",
    "        rs = rot.get_rect(center=(self.right.ox + rect.centerx, rect.centery))\n",
    "        self.screen.blit(rot, rs)\n",
    "\n",
    "    # --- Main loop ---\n",
    "    def run(self):\n",
    "        running = True\n",
    "        while running:\n",
    "            dt = self.clock.tick(30) / 1000.0\n",
    "            self.beam_angle = (self.beam_angle + self.beam_speed*dt) % (2*np.pi)\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    running = False\n",
    "                elif ev.type == pygame.KEYDOWN:\n",
    "                    if   ev.key == pygame.K_UP:    cmd = np.array([0.0, self.cfg.trans_step, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_LEFT:  cmd = np.array([-self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_RIGHT: cmd = np.array([ self.cfg.rot_step, 0.0, 0.0], dtype=np.float32)\n",
    "                    elif ev.key == pygame.K_COMMA: self.cfg.beam_subsample_step = max(1, self.cfg.beam_subsample_step-1); cmd=None\n",
    "                    elif ev.key == pygame.K_PERIOD:self.cfg.beam_subsample_step = min(12, self.cfg.beam_subsample_step+1); cmd=None\n",
    "                    elif ev.key == pygame.K_n:     self.cfg.use_nearest = not self.cfg.use_nearest; cmd=None\n",
    "                    elif ev.key == pygame.K_p:     self.draw_particles = not self.draw_particles; cmd=None\n",
    "                    elif ev.key == pygame.K_c:     self.draw_cov = not self.draw_cov; cmd=None\n",
    "                    elif ev.key == pygame.K_g:     # re-init particles around center\n",
    "                        cx, cy = self.cfg.panel_w//2, self.cfg.panel_h//2\n",
    "                        gx, gy = self.map.nearest_free_to((cx, cy))\n",
    "                        self.fs.global_initialize(gx, gy, th_sd_deg=10.0, pos_sd=3.0); cmd=None\n",
    "                    elif ev.key == pygame.K_k:\n",
    "                        cx, cy = self.cfg.panel_w//2, self.cfg.panel_h//2\n",
    "                        gx, gy = self.map.nearest_free_to((cx, cy))\n",
    "                        self.gt_pose  = np.array([gx, gy, 0.0], dtype=np.float32)\n",
    "                        self.est_pose = self.gt_pose.copy()\n",
    "                        self.gt_traj.clear(); self.est_traj.clear(); cmd=None\n",
    "                    else:\n",
    "                        cmd=None\n",
    "                    if cmd is not None:\n",
    "                        self.step_motion(cmd)\n",
    "                elif ev.type == self.SCAN_EVENT:\n",
    "                    self.step_scan()\n",
    "\n",
    "            self.draw_left(); self.draw_right(); pygame.display.flip()\n",
    "\n",
    "        pygame.quit(); sys.exit()\n",
    "\n",
    "# run_demo.py\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    App(cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683bebce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8c920",
   "metadata": {},
   "source": [
    "#### ‚è±Ô∏è <span style=\"color:#a4d4a3\">**FastSLAM Complexity**</span>\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Update robot particles**</span> based on the control $O(N)$\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Incorporate an obseravtion**</span> into the Kalman Filters $O(N)$\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Resample particle**</span> set $O(N \\cdot M)$\n",
    "\n",
    "where:\n",
    "\n",
    "- $N$ is the number of particles\n",
    "- $M$ is the number of landmarks\n",
    "\n",
    "Thus $O(N \\cdot M)$ for FastSLAM1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c936c7f",
   "metadata": {},
   "source": [
    "#### ‚¨ÜÔ∏è <span style=\"color:#a4d4a3\">**From FastSLAM1.0 to FastSLAM2.0**</span>\n",
    "\n",
    "<span style=\"color:#00703c\">**FastSLAM1.0**</span> uses the motion model as the proposal distribution:\n",
    "\n",
    "$$\n",
    "x_t^{[k]} \\sim p(x_t \\mid x_{t-1}^{[k]}, u_t)\n",
    "$$\n",
    "\n",
    "*But, is there <span style=\"color:#ffa500\">**a better distribution**</span> to sample from?*\n",
    "\n",
    "- <span style=\"color:#00703c\">**FastSLAM 2.0**</span> considers also the measurements during sampling.\n",
    "\n",
    "- Especially useful if an <span style=\"color:#ffa500\">**accurate sensor is used**</span> (e.g. predictions from scan matching, compared to the motion noise).\n",
    "\n",
    "- <span style=\"color:#00703c\">**FastSLAM 2.0**</span>  samples from:\n",
    "\n",
    "    $$\n",
    "    x_t^{[k]} \\sim p(x_t \\mid x_{t-1}^{[k]}, u_{1:t}. z_{1:t})\n",
    "    $$\n",
    "\n",
    "- Results in a <span style=\"color:#ffa500\">**more peaked proposal distribution**</span>.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Less particles**</span> required.\n",
    "\n",
    "- More robust and accurate but also <span style=\"color:#ffa500\">**more complex**</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c53b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41229d5c",
   "metadata": {},
   "source": [
    "#### ‚úîÔ∏è <span style=\"color:#a4d4a3\">Summary</span>\n",
    "\n",
    "- Uses a <span style=\"color:#ffa500\">**Particle Filter**</span> to model the belief over <span style=\"color:#ffa500\">**robot paths**</span>.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Factorizes**</span> the SLAM posterior into <span style=\"color:#ffa500\">**low-dimensional**</span> problems.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Samples only the robot‚Äôs path**</span>; for each particle, <span style=\"color:#ffa500\">**computes landmarks**</span> (independent EKFs) <span style=\"color:#ffa500\">**given the path**</span>.\n",
    "\n",
    "- Particle <span style=\"color:#ffa500\">**weights**</span> measure how <span style=\"color:#ffa500\">**consistent**</span> each sample‚Äôs world is with <span style=\"color:#ffa500\">**what the system actually perceives**</span>.\n",
    "\n",
    "- Per-particle data association.\n",
    "\n",
    "- No robot pose uncertainty in the per-particle data association.\n",
    "\n",
    "- <span style=\"color:#00703c\">**FastSLAM1.0**</span> and <span style=\"color:#00703c\">**FastSLAM2.0**</span> differ in the <span style=\"color:#ffa500\">**proposal distribution**</span>.\n",
    "\n",
    "- Complexity $O(N \\cdot \\log{M})$.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Scales well**</span> (1 million+ features).\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Robust to ambiguities**</span> in the data association.\n",
    "\n",
    "- <span style=\"color:#ffa500\">**Advantages compared to the classical EKF**</span> approach (especially with non-liberalities).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217d204",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81491d73",
   "metadata": {},
   "source": [
    "### üìö <span style=\"color:#a4d4a3\">**Reading Material**</span>\n",
    "\n",
    "**FastSLAM**\n",
    "- Thrun et al.: *\"Probabilistic Robotics\"*, **Chapter 13.1-13.3, 13.8**\n",
    " \n",
    "- Montemerlo, Thrun, Kollar amd Wegbreit: ***\"FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem\"***, 2002\n",
    "\n",
    "- Montemerlo and Thrun: ***\"Simultaneous Localization and Mapping with Uknown Data Association Using FastSLAM\"***, 2003"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
